{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4725e2ad-4da9-4c78-b84a-93d933993d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "175c1325-3340-4988-bac5-60007210010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc0c898d-e597-474a-914d-5cd212e737cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Marker Genes.......\n",
      "1125\n",
      "1125\n",
      "2250\n",
      "2250\n",
      "                    0                1\n",
      "0     ENSG00000101210  ENSG00000172270\n",
      "1     ENSG00000099622  ENSG00000141905\n",
      "2     ENSG00000105278  ENSG00000167658\n",
      "3     ENSG00000178951  ENSG00000089847\n",
      "4     ENSG00000141985  ENSG00000127663\n",
      "...               ...              ...\n",
      "1120  ENSG00000285395  ENSG00000103316\n",
      "1121  ENSG00000140740  ENSG00000284218\n",
      "1122  ENSG00000122254  ENSG00000103365\n",
      "1123  ENSG00000006116  ENSG00000182601\n",
      "1124  ENSG00000077235  ENSG00000171208\n",
      "\n",
      "[1125 rows x 2 columns]\n",
      "                    0                1\n",
      "0     ENSG00000101210  ENSG00000172270\n",
      "1     ENSG00000099622  ENSG00000141905\n",
      "2     ENSG00000105278  ENSG00000167658\n",
      "3     ENSG00000178951  ENSG00000089847\n",
      "4     ENSG00000141985  ENSG00000127663\n",
      "...               ...              ...\n",
      "1120  ENSG00000285395  ENSG00000103316\n",
      "1121  ENSG00000140740  ENSG00000284218\n",
      "1122  ENSG00000122254  ENSG00000103365\n",
      "1123  ENSG00000006116  ENSG00000182601\n",
      "1124  ENSG00000077235  ENSG00000171208\n",
      "\n",
      "[1125 rows x 2 columns]\n",
      "Getting Pathway Genes.........\n",
      "Getting Masking.........\n",
      "HSA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwer/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.........\n",
      "Current sub-neural network has 1 hidden layers.\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▍                                                                                                                                                                         | 1/50 [00:00<00:15,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 5.0317, Train_accuracy: 49.82605608803692, Val Loss: 2.1583, Val_accuracy: 50.24494142705005\n",
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▉                                                                                                                                                                      | 2/50 [00:00<00:15,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 4.9790, Train_accuracy: 49.82605608803692, Val Loss: 2.1352, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████████▍                                                                                                                                                                  | 3/50 [00:01<00:21,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 4.9351, Train_accuracy: 49.82605608803692, Val Loss: 2.1158, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████████▊                                                                                                                                                               | 4/50 [00:01<00:18,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 4.9051, Train_accuracy: 49.82605608803692, Val Loss: 2.1025, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████████████▎                                                                                                                                                           | 5/50 [00:02<00:21,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 4.8874, Train_accuracy: 49.82605608803692, Val Loss: 2.0947, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████████████▊                                                                                                                                                        | 6/50 [00:02<00:18,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 4.8771, Train_accuracy: 49.82605608803692, Val Loss: 2.0903, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████████▏                                                                                                                                                    | 7/50 [00:03<00:20,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 4.8707, Train_accuracy: 49.82605608803692, Val Loss: 2.0875, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████████████▋                                                                                                                                                 | 8/50 [00:03<00:18,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 4.8666, Train_accuracy: 49.82605608803692, Val Loss: 2.0858, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████████▏                                                                                                                                             | 9/50 [00:03<00:16,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 4.8637, Train_accuracy: 49.82605608803692, Val Loss: 2.0846, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████████▍                                                                                                                                         | 10/50 [00:04<00:18,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 4.8617, Train_accuracy: 49.82605608803692, Val Loss: 2.0837, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████████▊                                                                                                                                      | 11/50 [00:04<00:16,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 4.8601, Train_accuracy: 49.82605608803692, Val Loss: 2.0831, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████████████████▎                                                                                                                                  | 12/50 [00:05<00:18,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 4.8589, Train_accuracy: 49.82605608803692, Val Loss: 2.0825, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████████████████████████▋                                                                                                                               | 13/50 [00:05<00:16,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 4.8579, Train_accuracy: 49.82605608803692, Val Loss: 2.0821, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████████████████████████████▏                                                                                                                           | 14/50 [00:06<00:17,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 4.8570, Train_accuracy: 49.82605608803692, Val Loss: 2.0818, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████████▌                                                                                                                        | 15/50 [00:06<00:15,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 4.8563, Train_accuracy: 49.82605608803692, Val Loss: 2.0815, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████████████████████████                                                                                                                     | 16/50 [00:06<00:13,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 4.8556, Train_accuracy: 49.82605608803692, Val Loss: 2.0812, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████████████████████████████████▍                                                                                                                 | 17/50 [00:07<00:15,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Loss: 4.8550, Train_accuracy: 49.82605608803692, Val Loss: 2.0810, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████████████████████████████████████▉                                                                                                              | 18/50 [00:07<00:13,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Loss: 4.8544, Train_accuracy: 49.82605608803692, Val Loss: 2.0807, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████████████████████████████████████▎                                                                                                          | 19/50 [00:08<00:14,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Train Loss: 4.8538, Train_accuracy: 49.82605608803692, Val Loss: 2.0805, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████████████████████████▊                                                                                                       | 20/50 [00:08<00:13,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Train Loss: 4.8531, Train_accuracy: 49.82605608803692, Val Loss: 2.0802, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████████████████████████████████████████▏                                                                                                   | 21/50 [00:09<00:11,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Train Loss: 4.8522, Train_accuracy: 49.82605608803692, Val Loss: 2.0799, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████████████████████████████████████████████▋                                                                                                | 22/50 [00:09<00:13,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Train Loss: 4.8511, Train_accuracy: 49.82605608803692, Val Loss: 2.0795, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████████████████████████████████████████                                                                                             | 23/50 [00:10<00:11,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Train Loss: 4.8495, Train_accuracy: 49.82605608803692, Val Loss: 2.0789, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████████████████████████████████████████████▌                                                                                         | 24/50 [00:10<00:10,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Train Loss: 4.8470, Train_accuracy: 49.82605608803692, Val Loss: 2.0780, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████████████                                                                                      | 25/50 [00:11<00:11,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Train Loss: 4.8429, Train_accuracy: 49.82605608803692, Val Loss: 2.0764, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 26/50 [00:11<00:10,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Train Loss: 4.8359, Train_accuracy: 49.82605608803692, Val Loss: 2.0736, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                               | 27/50 [00:11<00:09,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Train Loss: 4.8255, Train_accuracy: 49.82605608803692, Val Loss: 2.0695, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                           | 28/50 [00:12<00:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Train Loss: 4.8123, Train_accuracy: 49.82605608803692, Val Loss: 2.0642, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 29/50 [00:12<00:08,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Train Loss: 4.7981, Train_accuracy: 49.82605608803692, Val Loss: 2.0584, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 30/50 [00:13<00:09,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Train Loss: 4.7849, Train_accuracy: 49.82605608803692, Val Loss: 2.0530, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 31/50 [00:13<00:08,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Train Loss: 4.7732, Train_accuracy: 49.82605608803692, Val Loss: 2.0482, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 32/50 [00:13<00:07,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Train Loss: 4.7607, Train_accuracy: 49.82605608803692, Val Loss: 2.0431, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                          | 33/50 [00:14<00:07,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Train Loss: 4.7477, Train_accuracy: 49.82605608803692, Val Loss: 2.0378, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 34/50 [00:14<00:06,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Train Loss: 4.7342, Train_accuracy: 49.82605608803692, Val Loss: 2.0323, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 35/50 [00:15<00:07,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Train Loss: 4.7200, Train_accuracy: 49.82605608803692, Val Loss: 2.0266, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 36/50 [00:15<00:06,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Train Loss: 4.7051, Train_accuracy: 49.82605608803692, Val Loss: 2.0206, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                            | 37/50 [00:16<00:05,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Train Loss: 4.6897, Train_accuracy: 49.82605608803692, Val Loss: 2.0143, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                         | 38/50 [00:16<00:05,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Train Loss: 4.6739, Train_accuracy: 49.82605608803692, Val Loss: 2.0080, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 39/50 [00:17<00:04,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Train Loss: 4.6579, Train_accuracy: 49.82605608803692, Val Loss: 2.0017, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 40/50 [00:17<00:04,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Train Loss: 4.6417, Train_accuracy: 49.82605608803692, Val Loss: 1.9953, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 41/50 [00:18<00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Train Loss: 4.6255, Train_accuracy: 49.82605608803692, Val Loss: 1.9889, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 42/50 [00:18<00:03,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Train Loss: 4.6094, Train_accuracy: 49.82605608803692, Val Loss: 1.9826, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                        | 43/50 [00:19<00:03,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Train Loss: 4.5939, Train_accuracy: 49.82605608803692, Val Loss: 1.9766, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                    | 44/50 [00:19<00:02,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Train Loss: 4.5791, Train_accuracy: 49.82605608803692, Val Loss: 1.9710, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 45/50 [00:20<00:02,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Train Loss: 4.5652, Train_accuracy: 49.82605608803692, Val Loss: 1.9656, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 46/50 [00:20<00:01,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Train Loss: 4.5522, Train_accuracy: 49.82605608803692, Val Loss: 1.9606, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 47/50 [00:20<00:01,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Train Loss: 4.5399, Train_accuracy: 49.82605608803692, Val Loss: 1.9560, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 48/50 [00:21<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Train Loss: 4.5285, Train_accuracy: 49.82605608803692, Val Loss: 1.9516, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 49/50 [00:21<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Train Loss: 4.5178, Train_accuracy: 49.82605608803692, Val Loss: 1.9475, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:22<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Train Loss: 4.5077, Train_accuracy: 49.82605608803692, Val Loss: 1.9437, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accucary 50.27683134582624\n",
      "Current sub-neural network has 2 hidden layers.\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▍                                                                                                                                                                         | 1/50 [00:00<00:16,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 5.0780, Train_accuracy: 49.82605608803692, Val Loss: 2.1786, Val_accuracy: 50.24494142705005\n",
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▉                                                                                                                                                                      | 2/50 [00:00<00:24,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 5.0749, Train_accuracy: 49.82605608803692, Val Loss: 2.1772, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████████▍                                                                                                                                                                  | 3/50 [00:01<00:20,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 5.0708, Train_accuracy: 49.82605608803692, Val Loss: 2.1754, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████████▊                                                                                                                                                               | 4/50 [00:01<00:17,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 5.0650, Train_accuracy: 49.82605608803692, Val Loss: 2.1729, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████████████▎                                                                                                                                                           | 5/50 [00:02<00:21,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 5.0571, Train_accuracy: 49.82605608803692, Val Loss: 2.1695, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████████████▊                                                                                                                                                        | 6/50 [00:02<00:18,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 5.0465, Train_accuracy: 49.82605608803692, Val Loss: 2.1648, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████████▏                                                                                                                                                    | 7/50 [00:03<00:20,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 5.0326, Train_accuracy: 49.82605608803692, Val Loss: 2.1588, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████████████▋                                                                                                                                                 | 8/50 [00:03<00:18,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 5.0152, Train_accuracy: 49.82605608803692, Val Loss: 2.1512, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████████▏                                                                                                                                             | 9/50 [00:03<00:16,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 4.9947, Train_accuracy: 49.82605608803692, Val Loss: 2.1423, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████████▍                                                                                                                                         | 10/50 [00:04<00:18,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 4.9726, Train_accuracy: 49.82605608803692, Val Loss: 2.1325, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████████▊                                                                                                                                      | 11/50 [00:04<00:16,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 4.9506, Train_accuracy: 49.82605608803692, Val Loss: 2.1229, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████████████████▎                                                                                                                                  | 12/50 [00:05<00:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 4.9308, Train_accuracy: 49.82605608803692, Val Loss: 2.1142, Val_accuracy: 50.24494142705005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/custom_main.py:391\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_dict_fc, model_dict_sparse\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 391\u001b[0m     model_dict_fc, model_dict_sparse \u001b[38;5;241m=\u001b[39m  \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_dict_sparse)\n",
      "File \u001b[0;32m/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/custom_main.py:357\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgene_expression\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprint_information\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent sub-neural network has \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(output_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m hidden layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 357\u001b[0m     output_train, output_val,model_dict_sparse[output_layer] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_cell_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlayers_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmasking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmodel_save_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_save_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdate_string\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranining_fully_connected_layers:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(masking) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/custom_main.py:206\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(train_dataloader, val_dataloader, test_dataloader, test_cell_id, layers_node, masking, output_layer, model_save_dir, date_string, learning_rate, num_epochs, weight_decay)\u001b[0m\n\u001b[1;32m    198\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_features,batch_targets \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m    200\u001b[0m     \n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#print(batch_targets)\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model_nn(batch_features)\n\u001b[1;32m    208\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_compile.py:20\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mThis API should be only used inside torch, external users should still use\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mtorch._dynamo.disable. The main goal of this API is to avoid circular\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mthe invocation of the decorated function.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: CustomNetwork(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=582, out_features=356, bias=False)\n",
      "    (1): Linear(in_features=356, out_features=1, bias=True)\n",
      "  )\n",
      "), 3: CustomNetwork(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=582, out_features=356, bias=False)\n",
      "    (1): Linear(in_features=356, out_features=134, bias=False)\n",
      "    (2): Linear(in_features=134, out_features=1, bias=True)\n",
      "  )\n",
      "), 4: CustomNetwork(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=582, out_features=356, bias=False)\n",
      "    (1): Linear(in_features=356, out_features=134, bias=False)\n",
      "    (2): Linear(in_features=134, out_features=29, bias=False)\n",
      "    (3): Linear(in_features=29, out_features=1, bias=True)\n",
      "  )\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "def run_script_and_capture_output(script_name):\n",
    "    # Backup the original globals\n",
    "    old_globals = globals().copy()\n",
    "\n",
    "    # Run the script and capture the outputs\n",
    "    %run -i $script_name\n",
    "\n",
    "    # Extract the outputs from the globals after running the script\n",
    "    model_dict_fc = globals().get('model_dict_fc')\n",
    "    model_dict_sparse = globals().get('model_dict_sparse')\n",
    "\n",
    "    # Restore the original globals to avoid polluting the notebook environment\n",
    "    globals().update(old_globals)\n",
    "\n",
    "    return model_dict_fc, model_dict_sparse\n",
    "\n",
    "# Run the script and capture the outputs\n",
    "model_dict_fc, model_dict_sparse = run_script_and_capture_output('custom_main.py')\n",
    "\n",
    "# Now you can use model_dict_fc and model_dict_sparse in your notebook\n",
    "print(model_dict_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dfacfaa6-5286-48c8-8770-44ba176da422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'custom_main.py'], returncode=0, stdout=b'Getting Marker Genes.......\\n1125\\n1125\\n2250\\n2250\\n                    0                1\\n0     ENSG00000101210  ENSG00000172270\\n1     ENSG00000099622  ENSG00000141905\\n2     ENSG00000105278  ENSG00000167658\\n3     ENSG00000178951  ENSG00000089847\\n4     ENSG00000141985  ENSG00000127663\\n...               ...              ...\\n1120  ENSG00000285395  ENSG00000103316\\n1121  ENSG00000140740  ENSG00000284218\\n1122  ENSG00000122254  ENSG00000103365\\n1123  ENSG00000006116  ENSG00000182601\\n1124  ENSG00000077235  ENSG00000171208\\n\\n[1125 rows x 2 columns]\\n                    0                1\\n0     ENSG00000101210  ENSG00000172270\\n1     ENSG00000099622  ENSG00000141905\\n2     ENSG00000105278  ENSG00000167658\\n3     ENSG00000178951  ENSG00000089847\\n4     ENSG00000141985  ENSG00000127663\\n...               ...              ...\\n1120  ENSG00000285395  ENSG00000103316\\n1121  ENSG00000140740  ENSG00000284218\\n1122  ENSG00000122254  ENSG00000103365\\n1123  ENSG00000006116  ENSG00000182601\\n1124  ENSG00000077235  ENSG00000171208\\n\\n[1125 rows x 2 columns]\\nGetting Pathway Genes.........\\nGetting Masking.........\\nHSA\\nTraining.........\\nCurrent sub-neural network has 1 hidden layers.\\n...\\nEpoch [1/50], Train Loss: 4.8181, Train_accuracy: 54.12140575079872, Val Loss: 2.0656, Val_accuracy: 53.88711395101171\\nModel saved.\\nEpoch [2/50], Train Loss: 4.7789, Train_accuracy: 62.71210507632233, Val Loss: 2.0490, Val_accuracy: 62.44941427050053\\nModel saved.\\nEpoch [3/50], Train Loss: 4.7320, Train_accuracy: 65.97799077032303, Val Loss: 2.0291, Val_accuracy: 65.28221512247072\\nModel saved.\\nEpoch [4/50], Train Loss: 4.6759, Train_accuracy: 66.62406815761449, Val Loss: 2.0056, Val_accuracy: 65.45260915867945\\nModel saved.\\nEpoch [5/50], Train Loss: 4.6107, Train_accuracy: 66.96485623003196, Val Loss: 1.9784, Val_accuracy: 65.75079872204473\\nModel saved.\\nEpoch [6/50], Train Loss: 4.5387, Train_accuracy: 67.17074902378417, Val Loss: 1.9485, Val_accuracy: 66.09158679446219\\nModel saved.\\nEpoch [7/50], Train Loss: 4.4640, Train_accuracy: 67.53993610223642, Val Loss: 1.9176, Val_accuracy: 66.5601703940362\\nModel saved.\\nEpoch [8/50], Train Loss: 4.3900, Train_accuracy: 68.06531771388002, Val Loss: 1.8870, Val_accuracy: 67.13525026624067\\nModel saved.\\nEpoch [9/50], Train Loss: 4.3187, Train_accuracy: 68.8533901313454, Val Loss: 1.8577, Val_accuracy: 68.00851970181044\\nModel saved.\\nEpoch [10/50], Train Loss: 4.2517, Train_accuracy: 69.56336528221512, Val Loss: 1.8303, Val_accuracy: 68.58359957401491\\nModel saved.\\nEpoch [11/50], Train Loss: 4.1898, Train_accuracy: 69.96805111821087, Val Loss: 1.8050, Val_accuracy: 69.22257720979766\\nModel saved.\\nEpoch [12/50], Train Loss: 4.1331, Train_accuracy: 70.50763223287186, Val Loss: 1.7821, Val_accuracy: 69.92545260915868\\nModel saved.\\nEpoch [13/50], Train Loss: 4.0816, Train_accuracy: 71.03301384451544, Val Loss: 1.7613, Val_accuracy: 70.3940362087327\\nModel saved.\\nEpoch [14/50], Train Loss: 4.0347, Train_accuracy: 71.6435924742634, Val Loss: 1.7424, Val_accuracy: 70.69222577209797\\nModel saved.\\nEpoch [15/50], Train Loss: 3.9919, Train_accuracy: 71.92048278310259, Val Loss: 1.7254, Val_accuracy: 71.3738019169329\\nModel saved.\\nEpoch [16/50], Train Loss: 3.9527, Train_accuracy: 72.24707135250266, Val Loss: 1.7100, Val_accuracy: 71.73588924387647\\nModel saved.\\nEpoch [17/50], Train Loss: 3.9168, Train_accuracy: 72.59495917642883, Val Loss: 1.6962, Val_accuracy: 72.22577209797657\\nModel saved.\\nEpoch [18/50], Train Loss: 3.8836, Train_accuracy: 72.86474973375933, Val Loss: 1.6836, Val_accuracy: 72.60915867944622\\nModel saved.\\nEpoch [19/50], Train Loss: 3.8527, Train_accuracy: 73.1629392971246, Val Loss: 1.6723, Val_accuracy: 72.97124600638978\\nModel saved.\\nEpoch [20/50], Train Loss: 3.8241, Train_accuracy: 73.30493432729854, Val Loss: 1.6619, Val_accuracy: 73.07774227902023\\nModel saved.\\nEpoch [21/50], Train Loss: 3.7972, Train_accuracy: 73.54632587859425, Val Loss: 1.6525, Val_accuracy: 73.24813631522896\\nModel saved.\\nEpoch [22/50], Train Loss: 3.7720, Train_accuracy: 73.83741569045084, Val Loss: 1.6438, Val_accuracy: 73.50372736954206\\nModel saved.\\nEpoch [23/50], Train Loss: 3.7481, Train_accuracy: 74.07880724174655, Val Loss: 1.6358, Val_accuracy: 73.46112886048988\\nEpoch [24/50], Train Loss: 3.7256, Train_accuracy: 74.23500177493787, Val Loss: 1.6284, Val_accuracy: 73.6954206602769\\nModel saved.\\nEpoch [25/50], Train Loss: 3.7041, Train_accuracy: 74.36279730209442, Val Loss: 1.6215, Val_accuracy: 73.73801916932908\\nModel saved.\\nEpoch [26/50], Train Loss: 3.6834, Train_accuracy: 74.59708910188144, Val Loss: 1.6151, Val_accuracy: 74.03620873269436\\nModel saved.\\nEpoch [27/50], Train Loss: 3.6633, Train_accuracy: 74.88817891373802, Val Loss: 1.6090, Val_accuracy: 73.9297124600639\\nEpoch [28/50], Train Loss: 3.6442, Train_accuracy: 74.97337593184238, Val Loss: 1.6032, Val_accuracy: 74.12140575079871\\nModel saved.\\nEpoch [29/50], Train Loss: 3.6260, Train_accuracy: 75.17926872559461, Val Loss: 1.5979, Val_accuracy: 74.37699680511182\\nModel saved.\\nEpoch [30/50], Train Loss: 3.6086, Train_accuracy: 75.32836350727725, Val Loss: 1.5930, Val_accuracy: 74.46219382321618\\nModel saved.\\nEpoch [31/50], Train Loss: 3.5921, Train_accuracy: 75.4206602768903, Val Loss: 1.5884, Val_accuracy: 74.54739084132055\\nModel saved.\\nEpoch [32/50], Train Loss: 3.5762, Train_accuracy: 75.47745828895988, Val Loss: 1.5840, Val_accuracy: 74.52609158679446\\nEpoch [33/50], Train Loss: 3.5610, Train_accuracy: 75.64785232516861, Val Loss: 1.5799, Val_accuracy: 74.71778487752928\\nModel saved.\\nEpoch [34/50], Train Loss: 3.5464, Train_accuracy: 75.82534611288605, Val Loss: 1.5760, Val_accuracy: 74.6964856230032\\nEpoch [35/50], Train Loss: 3.5323, Train_accuracy: 75.97444089456869, Val Loss: 1.5723, Val_accuracy: 74.9520766773163\\nModel saved.\\nEpoch [36/50], Train Loss: 3.5189, Train_accuracy: 76.08803691870784, Val Loss: 1.5689, Val_accuracy: 74.84558040468583\\nEpoch [37/50], Train Loss: 3.5060, Train_accuracy: 76.24423145189918, Val Loss: 1.5657, Val_accuracy: 74.90947816826412\\nEpoch [38/50], Train Loss: 3.4936, Train_accuracy: 76.25843095491658, Val Loss: 1.5626, Val_accuracy: 74.90947816826412\\nEpoch [39/50], Train Loss: 3.4817, Train_accuracy: 76.40752573659923, Val Loss: 1.5598, Val_accuracy: 75.01597444089457\\nModel saved.\\nEpoch [40/50], Train Loss: 3.4702, Train_accuracy: 76.54242101526447, Val Loss: 1.5571, Val_accuracy: 75.03727369542067\\nModel saved.\\nEpoch [41/50], Train Loss: 3.4592, Train_accuracy: 76.59211927582534, Val Loss: 1.5546, Val_accuracy: 75.14376996805112\\nModel saved.\\nEpoch [42/50], Train Loss: 3.4485, Train_accuracy: 76.6915157969471, Val Loss: 1.5523, Val_accuracy: 75.07987220447285\\nEpoch [43/50], Train Loss: 3.4383, Train_accuracy: 76.7128150514732, Val Loss: 1.5500, Val_accuracy: 75.14376996805112\\nEpoch [44/50], Train Loss: 3.4283, Train_accuracy: 76.76251331203407, Val Loss: 1.5478, Val_accuracy: 75.16506922257722\\nModel saved.\\nEpoch [45/50], Train Loss: 3.4187, Train_accuracy: 76.84061057862975, Val Loss: 1.5458, Val_accuracy: 75.16506922257722\\nEpoch [46/50], Train Loss: 3.4094, Train_accuracy: 76.90450834220802, Val Loss: 1.5437, Val_accuracy: 75.2076677316294\\nModel saved.\\nEpoch [47/50], Train Loss: 3.4003, Train_accuracy: 77.00390486332978, Val Loss: 1.5419, Val_accuracy: 75.2076677316294\\nEpoch [48/50], Train Loss: 3.3916, Train_accuracy: 77.06070287539936, Val Loss: 1.5401, Val_accuracy: 75.29286474973377\\nModel saved.\\nEpoch [49/50], Train Loss: 3.3830, Train_accuracy: 77.15299964501243, Val Loss: 1.5384, Val_accuracy: 75.31416400425985\\nModel saved.\\nEpoch [50/50], Train Loss: 3.3747, Train_accuracy: 77.17429889953851, Val Loss: 1.5368, Val_accuracy: 75.27156549520767\\nTest Accucary 75.10647359454855\\nCurrent sub-neural network has 2 hidden layers.\\n...\\nEpoch [1/50], Train Loss: 4.8527, Train_accuracy: 50.17394391196308, Val Loss: 2.0795, Val_accuracy: 49.75505857294995\\nModel saved.\\nEpoch [2/50], Train Loss: 4.8509, Train_accuracy: 50.17394391196308, Val Loss: 2.0788, Val_accuracy: 49.75505857294995\\nEpoch [3/50], Train Loss: 4.8484, Train_accuracy: 50.17394391196308, Val Loss: 2.0778, Val_accuracy: 49.75505857294995\\nEpoch [4/50], Train Loss: 4.8448, Train_accuracy: 50.17394391196308, Val Loss: 2.0764, Val_accuracy: 49.75505857294995\\nEpoch [5/50], Train Loss: 4.8395, Train_accuracy: 52.637557685481006, Val Loss: 2.0742, Val_accuracy: 51.97018104366347\\nModel saved.\\nEpoch [6/50], Train Loss: 4.8320, Train_accuracy: 62.86119985800497, Val Loss: 2.0712, Val_accuracy: 62.87539936102237\\nModel saved.\\nEpoch [7/50], Train Loss: 4.8216, Train_accuracy: 65.5733049343273, Val Loss: 2.0669, Val_accuracy: 65.21831735889243\\nModel saved.\\nEpoch [8/50], Train Loss: 4.8076, Train_accuracy: 65.3106141285055, Val Loss: 2.0612, Val_accuracy: 64.66453674121406\\nEpoch [9/50], Train Loss: 4.7893, Train_accuracy: 65.11182108626198, Val Loss: 2.0536, Val_accuracy: 64.00425985090521\\nEpoch [10/50], Train Loss: 4.7659, Train_accuracy: 65.67980120695776, Val Loss: 2.0439, Val_accuracy: 64.89882854100107\\nEpoch [11/50], Train Loss: 4.7369, Train_accuracy: 66.354277600284, Val Loss: 2.0319, Val_accuracy: 65.34611288604899\\nModel saved.\\nEpoch [12/50], Train Loss: 4.7020, Train_accuracy: 66.8370607028754, Val Loss: 2.0175, Val_accuracy: 66.19808306709265\\nModel saved.\\nEpoch [13/50], Train Loss: 4.6614, Train_accuracy: 67.3340433084842, Val Loss: 2.0006, Val_accuracy: 66.3045793397231\\nModel saved.\\nEpoch [14/50], Train Loss: 4.6151, Train_accuracy: 67.41214057507987, Val Loss: 1.9815, Val_accuracy: 66.43237486687966\\nModel saved.\\nEpoch [15/50], Train Loss: 4.5649, Train_accuracy: 67.40504082357117, Val Loss: 1.9608, Val_accuracy: 66.70926517571885\\nModel saved.\\nEpoch [16/50], Train Loss: 4.5117, Train_accuracy: 67.73872914447995, Val Loss: 1.9389, Val_accuracy: 66.96485623003196\\nModel saved.\\nEpoch [17/50], Train Loss: 4.4570, Train_accuracy: 67.99432019879305, Val Loss: 1.9165, Val_accuracy: 67.11395101171459\\nModel saved.\\nEpoch [18/50], Train Loss: 4.4022, Train_accuracy: 68.19311324103657, Val Loss: 1.8941, Val_accuracy: 67.53993610223642\\nModel saved.\\nEpoch [19/50], Train Loss: 4.3489, Train_accuracy: 68.3493077742279, Val Loss: 1.8725, Val_accuracy: 67.90202342917998\\nModel saved.\\nEpoch [20/50], Train Loss: 4.2981, Train_accuracy: 68.67589634362797, Val Loss: 1.8519, Val_accuracy: 68.20021299254526\\nModel saved.\\nEpoch [21/50], Train Loss: 4.2501, Train_accuracy: 69.08058217962372, Val Loss: 1.8327, Val_accuracy: 68.58359957401491\\nModel saved.\\nEpoch [22/50], Train Loss: 4.2054, Train_accuracy: 69.50656727014554, Val Loss: 1.8148, Val_accuracy: 68.90308839190628\\nModel saved.\\nEpoch [23/50], Train Loss: 4.1640, Train_accuracy: 69.81895633652822, Val Loss: 1.7983, Val_accuracy: 69.28647497337593\\nModel saved.\\nEpoch [24/50], Train Loss: 4.1255, Train_accuracy: 70.28044018459354, Val Loss: 1.7831, Val_accuracy: 69.6059637912673\\nModel saved.\\nEpoch [25/50], Train Loss: 4.0897, Train_accuracy: 70.75612353567625, Val Loss: 1.7692, Val_accuracy: 70.1171458998935\\nModel saved.\\nEpoch [26/50], Train Loss: 4.0563, Train_accuracy: 70.99041533546325, Val Loss: 1.7563, Val_accuracy: 70.45793397231097\\nModel saved.\\nEpoch [27/50], Train Loss: 4.0248, Train_accuracy: 71.31700390486333, Val Loss: 1.7443, Val_accuracy: 70.82002129925452\\nModel saved.\\nEpoch [28/50], Train Loss: 3.9952, Train_accuracy: 71.56549520766774, Val Loss: 1.7332, Val_accuracy: 71.22470713525027\\nModel saved.\\nEpoch [29/50], Train Loss: 3.9673, Train_accuracy: 71.83528576499822, Val Loss: 1.7228, Val_accuracy: 71.28860489882854\\nModel saved.\\nEpoch [30/50], Train Loss: 3.9408, Train_accuracy: 72.24707135250266, Val Loss: 1.7132, Val_accuracy: 71.43769968051119\\nModel saved.\\nEpoch [31/50], Train Loss: 3.9157, Train_accuracy: 72.49556265530707, Val Loss: 1.7043, Val_accuracy: 71.60809371671992\\nModel saved.\\nEpoch [32/50], Train Loss: 3.8918, Train_accuracy: 72.80795172168975, Val Loss: 1.6960, Val_accuracy: 71.77848775292864\\nModel saved.\\nEpoch [33/50], Train Loss: 3.8690, Train_accuracy: 72.98544550940717, Val Loss: 1.6883, Val_accuracy: 71.77848775292864\\nEpoch [34/50], Train Loss: 3.8473, Train_accuracy: 73.30493432729854, Val Loss: 1.6810, Val_accuracy: 71.99148029818956\\nModel saved.\\nEpoch [35/50], Train Loss: 3.8268, Train_accuracy: 73.34043308484203, Val Loss: 1.6743, Val_accuracy: 72.03407880724174\\nModel saved.\\nEpoch [36/50], Train Loss: 3.8073, Train_accuracy: 73.61732339368122, Val Loss: 1.6679, Val_accuracy: 72.16187433439829\\nModel saved.\\nEpoch [37/50], Train Loss: 3.7888, Train_accuracy: 73.80901668441605, Val Loss: 1.6620, Val_accuracy: 72.48136315228967\\nModel saved.\\nEpoch [38/50], Train Loss: 3.7713, Train_accuracy: 73.9297124600639, Val Loss: 1.6566, Val_accuracy: 72.50266240681576\\nModel saved.\\nEpoch [39/50], Train Loss: 3.7547, Train_accuracy: 74.14270500532481, Val Loss: 1.6515, Val_accuracy: 72.71565495207668\\nModel saved.\\nEpoch [40/50], Train Loss: 3.7388, Train_accuracy: 74.1498047568335, Val Loss: 1.6468, Val_accuracy: 72.86474973375933\\nModel saved.\\nEpoch [41/50], Train Loss: 3.7237, Train_accuracy: 74.19950301739439, Val Loss: 1.6424, Val_accuracy: 72.94994675186368\\nModel saved.\\nEpoch [42/50], Train Loss: 3.7092, Train_accuracy: 74.28470003549876, Val Loss: 1.6383, Val_accuracy: 72.97124600638978\\nModel saved.\\nEpoch [43/50], Train Loss: 3.6955, Train_accuracy: 74.41249556265531, Val Loss: 1.6345, Val_accuracy: 73.12034078807241\\nModel saved.\\nEpoch [44/50], Train Loss: 3.6824, Train_accuracy: 74.50479233226837, Val Loss: 1.6310, Val_accuracy: 73.14164004259851\\nModel saved.\\nEpoch [45/50], Train Loss: 3.6698, Train_accuracy: 74.64678736244231, Val Loss: 1.6276, Val_accuracy: 73.29073482428115\\nModel saved.\\nEpoch [46/50], Train Loss: 3.6578, Train_accuracy: 74.83848065317714, Val Loss: 1.6244, Val_accuracy: 73.4185303514377\\nModel saved.\\nEpoch [47/50], Train Loss: 3.6462, Train_accuracy: 74.99467518636848, Val Loss: 1.6215, Val_accuracy: 73.20553780617678\\nEpoch [48/50], Train Loss: 3.6351, Train_accuracy: 74.97337593184238, Val Loss: 1.6187, Val_accuracy: 73.24813631522896\\nEpoch [49/50], Train Loss: 3.6244, Train_accuracy: 75.08697195598154, Val Loss: 1.6161, Val_accuracy: 73.1629392971246\\nEpoch [50/50], Train Loss: 3.6142, Train_accuracy: 75.15086971955982, Val Loss: 1.6136, Val_accuracy: 73.09904153354633\\nTest Accucary 73.44548551959114\\nCurrent sub-neural network has 3 hidden layers.\\n...\\nEpoch [1/50], Train Loss: 4.8531, Train_accuracy: 49.82605608803692, Val Loss: 2.0800, Val_accuracy: 50.24494142705005\\nModel saved.\\nEpoch [2/50], Train Loss: 4.8528, Train_accuracy: 49.82605608803692, Val Loss: 2.0799, Val_accuracy: 50.24494142705005\\nEpoch [3/50], Train Loss: 4.8525, Train_accuracy: 49.82605608803692, Val Loss: 2.0797, Val_accuracy: 50.24494142705005\\nEpoch [4/50], Train Loss: 4.8521, Train_accuracy: 49.82605608803692, Val Loss: 2.0796, Val_accuracy: 50.24494142705005\\nEpoch [5/50], Train Loss: 4.8516, Train_accuracy: 49.82605608803692, Val Loss: 2.0794, Val_accuracy: 50.24494142705005\\nEpoch [6/50], Train Loss: 4.8509, Train_accuracy: 49.82605608803692, Val Loss: 2.0790, Val_accuracy: 50.24494142705005\\nEpoch [7/50], Train Loss: 4.8499, Train_accuracy: 49.82605608803692, Val Loss: 2.0786, Val_accuracy: 50.24494142705005\\nEpoch [8/50], Train Loss: 4.8484, Train_accuracy: 50.06744763933262, Val Loss: 2.0780, Val_accuracy: 50.35143769968051\\nModel saved.\\nEpoch [9/50], Train Loss: 4.8462, Train_accuracy: 57.80617678381257, Val Loss: 2.0770, Val_accuracy: 58.2321618743344\\nModel saved.\\nEpoch [10/50], Train Loss: 4.8430, Train_accuracy: 65.68690095846645, Val Loss: 2.0757, Val_accuracy: 65.19701810436635\\nModel saved.\\nEpoch [11/50], Train Loss: 4.8385, Train_accuracy: 67.37664181753638, Val Loss: 2.0738, Val_accuracy: 65.79339723109692\\nModel saved.\\nEpoch [12/50], Train Loss: 4.8323, Train_accuracy: 67.51863684771033, Val Loss: 2.0712, Val_accuracy: 65.79339723109692\\nEpoch [13/50], Train Loss: 4.8239, Train_accuracy: 67.27014554490593, Val Loss: 2.0676, Val_accuracy: 65.66560170394037\\nEpoch [14/50], Train Loss: 4.8129, Train_accuracy: 67.15654952076677, Val Loss: 2.0630, Val_accuracy: 65.70820021299255\\nEpoch [15/50], Train Loss: 4.7988, Train_accuracy: 67.3553425630103, Val Loss: 2.0571, Val_accuracy: 65.814696485623\\nModel saved.\\nEpoch [16/50], Train Loss: 4.7810, Train_accuracy: 67.53993610223642, Val Loss: 2.0496, Val_accuracy: 66.00638977635782\\nModel saved.\\nEpoch [17/50], Train Loss: 4.7591, Train_accuracy: 67.75292864749734, Val Loss: 2.0405, Val_accuracy: 66.19808306709265\\nModel saved.\\nEpoch [18/50], Train Loss: 4.7326, Train_accuracy: 67.70323038693645, Val Loss: 2.0294, Val_accuracy: 66.34717784877529\\nModel saved.\\nEpoch [19/50], Train Loss: 4.7013, Train_accuracy: 67.92332268370608, Val Loss: 2.0162, Val_accuracy: 66.43237486687966\\nModel saved.\\nEpoch [20/50], Train Loss: 4.6651, Train_accuracy: 67.94462193823216, Val Loss: 2.0011, Val_accuracy: 66.5601703940362\\nModel saved.\\nEpoch [21/50], Train Loss: 4.6242, Train_accuracy: 68.15051473198439, Val Loss: 1.9839, Val_accuracy: 66.85835995740149\\nModel saved.\\nEpoch [22/50], Train Loss: 4.5790, Train_accuracy: 68.20021299254526, Val Loss: 1.9650, Val_accuracy: 67.11395101171459\\nModel saved.\\nEpoch [23/50], Train Loss: 4.5304, Train_accuracy: 68.38480653177139, Val Loss: 1.9446, Val_accuracy: 67.53993610223642\\nModel saved.\\nEpoch [24/50], Train Loss: 4.4791, Train_accuracy: 68.57649982250621, Val Loss: 1.9231, Val_accuracy: 67.81682641107561\\nModel saved.\\nEpoch [25/50], Train Loss: 4.4250, Train_accuracy: 68.76109336173234, Val Loss: 1.9005, Val_accuracy: 68.09371671991481\\nModel saved.\\nEpoch [26/50], Train Loss: 4.3714, Train_accuracy: 68.98828541001065, Val Loss: 1.8781, Val_accuracy: 68.45580404685836\\nModel saved.\\nEpoch [27/50], Train Loss: 4.3193, Train_accuracy: 69.22967696130635, Val Loss: 1.8564, Val_accuracy: 68.73269435569755\\nModel saved.\\nEpoch [28/50], Train Loss: 4.2696, Train_accuracy: 69.54916577919772, Val Loss: 1.8358, Val_accuracy: 68.83919062832801\\nModel saved.\\nEpoch [29/50], Train Loss: 4.2229, Train_accuracy: 69.80475683351082, Val Loss: 1.8165, Val_accuracy: 68.92438764643238\\nModel saved.\\nEpoch [30/50], Train Loss: 4.1796, Train_accuracy: 70.07454739084132, Val Loss: 1.7987, Val_accuracy: 69.20127795527156\\nModel saved.\\nEpoch [31/50], Train Loss: 4.1398, Train_accuracy: 70.28753993610223, Val Loss: 1.7825, Val_accuracy: 69.58466453674122\\nModel saved.\\nEpoch [32/50], Train Loss: 4.1032, Train_accuracy: 70.50053248136315, Val Loss: 1.7677, Val_accuracy: 69.73375931842385\\nModel saved.\\nEpoch [33/50], Train Loss: 4.0695, Train_accuracy: 70.79162229321973, Val Loss: 1.7543, Val_accuracy: 70.03194888178913\\nModel saved.\\nEpoch [34/50], Train Loss: 4.0383, Train_accuracy: 70.95491657791978, Val Loss: 1.7421, Val_accuracy: 70.24494142705005\\nModel saved.\\nEpoch [35/50], Train Loss: 4.0095, Train_accuracy: 71.20340788072417, Val Loss: 1.7309, Val_accuracy: 70.35143769968052\\nModel saved.\\nEpoch [36/50], Train Loss: 3.9828, Train_accuracy: 71.44479943201988, Val Loss: 1.7208, Val_accuracy: 70.58572949946752\\nModel saved.\\nEpoch [37/50], Train Loss: 3.9579, Train_accuracy: 71.55839545615903, Val Loss: 1.7115, Val_accuracy: 70.84132055378062\\nModel saved.\\nEpoch [38/50], Train Loss: 3.9346, Train_accuracy: 71.78558750443734, Val Loss: 1.7029, Val_accuracy: 71.07561235356762\\nModel saved.\\nEpoch [39/50], Train Loss: 3.9128, Train_accuracy: 72.07667731629392, Val Loss: 1.6949, Val_accuracy: 71.3738019169329\\nModel saved.\\nEpoch [40/50], Train Loss: 3.8924, Train_accuracy: 72.26837060702876, Val Loss: 1.6876, Val_accuracy: 71.395101171459\\nModel saved.\\nEpoch [41/50], Train Loss: 3.8733, Train_accuracy: 72.43876464323749, Val Loss: 1.6808, Val_accuracy: 71.58679446219382\\nModel saved.\\nEpoch [42/50], Train Loss: 3.8555, Train_accuracy: 72.6588569400071, Val Loss: 1.6746, Val_accuracy: 71.71458998935037\\nModel saved.\\nEpoch [43/50], Train Loss: 3.8386, Train_accuracy: 72.79375221867235, Val Loss: 1.6689, Val_accuracy: 71.77848775292864\\nModel saved.\\nEpoch [44/50], Train Loss: 3.8226, Train_accuracy: 73.00674476393326, Val Loss: 1.6635, Val_accuracy: 71.84238551650692\\nModel saved.\\nEpoch [45/50], Train Loss: 3.8075, Train_accuracy: 73.14164004259851, Val Loss: 1.6584, Val_accuracy: 72.11927582534611\\nModel saved.\\nEpoch [46/50], Train Loss: 3.7931, Train_accuracy: 73.27653532126375, Val Loss: 1.6537, Val_accuracy: 72.26837060702876\\nModel saved.\\nEpoch [47/50], Train Loss: 3.7794, Train_accuracy: 73.46822861199858, Val Loss: 1.6492, Val_accuracy: 72.50266240681576\\nModel saved.\\nEpoch [48/50], Train Loss: 3.7664, Train_accuracy: 73.58892438764643, Val Loss: 1.6450, Val_accuracy: 72.50266240681576\\nEpoch [49/50], Train Loss: 3.7539, Train_accuracy: 73.68832090876819, Val Loss: 1.6411, Val_accuracy: 72.58785942492013\\nModel saved.\\nEpoch [50/50], Train Loss: 3.7420, Train_accuracy: 73.75931842385516, Val Loss: 1.6375, Val_accuracy: 72.69435569755059\\nModel saved.\\nTest Accucary 73.3603066439523\\ntranining_fully_connected_layers:\\nCurrent sub-neural network has 1 hidden layers.\\n...\\nEpoch [1/50], Train Loss: 4.6210, Train_accuracy: 64.88462903798367, Val Loss: 1.9895, Val_accuracy: 64.60063897763578\\nModel saved.\\nEpoch [2/50], Train Loss: 4.5691, Train_accuracy: 60.922967696130634, Val Loss: 1.9719, Val_accuracy: 58.78594249201278\\nEpoch [3/50], Train Loss: 4.3050, Train_accuracy: 68.98828541001065, Val Loss: 1.8605, Val_accuracy: 68.64749733759318\\nModel saved.\\nEpoch [4/50], Train Loss: 4.0257, Train_accuracy: 71.60809371671992, Val Loss: 1.7493, Val_accuracy: 71.16080937167199\\nModel saved.\\nEpoch [5/50], Train Loss: 3.8266, Train_accuracy: 73.70962016329429, Val Loss: 1.6761, Val_accuracy: 72.65175718849841\\nModel saved.\\nEpoch [6/50], Train Loss: 3.6624, Train_accuracy: 75.39226127085551, Val Loss: 1.6109, Val_accuracy: 74.12140575079871\\nModel saved.\\nEpoch [7/50], Train Loss: 3.5206, Train_accuracy: 76.86900958466454, Val Loss: 1.5640, Val_accuracy: 75.33546325878594\\nModel saved.\\nEpoch [8/50], Train Loss: 3.4285, Train_accuracy: 76.87610933617323, Val Loss: 1.5346, Val_accuracy: 75.1863684771033\\nEpoch [9/50], Train Loss: 3.3300, Train_accuracy: 77.84877529286474, Val Loss: 1.5087, Val_accuracy: 75.91054313099042\\nModel saved.\\nEpoch [10/50], Train Loss: 3.2741, Train_accuracy: 77.89137380191693, Val Loss: 1.4946, Val_accuracy: 75.2076677316294\\nEpoch [11/50], Train Loss: 3.2055, Train_accuracy: 78.80014199503017, Val Loss: 1.4793, Val_accuracy: 75.91054313099042\\nEpoch [12/50], Train Loss: 3.1548, Train_accuracy: 78.91373801916933, Val Loss: 1.4703, Val_accuracy: 75.9531416400426\\nModel saved.\\nEpoch [13/50], Train Loss: 3.1191, Train_accuracy: 79.14802981895633, Val Loss: 1.4651, Val_accuracy: 75.97444089456869\\nModel saved.\\nEpoch [14/50], Train Loss: 3.0654, Train_accuracy: 79.58821441249556, Val Loss: 1.4558, Val_accuracy: 76.25133120340789\\nModel saved.\\nEpoch [15/50], Train Loss: 3.0203, Train_accuracy: 80.2555910543131, Val Loss: 1.4499, Val_accuracy: 76.35782747603834\\nModel saved.\\nEpoch [16/50], Train Loss: 2.9786, Train_accuracy: 80.61767838125665, Val Loss: 1.4439, Val_accuracy: 76.27263045793397\\nEpoch [17/50], Train Loss: 2.9311, Train_accuracy: 80.88746893858715, Val Loss: 1.4372, Val_accuracy: 76.40042598509052\\nModel saved.\\nEpoch [18/50], Train Loss: 2.8802, Train_accuracy: 81.40575079872204, Val Loss: 1.4283, Val_accuracy: 76.74121405750799\\nModel saved.\\nEpoch [19/50], Train Loss: 2.8299, Train_accuracy: 81.90983315583955, Val Loss: 1.4199, Val_accuracy: 77.18849840255591\\nModel saved.\\nEpoch [20/50], Train Loss: 2.7838, Train_accuracy: 82.22222222222223, Val Loss: 1.4122, Val_accuracy: 77.16719914802982\\nEpoch [21/50], Train Loss: 2.7374, Train_accuracy: 82.68370607028754, Val Loss: 1.4055, Val_accuracy: 77.33759318423856\\nModel saved.\\nEpoch [22/50], Train Loss: 2.6835, Train_accuracy: 83.10969116080938, Val Loss: 1.3960, Val_accuracy: 77.80617678381256\\nModel saved.\\nEpoch [23/50], Train Loss: 2.6302, Train_accuracy: 83.5285764998225, Val Loss: 1.3878, Val_accuracy: 77.84877529286474\\nModel saved.\\nEpoch [24/50], Train Loss: 2.5790, Train_accuracy: 84.06105786297479, Val Loss: 1.3790, Val_accuracy: 78.10436634717784\\nModel saved.\\nEpoch [25/50], Train Loss: 2.5350, Train_accuracy: 84.33794817181399, Val Loss: 1.3727, Val_accuracy: 78.04046858359958\\nEpoch [26/50], Train Loss: 2.4850, Train_accuracy: 84.73553425630102, Val Loss: 1.3651, Val_accuracy: 78.27476038338658\\nModel saved.\\nEpoch [27/50], Train Loss: 2.4300, Train_accuracy: 85.35321263755769, Val Loss: 1.3577, Val_accuracy: 78.82854100106496\\nModel saved.\\nEpoch [28/50], Train Loss: 2.3806, Train_accuracy: 85.79339723109692, Val Loss: 1.3476, Val_accuracy: 78.87113951011715\\nModel saved.\\nEpoch [29/50], Train Loss: 2.3315, Train_accuracy: 86.21938232161874, Val Loss: 1.3417, Val_accuracy: 79.12673056443025\\nModel saved.\\nEpoch [30/50], Train Loss: 2.2785, Train_accuracy: 86.53887113951012, Val Loss: 1.3324, Val_accuracy: 79.16932907348243\\nModel saved.\\nEpoch [31/50], Train Loss: 2.2246, Train_accuracy: 87.15654952076677, Val Loss: 1.3256, Val_accuracy: 79.70181043663472\\nModel saved.\\nEpoch [32/50], Train Loss: 2.1699, Train_accuracy: 87.63223287184948, Val Loss: 1.3145, Val_accuracy: 79.82960596379127\\nModel saved.\\nEpoch [33/50], Train Loss: 2.1151, Train_accuracy: 88.15761448349308, Val Loss: 1.3088, Val_accuracy: 80.19169329073482\\nModel saved.\\nEpoch [34/50], Train Loss: 2.0644, Train_accuracy: 88.48420305289315, Val Loss: 1.2996, Val_accuracy: 80.42598509052183\\nModel saved.\\nEpoch [35/50], Train Loss: 2.0143, Train_accuracy: 88.96698615548456, Val Loss: 1.2953, Val_accuracy: 80.59637912673057\\nModel saved.\\nEpoch [36/50], Train Loss: 1.9646, Train_accuracy: 89.32197373091942, Val Loss: 1.2905, Val_accuracy: 80.7454739084132\\nModel saved.\\nEpoch [37/50], Train Loss: 1.9174, Train_accuracy: 89.5917642882499, Val Loss: 1.2845, Val_accuracy: 80.89456869009585\\nModel saved.\\nEpoch [38/50], Train Loss: 1.8704, Train_accuracy: 90.06744763933263, Val Loss: 1.2783, Val_accuracy: 81.08626198083067\\nModel saved.\\nEpoch [39/50], Train Loss: 1.8236, Train_accuracy: 90.56443024494143, Val Loss: 1.2716, Val_accuracy: 81.10756123535677\\nModel saved.\\nEpoch [40/50], Train Loss: 1.7723, Train_accuracy: 90.94071707490238, Val Loss: 1.2662, Val_accuracy: 81.21405750798722\\nModel saved.\\nEpoch [41/50], Train Loss: 1.7257, Train_accuracy: 91.28150514731985, Val Loss: 1.2594, Val_accuracy: 81.29925452609159\\nModel saved.\\nEpoch [42/50], Train Loss: 1.6833, Train_accuracy: 91.62229321973732, Val Loss: 1.2554, Val_accuracy: 81.34185303514377\\nModel saved.\\nEpoch [43/50], Train Loss: 1.6423, Train_accuracy: 92.01277955271566, Val Loss: 1.2472, Val_accuracy: 81.57614483493077\\nModel saved.\\nEpoch [44/50], Train Loss: 1.6069, Train_accuracy: 92.39616613418531, Val Loss: 1.2423, Val_accuracy: 81.57614483493077\\nEpoch [45/50], Train Loss: 1.5758, Train_accuracy: 92.63045793397231, Val Loss: 1.2399, Val_accuracy: 81.40575079872204\\nEpoch [46/50], Train Loss: 1.5598, Train_accuracy: 92.60915867944622, Val Loss: 1.2439, Val_accuracy: 81.55484558040469\\nEpoch [47/50], Train Loss: 1.5426, Train_accuracy: 92.72275470358538, Val Loss: 1.2458, Val_accuracy: 81.66134185303514\\nModel saved.\\nEpoch [48/50], Train Loss: 1.4597, Train_accuracy: 93.48242811501598, Val Loss: 1.2334, Val_accuracy: 82.0021299254526\\nModel saved.\\nEpoch [49/50], Train Loss: 1.4162, Train_accuracy: 93.6812211572595, Val Loss: 1.2430, Val_accuracy: 82.08732694355697\\nModel saved.\\nEpoch [50/50], Train Loss: 1.3774, Train_accuracy: 93.81611643592474, Val Loss: 1.2320, Val_accuracy: 82.2790202342918\\nModel saved.\\nTest Accucary 82.9855195911414\\nCurrent sub-neural network has 2 hidden layers.\\n...\\nEpoch [1/50], Train Loss: 4.5556, Train_accuracy: 66.29037983670571, Val Loss: 1.9587, Val_accuracy: 65.89989350372737\\nModel saved.\\nEpoch [2/50], Train Loss: 4.0714, Train_accuracy: 70.83422080227191, Val Loss: 1.7657, Val_accuracy: 69.71246006389777\\nModel saved.\\nEpoch [3/50], Train Loss: 3.7325, Train_accuracy: 74.4408945686901, Val Loss: 1.6320, Val_accuracy: 73.71671991480298\\nModel saved.\\nEpoch [4/50], Train Loss: 3.8049, Train_accuracy: 71.77138800141995, Val Loss: 1.6654, Val_accuracy: 71.395101171459\\nEpoch [5/50], Train Loss: 3.5269, Train_accuracy: 76.85481008164714, Val Loss: 1.5748, Val_accuracy: 74.90947816826412\\nModel saved.\\nEpoch [6/50], Train Loss: 3.4262, Train_accuracy: 76.13773517926873, Val Loss: 1.5398, Val_accuracy: 74.37699680511182\\nEpoch [7/50], Train Loss: 3.2149, Train_accuracy: 78.87823926162584, Val Loss: 1.4787, Val_accuracy: 76.42172523961662\\nModel saved.\\nEpoch [8/50], Train Loss: 3.0902, Train_accuracy: 79.78700745473908, Val Loss: 1.4534, Val_accuracy: 76.65601703940362\\nModel saved.\\nEpoch [9/50], Train Loss: 2.9683, Train_accuracy: 80.69577564785233, Val Loss: 1.4276, Val_accuracy: 77.08200212992546\\nModel saved.\\nEpoch [10/50], Train Loss: 3.0325, Train_accuracy: 79.22612708555201, Val Loss: 1.4712, Val_accuracy: 75.6975505857295\\nEpoch [11/50], Train Loss: 2.8118, Train_accuracy: 81.782037628683, Val Loss: 1.4083, Val_accuracy: 77.27369542066027\\nModel saved.\\nEpoch [12/50], Train Loss: 2.6737, Train_accuracy: 83.0315938942137, Val Loss: 1.3935, Val_accuracy: 77.84877529286474\\nModel saved.\\nEpoch [13/50], Train Loss: 2.5388, Train_accuracy: 83.87646432374866, Val Loss: 1.3742, Val_accuracy: 77.80617678381256\\nEpoch [14/50], Train Loss: 2.5451, Train_accuracy: 83.74866879659211, Val Loss: 1.4461, Val_accuracy: 77.63578274760384\\nEpoch [15/50], Train Loss: 2.4772, Train_accuracy: 84.28115015974441, Val Loss: 1.4593, Val_accuracy: 77.76357827476038\\nEpoch [16/50], Train Loss: 2.1487, Train_accuracy: 87.15654952076677, Val Loss: 1.3486, Val_accuracy: 79.42492012779553\\nModel saved.\\nEpoch [17/50], Train Loss: 2.3693, Train_accuracy: 84.84203052893149, Val Loss: 1.5293, Val_accuracy: 77.48668796592119\\nEpoch [18/50], Train Loss: 1.9736, Train_accuracy: 88.24281150159744, Val Loss: 1.3450, Val_accuracy: 79.40362087326943\\nEpoch [19/50], Train Loss: 2.0654, Train_accuracy: 86.91515796947107, Val Loss: 1.4941, Val_accuracy: 78.08306709265176\\nEpoch [20/50], Train Loss: 1.6854, Train_accuracy: 90.4082357117501, Val Loss: 1.3379, Val_accuracy: 80.29818956336528\\nModel saved.\\nEpoch [21/50], Train Loss: 1.7554, Train_accuracy: 89.30067447639333, Val Loss: 1.4612, Val_accuracy: 79.57401490947817\\nEpoch [22/50], Train Loss: 2.2448, Train_accuracy: 84.89882854100107, Val Loss: 1.7833, Val_accuracy: 75.97444089456869\\nEpoch [23/50], Train Loss: 1.4986, Train_accuracy: 91.68619098331558, Val Loss: 1.3371, Val_accuracy: 80.7667731629393\\nModel saved.\\nEpoch [24/50], Train Loss: 1.3662, Train_accuracy: 92.55236066737665, Val Loss: 1.3865, Val_accuracy: 81.42705005324814\\nModel saved.\\nEpoch [25/50], Train Loss: 1.2179, Train_accuracy: 93.95101171459, Val Loss: 1.3539, Val_accuracy: 81.59744408945687\\nModel saved.\\nEpoch [26/50], Train Loss: 1.1475, Train_accuracy: 94.46929357472489, Val Loss: 1.4023, Val_accuracy: 81.5122470713525\\nEpoch [27/50], Train Loss: 1.0263, Train_accuracy: 95.27156549520767, Val Loss: 1.3474, Val_accuracy: 81.29925452609159\\nEpoch [28/50], Train Loss: 1.0871, Train_accuracy: 94.81718139865104, Val Loss: 1.4635, Val_accuracy: 81.27795527156549\\nEpoch [29/50], Train Loss: 0.9089, Train_accuracy: 96.17323393681221, Val Loss: 1.3997, Val_accuracy: 81.95953141640042\\nModel saved.\\nEpoch [30/50], Train Loss: 0.9571, Train_accuracy: 95.26446574369898, Val Loss: 1.3852, Val_accuracy: 81.4909478168264\\nEpoch [31/50], Train Loss: 0.8770, Train_accuracy: 96.16613418530352, Val Loss: 1.3802, Val_accuracy: 81.42705005324814\\nEpoch [32/50], Train Loss: 1.5414, Train_accuracy: 89.81185658501953, Val Loss: 1.8180, Val_accuracy: 78.14696485623003\\nEpoch [33/50], Train Loss: 0.9600, Train_accuracy: 94.90947816826412, Val Loss: 1.5433, Val_accuracy: 81.06496272630459\\nEpoch [34/50], Train Loss: 0.8322, Train_accuracy: 95.81824636137735, Val Loss: 1.5359, Val_accuracy: 81.72523961661342\\nEpoch [35/50], Train Loss: 0.7829, Train_accuracy: 96.30812921547746, Val Loss: 1.4559, Val_accuracy: 82.0021299254526\\nModel saved.\\nEpoch [36/50], Train Loss: 2.0884, Train_accuracy: 85.21831735889243, Val Loss: 2.0550, Val_accuracy: 74.88817891373802\\nEpoch [37/50], Train Loss: 0.9603, Train_accuracy: 96.15193468228613, Val Loss: 1.3434, Val_accuracy: 82.0021299254526\\nEpoch [38/50], Train Loss: 0.9704, Train_accuracy: 95.25026624068158, Val Loss: 1.3962, Val_accuracy: 82.19382321618744\\nModel saved.\\nEpoch [39/50], Train Loss: 1.0075, Train_accuracy: 94.41249556265531, Val Loss: 1.4389, Val_accuracy: 81.42705005324814\\nEpoch [40/50], Train Loss: 0.7266, Train_accuracy: 96.86900958466454, Val Loss: 1.4358, Val_accuracy: 82.57720979765708\\nModel saved.\\nEpoch [41/50], Train Loss: 0.6912, Train_accuracy: 96.87610933617323, Val Loss: 1.4817, Val_accuracy: 82.19382321618744\\nEpoch [42/50], Train Loss: 0.6298, Train_accuracy: 97.33049343272985, Val Loss: 1.4453, Val_accuracy: 82.61980830670926\\nModel saved.\\nEpoch [43/50], Train Loss: 0.5238, Train_accuracy: 98.2037628682996, Val Loss: 1.5172, Val_accuracy: 82.89669861554846\\nModel saved.\\nEpoch [44/50], Train Loss: 0.5181, Train_accuracy: 98.00496982605608, Val Loss: 1.5275, Val_accuracy: 82.74760383386581\\nEpoch [45/50], Train Loss: 0.4349, Train_accuracy: 98.55875044373447, Val Loss: 1.5239, Val_accuracy: 82.68370607028754\\nEpoch [46/50], Train Loss: 0.3940, Train_accuracy: 98.69364572239972, Val Loss: 1.5715, Val_accuracy: 82.98189563365283\\nModel saved.\\nEpoch [47/50], Train Loss: 0.3642, Train_accuracy: 98.84274050408236, Val Loss: 1.5971, Val_accuracy: 83.06709265175719\\nModel saved.\\nEpoch [48/50], Train Loss: 0.3388, Train_accuracy: 98.99183528576499, Val Loss: 1.6065, Val_accuracy: 83.0457933972311\\nEpoch [49/50], Train Loss: 0.3060, Train_accuracy: 99.20482783102591, Val Loss: 1.6361, Val_accuracy: 83.00319488817891\\nEpoch [50/50], Train Loss: 0.2812, Train_accuracy: 99.31842385516507, Val Loss: 1.6545, Val_accuracy: 82.96059637912673\\nTest Accucary 84.45485519591142\\nCurrent sub-neural network has 3 hidden layers.\\n...\\nEpoch [1/50], Train Loss: 4.3329, Train_accuracy: 69.42137025204117, Val Loss: 1.8657, Val_accuracy: 68.604898828541\\nModel saved.\\nEpoch [2/50], Train Loss: 4.0272, Train_accuracy: 70.69932552360667, Val Loss: 1.7402, Val_accuracy: 70.1384451544196\\nModel saved.\\nEpoch [3/50], Train Loss: 3.7149, Train_accuracy: 75.11537096201633, Val Loss: 1.6274, Val_accuracy: 73.61022364217253\\nModel saved.\\nEpoch [4/50], Train Loss: 3.5001, Train_accuracy: 76.86190983315583, Val Loss: 1.5486, Val_accuracy: 75.10117145899893\\nModel saved.\\nEpoch [5/50], Train Loss: 3.5839, Train_accuracy: 74.32729854455094, Val Loss: 1.5883, Val_accuracy: 72.99254526091586\\nEpoch [6/50], Train Loss: 3.3033, Train_accuracy: 78.38125665601704, Val Loss: 1.5039, Val_accuracy: 75.91054313099042\\nModel saved.\\nEpoch [7/50], Train Loss: 3.1567, Train_accuracy: 79.55981540646077, Val Loss: 1.4629, Val_accuracy: 76.4643237486688\\nModel saved.\\nEpoch [8/50], Train Loss: 3.1582, Train_accuracy: 78.78594249201278, Val Loss: 1.4788, Val_accuracy: 75.6762513312034\\nEpoch [9/50], Train Loss: 3.0497, Train_accuracy: 79.765708200213, Val Loss: 1.4595, Val_accuracy: 75.6975505857295\\nEpoch [10/50], Train Loss: 2.8560, Train_accuracy: 81.46964856230032, Val Loss: 1.4126, Val_accuracy: 76.76251331203407\\nModel saved.\\nEpoch [11/50], Train Loss: 2.7653, Train_accuracy: 82.25062122825702, Val Loss: 1.4041, Val_accuracy: 77.01810436634717\\nModel saved.\\nEpoch [12/50], Train Loss: 2.6171, Train_accuracy: 83.50727724529642, Val Loss: 1.3810, Val_accuracy: 77.95527156549521\\nModel saved.\\nEpoch [13/50], Train Loss: 2.4745, Train_accuracy: 84.67163649272275, Val Loss: 1.3684, Val_accuracy: 78.10436634717784\\nModel saved.\\nEpoch [14/50], Train Loss: 2.4620, Train_accuracy: 84.3237486687966, Val Loss: 1.4155, Val_accuracy: 78.04046858359958\\nEpoch [15/50], Train Loss: 2.2132, Train_accuracy: 86.53177138800142, Val Loss: 1.3624, Val_accuracy: 78.9776357827476\\nModel saved.\\nEpoch [16/50], Train Loss: 2.3314, Train_accuracy: 85.28221512247072, Val Loss: 1.4796, Val_accuracy: 77.27369542066027\\nEpoch [17/50], Train Loss: 1.9310, Train_accuracy: 88.54810081647142, Val Loss: 1.3387, Val_accuracy: 79.70181043663472\\nModel saved.\\nEpoch [18/50], Train Loss: 1.8111, Train_accuracy: 89.30777422790203, Val Loss: 1.3459, Val_accuracy: 80.234291799787\\nModel saved.\\nEpoch [19/50], Train Loss: 2.0501, Train_accuracy: 86.99325523606674, Val Loss: 1.5568, Val_accuracy: 77.87007454739084\\nEpoch [20/50], Train Loss: 1.6042, Train_accuracy: 90.96201632942847, Val Loss: 1.3233, Val_accuracy: 80.63897763578275\\nModel saved.\\nEpoch [21/50], Train Loss: 1.6596, Train_accuracy: 89.93965211217608, Val Loss: 1.4485, Val_accuracy: 79.68051118210863\\nEpoch [22/50], Train Loss: 1.4726, Train_accuracy: 91.57969471068513, Val Loss: 1.3769, Val_accuracy: 81.0223642172524\\nModel saved.\\nEpoch [23/50], Train Loss: 1.4193, Train_accuracy: 91.8849840255591, Val Loss: 1.4393, Val_accuracy: 80.29818956336528\\nEpoch [24/50], Train Loss: 1.1489, Train_accuracy: 94.29179978700745, Val Loss: 1.3353, Val_accuracy: 81.7465388711395\\nModel saved.\\nEpoch [25/50], Train Loss: 1.0869, Train_accuracy: 94.51189208377707, Val Loss: 1.3781, Val_accuracy: 81.57614483493077\\nEpoch [26/50], Train Loss: 2.4179, Train_accuracy: 83.2729854455094, Val Loss: 1.9857, Val_accuracy: 74.58998935037273\\nEpoch [27/50], Train Loss: 1.2761, Train_accuracy: 93.1487397941072, Val Loss: 1.3837, Val_accuracy: 81.15015974440895\\nEpoch [28/50], Train Loss: 1.0431, Train_accuracy: 94.83848065317714, Val Loss: 1.3325, Val_accuracy: 82.04472843450479\\nModel saved.\\nEpoch [29/50], Train Loss: 0.9421, Train_accuracy: 95.35676251331203, Val Loss: 1.3453, Val_accuracy: 82.34291799787007\\nModel saved.\\nEpoch [30/50], Train Loss: 0.9929, Train_accuracy: 95.09407170749024, Val Loss: 1.3537, Val_accuracy: 82.25772097976571\\nEpoch [31/50], Train Loss: 1.9400, Train_accuracy: 86.50337238196663, Val Loss: 1.7865, Val_accuracy: 75.91054313099042\\nEpoch [32/50], Train Loss: 1.1371, Train_accuracy: 94.53319133830315, Val Loss: 1.3105, Val_accuracy: 81.42705005324814\\nEpoch [33/50], Train Loss: 1.0529, Train_accuracy: 94.58288959886404, Val Loss: 1.3659, Val_accuracy: 82.10862619808307\\nEpoch [34/50], Train Loss: 1.2299, Train_accuracy: 92.55946041888534, Val Loss: 1.4829, Val_accuracy: 80.61767838125665\\nEpoch [35/50], Train Loss: 0.9645, Train_accuracy: 95.12247071352503, Val Loss: 1.3835, Val_accuracy: 81.93823216187434\\nEpoch [36/50], Train Loss: 0.9028, Train_accuracy: 95.52715654952077, Val Loss: 1.4244, Val_accuracy: 81.89563365282216\\nEpoch [37/50], Train Loss: 0.7655, Train_accuracy: 96.31522896698615, Val Loss: 1.4147, Val_accuracy: 82.790202342918\\nModel saved.\\nEpoch [38/50], Train Loss: 0.7352, Train_accuracy: 96.32232871849486, Val Loss: 1.4818, Val_accuracy: 82.93929712460064\\nModel saved.\\nEpoch [39/50], Train Loss: 0.5950, Train_accuracy: 97.61448349307774, Val Loss: 1.4698, Val_accuracy: 82.91799787007454\\nEpoch [40/50], Train Loss: 0.5457, Train_accuracy: 97.74227902023429, Val Loss: 1.5428, Val_accuracy: 83.00319488817891\\nModel saved.\\nEpoch [41/50], Train Loss: 0.4749, Train_accuracy: 98.2534611288605, Val Loss: 1.5607, Val_accuracy: 83.25878594249201\\nModel saved.\\nEpoch [42/50], Train Loss: 0.4302, Train_accuracy: 98.38835640752573, Val Loss: 1.5682, Val_accuracy: 83.51437699680511\\nModel saved.\\nEpoch [43/50], Train Loss: 0.4067, Train_accuracy: 98.50195243166489, Val Loss: 1.6020, Val_accuracy: 83.36528221512248\\nEpoch [44/50], Train Loss: 0.3770, Train_accuracy: 98.66524671636493, Val Loss: 1.6146, Val_accuracy: 83.42917997870074\\nEpoch [45/50], Train Loss: 0.3389, Train_accuracy: 98.91373801916933, Val Loss: 1.6550, Val_accuracy: 83.49307774227903\\nEpoch [46/50], Train Loss: 0.2879, Train_accuracy: 99.18352857649982, Val Loss: 1.6779, Val_accuracy: 83.72736954206603\\nModel saved.\\nEpoch [47/50], Train Loss: 0.2519, Train_accuracy: 99.32552360667377, Val Loss: 1.7410, Val_accuracy: 83.15228966986156\\nEpoch [48/50], Train Loss: 0.2562, Train_accuracy: 99.31842385516507, Val Loss: 1.8223, Val_accuracy: 82.83280085197018\\nEpoch [49/50], Train Loss: 0.4500, Train_accuracy: 97.76357827476038, Val Loss: 2.1264, Val_accuracy: 81.2566560170394\\nEpoch [50/50], Train Loss: 0.4741, Train_accuracy: 97.64288249911253, Val Loss: 2.0679, Val_accuracy: 80.93716719914804\\nTest Accucary 82.28279386712096\\n', stderr=b'/home/anwer/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\\n  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\\n\\r  0%|          | 0/50 [00:00<?, ?it/s]\\r  2%|\\xe2\\x96\\x8f         | 1/50 [00:00<00:18,  2.66it/s]\\r  4%|\\xe2\\x96\\x8d         | 2/50 [00:00<00:18,  2.53it/s]\\r  6%|\\xe2\\x96\\x8c         | 3/50 [00:01<00:18,  2.54it/s]\\r  8%|\\xe2\\x96\\x8a         | 4/50 [00:01<00:18,  2.52it/s]\\r 10%|\\xe2\\x96\\x88         | 5/50 [00:01<00:17,  2.53it/s]\\r 12%|\\xe2\\x96\\x88\\xe2\\x96\\x8f        | 6/50 [00:02<00:17,  2.52it/s]\\r 14%|\\xe2\\x96\\x88\\xe2\\x96\\x8d        | 7/50 [00:02<00:17,  2.51it/s]\\r 16%|\\xe2\\x96\\x88\\xe2\\x96\\x8c        | 8/50 [00:03<00:16,  2.51it/s]\\r 18%|\\xe2\\x96\\x88\\xe2\\x96\\x8a        | 9/50 [00:03<00:16,  2.53it/s]\\r 20%|\\xe2\\x96\\x88\\xe2\\x96\\x88        | 10/50 [00:03<00:14,  2.69it/s]\\r 22%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f       | 11/50 [00:04<00:14,  2.64it/s]\\r 24%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d       | 12/50 [00:04<00:14,  2.60it/s]\\r 26%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c       | 13/50 [00:05<00:14,  2.60it/s]\\r 28%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a       | 14/50 [00:05<00:13,  2.59it/s]\\r 30%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88       | 15/50 [00:05<00:13,  2.60it/s]\\r 32%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f      | 16/50 [00:06<00:13,  2.59it/s]\\r 34%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d      | 17/50 [00:06<00:12,  2.58it/s]\\r 36%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c      | 18/50 [00:06<00:12,  2.57it/s]\\r 38%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a      | 19/50 [00:07<00:12,  2.57it/s]\\r 40%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88      | 20/50 [00:07<00:11,  2.56it/s]\\r 42%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f     | 21/50 [00:08<00:11,  2.56it/s]\\r 44%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d     | 22/50 [00:08<00:11,  2.54it/s]\\r 46%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c     | 23/50 [00:08<00:10,  2.53it/s]\\r 48%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a     | 24/50 [00:09<00:10,  2.51it/s]\\r 50%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88     | 25/50 [00:09<00:09,  2.50it/s]\\r 52%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f    | 26/50 [00:10<00:09,  2.51it/s]\\r 54%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d    | 27/50 [00:10<00:09,  2.53it/s]\\r 56%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c    | 28/50 [00:10<00:08,  2.68it/s]\\r 58%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a    | 29/50 [00:11<00:07,  2.65it/s]\\r 60%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88    | 30/50 [00:11<00:07,  2.63it/s]\\r 62%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f   | 31/50 [00:12<00:07,  2.61it/s]\\r 64%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d   | 32/50 [00:12<00:06,  2.60it/s]\\r 66%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c   | 33/50 [00:12<00:06,  2.58it/s]\\r 68%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a   | 34/50 [00:13<00:06,  2.56it/s]\\r 70%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88   | 35/50 [00:13<00:05,  2.54it/s]\\r 72%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f  | 36/50 [00:14<00:05,  2.53it/s]\\r 74%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d  | 37/50 [00:14<00:05,  2.53it/s]\\r 76%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c  | 38/50 [00:14<00:04,  2.52it/s]\\r 78%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a  | 39/50 [00:15<00:04,  2.50it/s]\\r 80%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88  | 40/50 [00:15<00:04,  2.48it/s]\\r 82%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f | 41/50 [00:16<00:03,  2.47it/s]\\r 84%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d | 42/50 [00:16<00:03,  2.47it/s]\\r 86%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c | 43/50 [00:16<00:02,  2.47it/s]\\r 88%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a | 44/50 [00:17<00:02,  2.47it/s]\\r 90%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88 | 45/50 [00:17<00:02,  2.47it/s]\\r 92%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f| 46/50 [00:18<00:01,  2.60it/s]\\r 94%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d| 47/50 [00:18<00:01,  2.57it/s]\\r 96%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c| 48/50 [00:18<00:00,  2.54it/s]\\r 98%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a| 49/50 [00:19<00:00,  2.54it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:19<00:00,  2.54it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:19<00:00,  2.55it/s]\\n\\r  0%|          | 0/50 [00:00<?, ?it/s]\\r  2%|\\xe2\\x96\\x8f         | 1/50 [00:00<00:20,  2.45it/s]\\r  4%|\\xe2\\x96\\x8d         | 2/50 [00:00<00:20,  2.38it/s]\\r  6%|\\xe2\\x96\\x8c         | 3/50 [00:01<00:19,  2.37it/s]\\r  8%|\\xe2\\x96\\x8a         | 4/50 [00:01<00:19,  2.36it/s]\\r 10%|\\xe2\\x96\\x88         | 5/50 [00:02<00:19,  2.36it/s]\\r 12%|\\xe2\\x96\\x88\\xe2\\x96\\x8f        | 6/50 [00:02<00:18,  2.35it/s]\\r 14%|\\xe2\\x96\\x88\\xe2\\x96\\x8d        | 7/50 [00:02<00:17,  2.50it/s]\\r 16%|\\xe2\\x96\\x88\\xe2\\x96\\x8c        | 8/50 [00:03<00:17,  2.46it/s]\\r 18%|\\xe2\\x96\\x88\\xe2\\x96\\x8a        | 9/50 [00:03<00:16,  2.44it/s]\\r 20%|\\xe2\\x96\\x88\\xe2\\x96\\x88        | 10/50 [00:04<00:16,  2.42it/s]\\r 22%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f       | 11/50 [00:04<00:16,  2.40it/s]\\r 24%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d       | 12/50 [00:04<00:15,  2.42it/s]\\r 26%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c       | 13/50 [00:05<00:15,  2.41it/s]\\r 28%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a       | 14/50 [00:05<00:15,  2.39it/s]\\r 30%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88       | 15/50 [00:06<00:14,  2.41it/s]\\r 32%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f      | 16/50 [00:06<00:14,  2.40it/s]\\r 34%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d      | 17/50 [00:07<00:13,  2.41it/s]\\r 36%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c      | 18/50 [00:07<00:13,  2.42it/s]\\r 38%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a      | 19/50 [00:07<00:12,  2.56it/s]\\r 40%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88      | 20/50 [00:08<00:11,  2.52it/s]\\r 42%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f     | 21/50 [00:08<00:11,  2.48it/s]\\r 44%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d     | 22/50 [00:09<00:11,  2.45it/s]\\r 46%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c     | 23/50 [00:09<00:11,  2.43it/s]\\r 48%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a     | 24/50 [00:09<00:10,  2.41it/s]\\r 50%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88     | 25/50 [00:10<00:10,  2.40it/s]\\r 52%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f    | 26/50 [00:10<00:10,  2.40it/s]\\r 54%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d    | 27/50 [00:11<00:09,  2.38it/s]\\r 56%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c    | 28/50 [00:11<00:09,  2.37it/s]\\r 58%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a    | 29/50 [00:12<00:08,  2.38it/s]\\r 60%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88    | 30/50 [00:12<00:08,  2.38it/s]\\r 62%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f   | 31/50 [00:12<00:07,  2.52it/s]\\r 64%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d   | 32/50 [00:13<00:07,  2.49it/s]\\r 66%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c   | 33/50 [00:13<00:06,  2.47it/s]\\r 68%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a   | 34/50 [00:14<00:06,  2.45it/s]\\r 70%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88   | 35/50 [00:14<00:06,  2.43it/s]\\r 72%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f  | 36/50 [00:14<00:05,  2.42it/s]\\r 74%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d  | 37/50 [00:15<00:05,  2.42it/s]\\r 76%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c  | 38/50 [00:15<00:04,  2.41it/s]\\r 78%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a  | 39/50 [00:16<00:04,  2.39it/s]\\r 80%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88  | 40/50 [00:16<00:04,  2.36it/s]\\r 82%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f | 41/50 [00:16<00:03,  2.37it/s]\\r 84%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d | 42/50 [00:17<00:03,  2.37it/s]\\r 86%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c | 43/50 [00:17<00:02,  2.50it/s]\\r 88%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a | 44/50 [00:18<00:02,  2.47it/s]\\r 90%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88 | 45/50 [00:18<00:02,  2.44it/s]\\r 92%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f| 46/50 [00:18<00:01,  2.42it/s]\\r 94%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d| 47/50 [00:19<00:01,  2.42it/s]\\r 96%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c| 48/50 [00:19<00:00,  2.41it/s]\\r 98%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a| 49/50 [00:20<00:00,  2.39it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.39it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.42it/s]\\n\\r  0%|          | 0/50 [00:00<?, ?it/s]\\r  2%|\\xe2\\x96\\x8f         | 1/50 [00:00<00:16,  2.94it/s]\\r  4%|\\xe2\\x96\\x8d         | 2/50 [00:00<00:18,  2.57it/s]\\r  6%|\\xe2\\x96\\x8c         | 3/50 [00:01<00:18,  2.48it/s]\\r  8%|\\xe2\\x96\\x8a         | 4/50 [00:01<00:18,  2.43it/s]\\r 10%|\\xe2\\x96\\x88         | 5/50 [00:02<00:18,  2.41it/s]\\r 12%|\\xe2\\x96\\x88\\xe2\\x96\\x8f        | 6/50 [00:02<00:18,  2.42it/s]\\r 14%|\\xe2\\x96\\x88\\xe2\\x96\\x8d        | 7/50 [00:02<00:17,  2.41it/s]\\r 16%|\\xe2\\x96\\x88\\xe2\\x96\\x8c        | 8/50 [00:03<00:17,  2.39it/s]\\r 18%|\\xe2\\x96\\x88\\xe2\\x96\\x8a        | 9/50 [00:03<00:17,  2.39it/s]\\r 20%|\\xe2\\x96\\x88\\xe2\\x96\\x88        | 10/50 [00:04<00:16,  2.37it/s]\\r 22%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f       | 11/50 [00:04<00:16,  2.35it/s]\\r 24%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d       | 12/50 [00:04<00:16,  2.36it/s]\\r 26%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c       | 13/50 [00:05<00:15,  2.36it/s]\\r 28%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a       | 14/50 [00:05<00:14,  2.51it/s]\\r 30%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88       | 15/50 [00:06<00:14,  2.46it/s]\\r 32%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f      | 16/50 [00:06<00:14,  2.42it/s]\\r 34%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d      | 17/50 [00:07<00:13,  2.40it/s]\\r 36%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c      | 18/50 [00:07<00:13,  2.40it/s]\\r 38%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a      | 19/50 [00:07<00:13,  2.38it/s]\\r 40%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88      | 20/50 [00:08<00:12,  2.37it/s]\\r 42%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f     | 21/50 [00:08<00:12,  2.37it/s]\\r 44%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d     | 22/50 [00:09<00:11,  2.37it/s]\\r 46%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c     | 23/50 [00:09<00:11,  2.36it/s]\\r 48%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a     | 24/50 [00:09<00:11,  2.36it/s]\\r 50%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88     | 25/50 [00:10<00:10,  2.35it/s]\\r 52%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f    | 26/50 [00:10<00:10,  2.34it/s]\\r 54%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d    | 27/50 [00:11<00:09,  2.34it/s]\\r 56%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c    | 28/50 [00:11<00:09,  2.34it/s]\\r 58%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a    | 29/50 [00:12<00:08,  2.48it/s]\\r 60%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88    | 30/50 [00:12<00:08,  2.44it/s]\\r 62%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f   | 31/50 [00:12<00:07,  2.41it/s]\\r 64%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d   | 32/50 [00:13<00:07,  2.38it/s]\\r 66%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c   | 33/50 [00:13<00:07,  2.37it/s]\\r 68%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a   | 34/50 [00:14<00:06,  2.36it/s]\\r 70%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88   | 35/50 [00:14<00:06,  2.36it/s]\\r 72%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f  | 36/50 [00:15<00:05,  2.37it/s]\\r 74%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d  | 37/50 [00:15<00:05,  2.39it/s]\\r 76%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c  | 38/50 [00:15<00:05,  2.40it/s]\\r 78%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a  | 39/50 [00:16<00:04,  2.39it/s]\\r 80%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88  | 40/50 [00:16<00:04,  2.38it/s]\\r 82%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f | 41/50 [00:17<00:03,  2.37it/s]\\r 84%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d | 42/50 [00:17<00:03,  2.35it/s]\\r 86%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c | 43/50 [00:17<00:02,  2.37it/s]\\r 88%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a | 44/50 [00:18<00:02,  2.50it/s]\\r 90%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88 | 45/50 [00:18<00:02,  2.45it/s]\\r 92%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f| 46/50 [00:19<00:01,  2.44it/s]\\r 94%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d| 47/50 [00:19<00:01,  2.43it/s]\\r 96%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c| 48/50 [00:19<00:00,  2.42it/s]\\r 98%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a| 49/50 [00:20<00:00,  2.40it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.40it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.40it/s]\\n\\r  0%|          | 0/50 [00:00<?, ?it/s]\\r  2%|\\xe2\\x96\\x8f         | 1/50 [00:00<00:19,  2.54it/s]\\r  4%|\\xe2\\x96\\x8d         | 2/50 [00:00<00:19,  2.47it/s]\\r  6%|\\xe2\\x96\\x8c         | 3/50 [00:01<00:19,  2.46it/s]\\r  8%|\\xe2\\x96\\x8a         | 4/50 [00:01<00:18,  2.46it/s]\\r 10%|\\xe2\\x96\\x88         | 5/50 [00:02<00:18,  2.46it/s]\\r 12%|\\xe2\\x96\\x88\\xe2\\x96\\x8f        | 6/50 [00:02<00:16,  2.62it/s]\\r 14%|\\xe2\\x96\\x88\\xe2\\x96\\x8d        | 7/50 [00:02<00:16,  2.55it/s]\\r 16%|\\xe2\\x96\\x88\\xe2\\x96\\x8c        | 8/50 [00:03<00:16,  2.52it/s]\\r 18%|\\xe2\\x96\\x88\\xe2\\x96\\x8a        | 9/50 [00:03<00:16,  2.48it/s]\\r 20%|\\xe2\\x96\\x88\\xe2\\x96\\x88        | 10/50 [00:04<00:16,  2.46it/s]\\r 22%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f       | 11/50 [00:04<00:15,  2.45it/s]\\r 24%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d       | 12/50 [00:04<00:15,  2.44it/s]\\r 26%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c       | 13/50 [00:05<00:15,  2.44it/s]\\r 28%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a       | 14/50 [00:05<00:14,  2.43it/s]\\r 30%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88       | 15/50 [00:06<00:14,  2.41it/s]\\r 32%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f      | 16/50 [00:06<00:13,  2.43it/s]\\r 34%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d      | 17/50 [00:06<00:13,  2.43it/s]\\r 36%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c      | 18/50 [00:07<00:12,  2.58it/s]\\r 38%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a      | 19/50 [00:07<00:12,  2.54it/s]\\r 40%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88      | 20/50 [00:08<00:11,  2.51it/s]\\r 42%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f     | 21/50 [00:08<00:11,  2.46it/s]\\r 44%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d     | 22/50 [00:08<00:11,  2.41it/s]\\r 46%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c     | 23/50 [00:09<00:11,  2.37it/s]\\r 48%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a     | 24/50 [00:09<00:11,  2.35it/s]\\r 50%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88     | 25/50 [00:10<00:10,  2.34it/s]\\r 52%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f    | 26/50 [00:10<00:10,  2.33it/s]\\r 54%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d    | 27/50 [00:11<00:09,  2.34it/s]\\r 56%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c    | 28/50 [00:11<00:09,  2.36it/s]\\r 58%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a    | 29/50 [00:11<00:08,  2.38it/s]\\r 60%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88    | 30/50 [00:12<00:07,  2.54it/s]\\r 62%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f   | 31/50 [00:12<00:07,  2.50it/s]\\r 64%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d   | 32/50 [00:13<00:07,  2.48it/s]\\r 66%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c   | 33/50 [00:13<00:06,  2.47it/s]\\r 68%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a   | 34/50 [00:13<00:06,  2.45it/s]\\r 70%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88   | 35/50 [00:14<00:06,  2.45it/s]\\r 72%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f  | 36/50 [00:14<00:05,  2.44it/s]\\r 74%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d  | 37/50 [00:15<00:05,  2.44it/s]\\r 76%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c  | 38/50 [00:15<00:04,  2.43it/s]\\r 78%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a  | 39/50 [00:15<00:04,  2.42it/s]\\r 80%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88  | 40/50 [00:16<00:04,  2.43it/s]\\r 82%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f | 41/50 [00:16<00:03,  2.43it/s]\\r 84%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d | 42/50 [00:17<00:03,  2.59it/s]\\r 86%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c | 43/50 [00:17<00:02,  2.54it/s]\\r 88%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a | 44/50 [00:17<00:02,  2.52it/s]\\r 90%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88 | 45/50 [00:18<00:01,  2.50it/s]\\r 92%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f| 46/50 [00:18<00:01,  2.49it/s]\\r 94%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d| 47/50 [00:19<00:01,  2.47it/s]\\r 96%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c| 48/50 [00:19<00:00,  2.46it/s]\\r 98%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a| 49/50 [00:19<00:00,  2.46it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.46it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.46it/s]\\n\\r  0%|          | 0/50 [00:00<?, ?it/s]\\r  2%|\\xe2\\x96\\x8f         | 1/50 [00:00<00:16,  3.04it/s]\\r  4%|\\xe2\\x96\\x8d         | 2/50 [00:00<00:18,  2.61it/s]\\r  6%|\\xe2\\x96\\x8c         | 3/50 [00:01<00:18,  2.53it/s]\\r  8%|\\xe2\\x96\\x8a         | 4/50 [00:01<00:18,  2.48it/s]\\r 10%|\\xe2\\x96\\x88         | 5/50 [00:01<00:18,  2.45it/s]\\r 12%|\\xe2\\x96\\x88\\xe2\\x96\\x8f        | 6/50 [00:02<00:18,  2.44it/s]\\r 14%|\\xe2\\x96\\x88\\xe2\\x96\\x8d        | 7/50 [00:02<00:17,  2.43it/s]\\r 16%|\\xe2\\x96\\x88\\xe2\\x96\\x8c        | 8/50 [00:03<00:17,  2.41it/s]\\r 18%|\\xe2\\x96\\x88\\xe2\\x96\\x8a        | 9/50 [00:03<00:17,  2.40it/s]\\r 20%|\\xe2\\x96\\x88\\xe2\\x96\\x88        | 10/50 [00:04<00:16,  2.39it/s]\\r 22%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f       | 11/50 [00:04<00:16,  2.38it/s]\\r 24%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d       | 12/50 [00:04<00:16,  2.37it/s]\\r 26%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c       | 13/50 [00:05<00:15,  2.37it/s]\\r 28%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a       | 14/50 [00:05<00:15,  2.37it/s]\\r 30%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88       | 15/50 [00:06<00:13,  2.51it/s]\\r 32%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f      | 16/50 [00:06<00:13,  2.45it/s]\\r 34%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d      | 17/50 [00:06<00:13,  2.43it/s]\\r 36%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c      | 18/50 [00:07<00:13,  2.40it/s]\\r 38%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a      | 19/50 [00:07<00:12,  2.39it/s]\\r 40%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88      | 20/50 [00:08<00:12,  2.37it/s]\\r 42%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f     | 21/50 [00:08<00:12,  2.36it/s]\\r 44%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d     | 22/50 [00:09<00:11,  2.37it/s]\\r 46%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c     | 23/50 [00:09<00:11,  2.39it/s]\\r 48%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a     | 24/50 [00:09<00:10,  2.39it/s]\\r 50%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88     | 25/50 [00:10<00:10,  2.38it/s]\\r 52%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f    | 26/50 [00:10<00:10,  2.38it/s]\\r 54%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d    | 27/50 [00:11<00:09,  2.36it/s]\\r 56%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c    | 28/50 [00:11<00:09,  2.38it/s]\\r 58%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a    | 29/50 [00:12<00:08,  2.39it/s]\\r 60%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88    | 30/50 [00:12<00:07,  2.54it/s]\\r 62%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f   | 31/50 [00:12<00:07,  2.49it/s]\\r 64%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d   | 32/50 [00:13<00:07,  2.46it/s]\\r 66%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c   | 33/50 [00:13<00:06,  2.44it/s]\\r 68%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a   | 34/50 [00:14<00:06,  2.42it/s]\\r 70%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88   | 35/50 [00:14<00:06,  2.40it/s]\\r 72%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f  | 36/50 [00:14<00:05,  2.39it/s]\\r 74%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d  | 37/50 [00:15<00:05,  2.38it/s]\\r 76%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c  | 38/50 [00:15<00:05,  2.35it/s]\\r 78%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a  | 39/50 [00:16<00:04,  2.34it/s]\\r 80%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88  | 40/50 [00:16<00:04,  2.32it/s]\\r 82%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f | 41/50 [00:17<00:03,  2.32it/s]\\r 84%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d | 42/50 [00:17<00:03,  2.31it/s]\\r 86%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c | 43/50 [00:17<00:03,  2.30it/s]\\r 88%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a | 44/50 [00:18<00:02,  2.30it/s]\\r 90%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88 | 45/50 [00:18<00:02,  2.45it/s]\\r 92%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f| 46/50 [00:19<00:01,  2.41it/s]\\r 94%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d| 47/50 [00:19<00:01,  2.40it/s]\\r 96%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c| 48/50 [00:19<00:00,  2.40it/s]\\r 98%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a| 49/50 [00:20<00:00,  2.40it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.40it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.40it/s]\\n\\r  0%|          | 0/50 [00:00<?, ?it/s]\\r  2%|\\xe2\\x96\\x8f         | 1/50 [00:00<00:20,  2.40it/s]\\r  4%|\\xe2\\x96\\x8d         | 2/50 [00:00<00:20,  2.36it/s]\\r  6%|\\xe2\\x96\\x8c         | 3/50 [00:01<00:19,  2.36it/s]\\r  8%|\\xe2\\x96\\x8a         | 4/50 [00:01<00:19,  2.35it/s]\\r 10%|\\xe2\\x96\\x88         | 5/50 [00:02<00:19,  2.36it/s]\\r 12%|\\xe2\\x96\\x88\\xe2\\x96\\x8f        | 6/50 [00:02<00:17,  2.53it/s]\\r 14%|\\xe2\\x96\\x88\\xe2\\x96\\x8d        | 7/50 [00:02<00:17,  2.49it/s]\\r 16%|\\xe2\\x96\\x88\\xe2\\x96\\x8c        | 8/50 [00:03<00:16,  2.47it/s]\\r 18%|\\xe2\\x96\\x88\\xe2\\x96\\x8a        | 9/50 [00:03<00:16,  2.46it/s]\\r 20%|\\xe2\\x96\\x88\\xe2\\x96\\x88        | 10/50 [00:04<00:16,  2.43it/s]\\r 22%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f       | 11/50 [00:04<00:16,  2.42it/s]\\r 24%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d       | 12/50 [00:04<00:15,  2.41it/s]\\r 26%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c       | 13/50 [00:05<00:15,  2.37it/s]\\r 28%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a       | 14/50 [00:05<00:15,  2.35it/s]\\r 30%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88       | 15/50 [00:06<00:14,  2.34it/s]\\r 32%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f      | 16/50 [00:06<00:14,  2.37it/s]\\r 34%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d      | 17/50 [00:07<00:13,  2.40it/s]\\r 36%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c      | 18/50 [00:07<00:12,  2.55it/s]\\r 38%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a      | 19/50 [00:07<00:12,  2.52it/s]\\r 40%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88      | 20/50 [00:08<00:12,  2.50it/s]\\r 42%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f     | 21/50 [00:08<00:11,  2.47it/s]\\r 44%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d     | 22/50 [00:09<00:11,  2.46it/s]\\r 46%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c     | 23/50 [00:09<00:11,  2.44it/s]\\r 48%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a     | 24/50 [00:09<00:10,  2.43it/s]\\r 50%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88     | 25/50 [00:10<00:10,  2.43it/s]\\r 52%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f    | 26/50 [00:10<00:09,  2.42it/s]\\r 54%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d    | 27/50 [00:11<00:09,  2.41it/s]\\r 56%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c    | 28/50 [00:11<00:09,  2.40it/s]\\r 58%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a    | 29/50 [00:11<00:08,  2.39it/s]\\r 60%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88    | 30/50 [00:12<00:07,  2.54it/s]\\r 62%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f   | 31/50 [00:12<00:07,  2.50it/s]\\r 64%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d   | 32/50 [00:13<00:07,  2.48it/s]\\r 66%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c   | 33/50 [00:13<00:06,  2.46it/s]\\r 68%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a   | 34/50 [00:13<00:06,  2.45it/s]\\r 70%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88   | 35/50 [00:14<00:06,  2.44it/s]\\r 72%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f  | 36/50 [00:14<00:05,  2.41it/s]\\r 74%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d  | 37/50 [00:15<00:05,  2.40it/s]\\r 76%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c  | 38/50 [00:15<00:04,  2.41it/s]\\r 78%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a  | 39/50 [00:16<00:04,  2.40it/s]\\r 80%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88  | 40/50 [00:16<00:04,  2.39it/s]\\r 82%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f | 41/50 [00:16<00:03,  2.39it/s]\\r 84%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d | 42/50 [00:17<00:03,  2.52it/s]\\r 86%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c | 43/50 [00:17<00:02,  2.46it/s]\\r 88%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a | 44/50 [00:18<00:02,  2.45it/s]\\r 90%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88 | 45/50 [00:18<00:02,  2.44it/s]\\r 92%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8f| 46/50 [00:18<00:01,  2.42it/s]\\r 94%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8d| 47/50 [00:19<00:01,  2.42it/s]\\r 96%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8c| 48/50 [00:19<00:00,  2.42it/s]\\r 98%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x8a| 49/50 [00:20<00:00,  2.42it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.41it/s]\\r100%|\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88\\xe2\\x96\\x88| 50/50 [00:20<00:00,  2.43it/s]\\n')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a29835d5-6e73-434f-ad29-7441e5c08018",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('model_save/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/2024_07_30_06_05_37/config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd577c60-5fac-4598-8602-d577c4ac98b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'test': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/test.csv',\n",
       "  'train': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/train.csv',\n",
       "  'val': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/val.csv',\n",
       "  'y_test': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/y_test.csv',\n",
       "  'y_train': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/y_train.csv',\n",
       "  'y_val': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/y_val.csv'},\n",
       " 'date_string': '2024_07_30_06_05_37',\n",
       " 'gene_expression': {'highly_expressed_threshold': 0.95,\n",
       "  'lowly_expressed_threshold': 0.95,\n",
       "  'marker': True,\n",
       "  'normalization': True,\n",
       "  'print_information': True},\n",
       " 'model_output': {'model_save_dir': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/model_save/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/'},\n",
       " 'pathways_network': {'datatype': 'diagnosis',\n",
       "  'ensemble_pathway_relation': '../../usman/CellTICS/reactome/Ensembl2Reactome_All_Levels.txt',\n",
       "  'n_hidden_layer': 5,\n",
       "  'pathway_names': '../../usman/CellTICS/reactome/ReactomePathways.txt',\n",
       "  'pathway_relation': '../../usman/CellTICS/reactome/ReactomePathwaysRelation.txt',\n",
       "  'species': 'human'},\n",
       " 'train': {'batch_size': 2048,\n",
       "  'epochs': 100,\n",
       "  'learning_rate': 0.001,\n",
       "  'weight_decay': 0.0001}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f6dbde7-ce2c-462a-b022-1dd1060197d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config['dataset']['train'],index_col=0)\n",
    "test = pd.read_csv(config['dataset']['test'],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bed73747-d6c5-4f9b-8e7b-171a99f1153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(config['dataset']['y_train'])\n",
    "y_test = pd.read_csv(config['dataset']['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9444059-467c-498f-8172-e297bc49e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(config['dataset']['val'],index_col=0)\n",
    "y_val = pd.read_csv(config['dataset']['y_val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e8dd019-d4fa-4e02-8c0c-f8784b7f9b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Marker Genes.......\n",
      "1125\n",
      "1125\n",
      "2250\n",
      "2250\n",
      "                    0                1\n",
      "0     ENSG00000101210  ENSG00000172270\n",
      "1     ENSG00000099622  ENSG00000141905\n",
      "2     ENSG00000105278  ENSG00000167658\n",
      "3     ENSG00000178951  ENSG00000089847\n",
      "4     ENSG00000141985  ENSG00000127663\n",
      "...               ...              ...\n",
      "1120  ENSG00000285395  ENSG00000103316\n",
      "1121  ENSG00000140740  ENSG00000284218\n",
      "1122  ENSG00000122254  ENSG00000103365\n",
      "1123  ENSG00000006116  ENSG00000182601\n",
      "1124  ENSG00000077235  ENSG00000171208\n",
      "\n",
      "[1125 rows x 2 columns]\n",
      "                    0                1\n",
      "0     ENSG00000101210  ENSG00000172270\n",
      "1     ENSG00000099622  ENSG00000141905\n",
      "2     ENSG00000105278  ENSG00000167658\n",
      "3     ENSG00000178951  ENSG00000089847\n",
      "4     ENSG00000141985  ENSG00000127663\n",
      "...               ...              ...\n",
      "1120  ENSG00000285395  ENSG00000103316\n",
      "1121  ENSG00000140740  ENSG00000284218\n",
      "1122  ENSG00000122254  ENSG00000103365\n",
      "1123  ENSG00000006116  ENSG00000182601\n",
      "1124  ENSG00000077235  ENSG00000171208\n",
      "\n",
      "[1125 rows x 2 columns]\n",
      "Getting Pathway Genes.........\n",
      "Getting Masking.........\n",
      "HSA\n"
     ]
    }
   ],
   "source": [
    "r_data_tmp = train.T\n",
    "q_data_tmp = test.T\n",
    "v_data_tmp = val.T\n",
    "r_label_tmp = y_train\n",
    "\n",
    "print('Getting Marker Genes.......')\n",
    "train_x, test_x, val_x, train_y = get_expression(r_data_tmp,\n",
    "                                                q_data_tmp,\n",
    "                                                v_data_tmp,\n",
    "                                                r_label_tmp,\n",
    "                                                thrh=config['gene_expression']['highly_expressed_threshold'],\n",
    "                                                thrl=config['gene_expression']['lowly_expressed_threshold'],\n",
    "                                                normalization=config['gene_expression']['normalization'],\n",
    "                                                marker=config['gene_expression']['marker'])\n",
    "\n",
    "\n",
    "print('Getting Pathway Genes.........')\n",
    "pathway_genes = get_gene_pathways(config['pathways_network']['ensemble_pathway_relation'], species=config['pathways_network']['species'])\n",
    "\n",
    "\n",
    "print('Getting Masking.........')\n",
    "masking, layers_node, train_x, test_x,val_x = get_masking(config['pathways_network']['pathway_names'],\n",
    "                                                        pathway_genes,\n",
    "                                                        config['pathways_network']['pathway_relation'],\n",
    "                                                        train_x,\n",
    "                                                        test_x,\n",
    "                                                        val_x,\n",
    "                                                        train_y,\n",
    "                                                        config['pathways_network']['datatype'],\n",
    "                                                        config['pathways_network']['species'],\n",
    "                                                        config['pathways_network']['n_hidden_layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e76ec569-6cef-42b7-b125-a682aa974d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    masking = list(masking.values())\n",
    "    layers_node = list(layers_node.values())\n",
    "except:\n",
    "    print('already_done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0433817-6cf3-4408-b83c-315d7b7c1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, count_matrix, label):\n",
    "        # Read the CSV file\n",
    "        self.data = count_matrix\n",
    "        # Separate features and target\n",
    "        self.features = self.data.values\n",
    "        self.target = label.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get features and target for a given index\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.target[idx], dtype=torch.float32)\n",
    "        return features, target\n",
    "\n",
    "train_dataset = TabularDataset(train_x.T,train_y)\n",
    "val_dataset = TabularDataset(val_x.T,y_val)\n",
    "test_dataset = TabularDataset(test_x.T,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4263e234-8d58-4466-aa05-3441f622838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train']['batch_size'], shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['train']['batch_size'], shuffle= False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['train']['batch_size'], shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68f44017-e6fe-4a75-a3f8-f47658bf316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_list = []\n",
    "    labels_list = []\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = 0\n",
    "    with torch.no_grad():  # No need to compute gradients during evaluation\n",
    "        for features, labels in dataloader:\n",
    "            outputs = model(features)\n",
    "            print(outputs)\n",
    "            #print(outputs)\n",
    "            predicted = torch.round(torch.sigmoid(outputs.data))\n",
    "            #print(outputs)\n",
    "            #print(predicted)\n",
    "            loss += criterion(outputs, labels)\n",
    "            #_, predicted = torch.sigmoid(outputs.data)\n",
    "            predicted_list.append(predicted)\n",
    "            labels_list.append(labels)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    #print(total)\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, loss, predicted_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00f66a8a-21d3-4200-b206-6867b98971e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(train_dataloader, layers_node, masking, output_layer,model_save_dir):\n",
    "    \n",
    "    model = CustomNetwork(layers_node, output_layer, masking)\n",
    "    model.load_state_dict(torch.load(f'{model_save_dir}best_model_{output_layer}_state_dict.pth'))\n",
    "    test_accuracy, test_loss, predicted_list_test, labels_list_test = evaluate(model, test_dataloader)\n",
    "    return test_accuracy, test_loss, predicted_list_test, labels_list_test,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af361e2b-2290-4826-a3b9-29fb6804ff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sub-neural network has 1 hidden layers.\n",
      "tensor([[0.4891],\n",
      "        [0.4895],\n",
      "        [0.4897],\n",
      "        ...,\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895]])\n",
      "tensor([[0.4895],\n",
      "        [0.4895],\n",
      "        [0.4901],\n",
      "        ...,\n",
      "        [0.4905],\n",
      "        [0.4883],\n",
      "        [0.4895]])\n",
      "tensor([[0.4895],\n",
      "        [0.4898],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4900],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4897],\n",
      "        [0.4895],\n",
      "        [0.4879],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4900],\n",
      "        [0.4885],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4897],\n",
      "        [0.4895],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4880],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4882],\n",
      "        [0.4898],\n",
      "        [0.4895],\n",
      "        [0.4886],\n",
      "        [0.4878],\n",
      "        [0.4877],\n",
      "        [0.4891],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4882],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4879],\n",
      "        [0.4893],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4899],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4888],\n",
      "        [0.4878],\n",
      "        [0.4886],\n",
      "        [0.4883],\n",
      "        [0.4898],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4877],\n",
      "        [0.4880],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4897],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4901],\n",
      "        [0.4885],\n",
      "        [0.4895],\n",
      "        [0.4883],\n",
      "        [0.4895],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4881],\n",
      "        [0.4880],\n",
      "        [0.4900],\n",
      "        [0.4887],\n",
      "        [0.4876],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4874],\n",
      "        [0.4903],\n",
      "        [0.4895],\n",
      "        [0.4899],\n",
      "        [0.4881],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4886],\n",
      "        [0.4907],\n",
      "        [0.4875],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4890],\n",
      "        [0.4883],\n",
      "        [0.4888],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4884],\n",
      "        [0.4886],\n",
      "        [0.4881],\n",
      "        [0.4883],\n",
      "        [0.4899],\n",
      "        [0.4883],\n",
      "        [0.4865],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4879],\n",
      "        [0.4890],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4886],\n",
      "        [0.4886],\n",
      "        [0.4894],\n",
      "        [0.4893],\n",
      "        [0.4901],\n",
      "        [0.4900],\n",
      "        [0.4884],\n",
      "        [0.4899],\n",
      "        [0.4898],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4883],\n",
      "        [0.4895],\n",
      "        [0.4882],\n",
      "        [0.4889],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4891],\n",
      "        [0.4888],\n",
      "        [0.4878],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4892],\n",
      "        [0.4881],\n",
      "        [0.4888],\n",
      "        [0.4879],\n",
      "        [0.4895],\n",
      "        [0.4874],\n",
      "        [0.4895],\n",
      "        [0.4889],\n",
      "        [0.4887],\n",
      "        [0.4887],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4906],\n",
      "        [0.4895],\n",
      "        [0.4880],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4878],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4905],\n",
      "        [0.4893],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4892],\n",
      "        [0.4881],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4884],\n",
      "        [0.4903],\n",
      "        [0.4895],\n",
      "        [0.4883],\n",
      "        [0.4885],\n",
      "        [0.4881],\n",
      "        [0.4895],\n",
      "        [0.4891],\n",
      "        [0.4885],\n",
      "        [0.4885],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4880],\n",
      "        [0.4888],\n",
      "        [0.4891],\n",
      "        [0.4895],\n",
      "        [0.4881],\n",
      "        [0.4871],\n",
      "        [0.4895],\n",
      "        [0.4892],\n",
      "        [0.4871],\n",
      "        [0.4885],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4892],\n",
      "        [0.4887],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4882],\n",
      "        [0.4896],\n",
      "        [0.4895],\n",
      "        [0.4891],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4884],\n",
      "        [0.4876],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4884],\n",
      "        [0.4900],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4890],\n",
      "        [0.4884],\n",
      "        [0.4892],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4892],\n",
      "        [0.4893],\n",
      "        [0.4895],\n",
      "        [0.4893],\n",
      "        [0.4895],\n",
      "        [0.4878],\n",
      "        [0.4884],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4880],\n",
      "        [0.4898],\n",
      "        [0.4891],\n",
      "        [0.4896],\n",
      "        [0.4895],\n",
      "        [0.4886],\n",
      "        [0.4889],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4892],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4897],\n",
      "        [0.4898],\n",
      "        [0.4871],\n",
      "        [0.4876],\n",
      "        [0.4881],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4902],\n",
      "        [0.4902],\n",
      "        [0.4872],\n",
      "        [0.4895],\n",
      "        [0.4903],\n",
      "        [0.4887],\n",
      "        [0.4876],\n",
      "        [0.4895],\n",
      "        [0.4860],\n",
      "        [0.4889],\n",
      "        [0.4885],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4889],\n",
      "        [0.4897],\n",
      "        [0.4897],\n",
      "        [0.4890],\n",
      "        [0.4899],\n",
      "        [0.4898],\n",
      "        [0.4869],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4891],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4882],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4892],\n",
      "        [0.4884],\n",
      "        [0.4892],\n",
      "        [0.4882],\n",
      "        [0.4893],\n",
      "        [0.4890],\n",
      "        [0.4900],\n",
      "        [0.4900],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4900],\n",
      "        [0.4879],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4897],\n",
      "        [0.4887],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4891],\n",
      "        [0.4895],\n",
      "        [0.4891],\n",
      "        [0.4892],\n",
      "        [0.4895],\n",
      "        [0.4892],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4886],\n",
      "        [0.4883],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4903],\n",
      "        [0.4897],\n",
      "        [0.4874],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4897],\n",
      "        [0.4887],\n",
      "        [0.4867],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4880],\n",
      "        [0.4878],\n",
      "        [0.4895],\n",
      "        [0.4897],\n",
      "        [0.4891],\n",
      "        [0.4886],\n",
      "        [0.4880],\n",
      "        [0.4892],\n",
      "        [0.4884],\n",
      "        [0.4887],\n",
      "        [0.4895],\n",
      "        [0.4881],\n",
      "        [0.4892],\n",
      "        [0.4895],\n",
      "        [0.4898],\n",
      "        [0.4882],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4882],\n",
      "        [0.4890],\n",
      "        [0.4892],\n",
      "        [0.4895],\n",
      "        [0.4878],\n",
      "        [0.4886],\n",
      "        [0.4887],\n",
      "        [0.4891],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4882],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4883],\n",
      "        [0.4895],\n",
      "        [0.4882],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4877],\n",
      "        [0.4875],\n",
      "        [0.4895],\n",
      "        [0.4879],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4898],\n",
      "        [0.4885],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4893],\n",
      "        [0.4897],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4897],\n",
      "        [0.4890],\n",
      "        [0.4888],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4868],\n",
      "        [0.4882],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4883],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4876],\n",
      "        [0.4885],\n",
      "        [0.4895],\n",
      "        [0.4898],\n",
      "        [0.4888],\n",
      "        [0.4891],\n",
      "        [0.4874],\n",
      "        [0.4880],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4898],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4889],\n",
      "        [0.4896],\n",
      "        [0.4895],\n",
      "        [0.4891],\n",
      "        [0.4890],\n",
      "        [0.4883],\n",
      "        [0.4895],\n",
      "        [0.4884],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4887],\n",
      "        [0.4899],\n",
      "        [0.4883],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4886],\n",
      "        [0.4885],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4889],\n",
      "        [0.4891],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4887],\n",
      "        [0.4894],\n",
      "        [0.4882],\n",
      "        [0.4881],\n",
      "        [0.4895],\n",
      "        [0.4898],\n",
      "        [0.4895],\n",
      "        [0.4891],\n",
      "        [0.4895],\n",
      "        [0.4883],\n",
      "        [0.4888],\n",
      "        [0.4884],\n",
      "        [0.4887],\n",
      "        [0.4895],\n",
      "        [0.4881],\n",
      "        [0.4881],\n",
      "        [0.4888],\n",
      "        [0.4882],\n",
      "        [0.4904],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4897],\n",
      "        [0.4879],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4880],\n",
      "        [0.4895],\n",
      "        [0.4887],\n",
      "        [0.4902],\n",
      "        [0.4895],\n",
      "        [0.4893],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4889],\n",
      "        [0.4888],\n",
      "        [0.4889],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4903],\n",
      "        [0.4881],\n",
      "        [0.4889],\n",
      "        [0.4883],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4888],\n",
      "        [0.4877],\n",
      "        [0.4895],\n",
      "        [0.4893],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4885],\n",
      "        [0.4886],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4895],\n",
      "        [0.4891],\n",
      "        [0.4877],\n",
      "        [0.4887],\n",
      "        [0.4895],\n",
      "        [0.4883],\n",
      "        [0.4895],\n",
      "        [0.4895],\n",
      "        [0.4906],\n",
      "        [0.4895],\n",
      "        [0.4894],\n",
      "        [0.4885],\n",
      "        [0.4878],\n",
      "        [0.4895],\n",
      "        [0.4893],\n",
      "        [0.4880],\n",
      "        [0.4902],\n",
      "        [0.4883],\n",
      "        [0.4884],\n",
      "        [0.4895],\n",
      "        [0.4893],\n",
      "        [0.4900],\n",
      "        [0.4889],\n",
      "        [0.4885],\n",
      "        [0.4891],\n",
      "        [0.4895],\n",
      "        [0.4890],\n",
      "        [0.4883],\n",
      "        [0.4886],\n",
      "        [0.4893],\n",
      "        [0.4888]])\n",
      "50.27683134582624\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e20d5f46-f330-45ad-a002-a5983e00e766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=582, out_features=843, bias=False)\n",
       "    (1): Linear(in_features=843, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4f10b-568d-49de-82af-f12ece6d2f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60eb0e0e-aa88-4014-828b-71d5f047dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =model.layers[0].weight.detach().cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8276cc5f-f2f2-47ab-a508-7b2c40d106c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.,  0., -0., ..., -0.,  0., -0.],\n",
       "       [-0., -0.,  0., ...,  0., -0., -0.],\n",
       "       [-0., -0.,  0., ...,  0., -0., -0.],\n",
       "       ...,\n",
       "       [ 0., -0., -0., ..., -0.,  0., -0.],\n",
       "       [-0., -0.,  0., ..., -0., -0.,  0.],\n",
       "       [-0., -0.,  0., ...,  0., -0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d8c29e6-11ef-4238-8210-0f4d2244221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490613"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x.flatten()).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31b00958-b5b6-491c-a5b6-2a434afd43b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490626"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(x.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a2c2dd6-e64d-4d5b-aaa8-205fb679604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/model_save/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['model_output']['model_save_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7f7655c-664f-46b0-a7d5-238de1eea605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = dict()\n",
    "models_state_dict = dict()\n",
    "for i in os.listdir(config['model_output']['model_save_dir']+ '2024_07_27_15_17_55'):\n",
    "    if 'state' in i:\n",
    "        continue\n",
    "        \n",
    "    elif '.pth' in i:\n",
    "        models[i] = torch.load(config['model_output']['model_save_dir']+ '2024_07_27_15_17_55'+'/' + i)\n",
    "        k = i.split('.')[0] + '_state_dict.' + i.split('.')[1]\n",
    "        models_state_dict[i] = torch.load(config['model_output']['model_save_dir']+ '2024_07_27_15_17_55'+'/' + k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e4e2762-a43b-47e9-9c3b-36d8f92e7553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0055, 0.0000],\n",
       "        [0.0000, -0.0000, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  ..., 0.0000, 0.0000, -0.0000],\n",
       "        ...,\n",
       "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, 0.0000, 0.0000],\n",
       "        [-0.0000, -0.0000, 0.0000,  ..., 0.0000, 0.0000, -0.0000]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['best_model_2.pth'].layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8dc5ea95-d714-40c2-bca6-f159b6dd8007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=582, out_features=843, bias=False)\n",
       "    (1): Linear(in_features=843, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models['best_model_2.pth']\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a56b760-ab80-4843-b961-a8c2d0a0f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.131345402910895"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, loss, predicted_list, labels_list = evaluate(models['best_model_2.pth'], train_dataloader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33574e1f-0a24-4c3f-879d-bdd86a33baaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodels\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5a320-b44b-408c-92d3-ca993abb04e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe72a24-3905-4609-8801-4f18ab2e0fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8dee7d77-8175-40f4-a986-afe79f76fac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e074417d-5532-4e8e-ba7d-e2e0d087d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'a':1,'b':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd0f2410-9f4c-420f-9496-8658fd3d4f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations saved to model_activations.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import csv\n",
    "\n",
    "# Define the model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN()\n",
    "\n",
    "# Dictionary to store activations\n",
    "model_dct = dict()\n",
    "\n",
    "# Hook function\n",
    "def hook_fn(module, input, output, layer_name):\n",
    "    global model_dct\n",
    "    input_list = [i.detach().cpu().numpy().tolist() for i in input]\n",
    "    output_list = output.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    # If the layer name is not in the dictionary, create a new list for it\n",
    "    if layer_name not in model_dct:\n",
    "        model_dct[layer_name] = []\n",
    "\n",
    "    # Append the activations to the corresponding layer list\n",
    "    model_dct[layer_name].append({\n",
    "        'input': input_list,\n",
    "        'output': output_list\n",
    "    })\n",
    "\n",
    "# Register hooks for each layer\n",
    "for name, layer in enumerate(model.children()):\n",
    "    layer_name = 'fc'+str(name+1)\n",
    "    layer.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n",
    "\n",
    "# Create a test dataset and dataloader\n",
    "# Assuming 100 samples, each of size 10\n",
    "test_data = torch.randn(100, 10)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "# Perform forward pass on each batch in the test loader\n",
    "for batch in test_loader:\n",
    "    model(batch)\n",
    "\n",
    "# Save the activations to a CSV file\n",
    "with open('model_activations.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['layer', 'input', 'output']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for layer_name, activations in model_dct.items():\n",
    "        for activation in activations:\n",
    "            writer.writerow({\n",
    "                'layer': layer_name,\n",
    "                'input': activation['input'],\n",
    "                'output': activation['output']\n",
    "            })\n",
    "\n",
    "print('Activations saved to model_activations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00576f-99b2-4cbf-890f-841ba9f6a7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
