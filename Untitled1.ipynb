{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4725e2ad-4da9-4c78-b84a-93d933993d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "from gene_expression import *\n",
    "from pathway_hierarchy import *\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from custom_neural_network import *\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175c1325-3340-4988-bac5-60007210010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29835d5-6e73-434f-ad29-7441e5c08018",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('model_save/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/2024_07_24_22_38_30/config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd577c60-5fac-4598-8602-d577c4ac98b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'test': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/test.csv',\n",
       "  'train': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/train.csv',\n",
       "  'val': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/val.csv',\n",
       "  'y_test': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/y_test.csv',\n",
       "  'y_train': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/y_train.csv',\n",
       "  'y_val': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/Preprocessed_data/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/y_val.csv'},\n",
       " 'gene_expression': {'highly_expressed_threshold': 0.95,\n",
       "  'lowly_expressed_threshold': 0.95,\n",
       "  'marker': True,\n",
       "  'normalization': True,\n",
       "  'print_information': True},\n",
       " 'model_output': {'model_save_dir': '/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/model_save/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/'},\n",
       " 'pathways_network': {'datatype': 'diagnosis',\n",
       "  'ensemble_pathway_relation': '../../usman/CellTICS/reactome/Ensembl2Reactome_All_Levels.txt',\n",
       "  'n_hidden_layer': 5,\n",
       "  'pathway_names': '../../usman/CellTICS/reactome/ReactomePathways.txt',\n",
       "  'pathway_relation': '../../usman/CellTICS/reactome/ReactomePathwaysRelation.txt',\n",
       "  'species': 'human'},\n",
       " 'train': {'batch_size': 2048,\n",
       "  'epochs': 100,\n",
       "  'learning_rate': 0.001,\n",
       "  'weight_decay': 0.0001}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f6dbde7-ce2c-462a-b022-1dd1060197d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config['dataset']['train'],index_col=0)\n",
    "test = pd.read_csv(config['dataset']['test'],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed73747-d6c5-4f9b-8e7b-171a99f1153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(config['dataset']['y_train'])\n",
    "y_test = pd.read_csv(config['dataset']['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9444059-467c-498f-8172-e297bc49e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(config['dataset']['val'],index_col=0)\n",
    "y_val = pd.read_csv(config['dataset']['y_val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8dd019-d4fa-4e02-8c0c-f8784b7f9b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Marker Genes.......\n",
      "1125\n",
      "1125\n",
      "2250\n",
      "2250\n",
      "                    0                1\n",
      "0     ENSG00000101210  ENSG00000172270\n",
      "1     ENSG00000099622  ENSG00000141905\n",
      "2     ENSG00000105278  ENSG00000167658\n",
      "3     ENSG00000178951  ENSG00000089847\n",
      "4     ENSG00000141985  ENSG00000127663\n",
      "...               ...              ...\n",
      "1120  ENSG00000285395  ENSG00000103316\n",
      "1121  ENSG00000140740  ENSG00000284218\n",
      "1122  ENSG00000122254  ENSG00000103365\n",
      "1123  ENSG00000006116  ENSG00000182601\n",
      "1124  ENSG00000077235  ENSG00000171208\n",
      "\n",
      "[1125 rows x 2 columns]\n",
      "                    0                1\n",
      "0     ENSG00000101210  ENSG00000172270\n",
      "1     ENSG00000099622  ENSG00000141905\n",
      "2     ENSG00000105278  ENSG00000167658\n",
      "3     ENSG00000178951  ENSG00000089847\n",
      "4     ENSG00000141985  ENSG00000127663\n",
      "...               ...              ...\n",
      "1120  ENSG00000285395  ENSG00000103316\n",
      "1121  ENSG00000140740  ENSG00000284218\n",
      "1122  ENSG00000122254  ENSG00000103365\n",
      "1123  ENSG00000006116  ENSG00000182601\n",
      "1124  ENSG00000077235  ENSG00000171208\n",
      "\n",
      "[1125 rows x 2 columns]\n",
      "Getting Pathway Genes.........\n",
      "Getting Masking.........\n",
      "HSA\n"
     ]
    }
   ],
   "source": [
    "r_data_tmp = train.T\n",
    "q_data_tmp = test.T\n",
    "v_data_tmp = val.T\n",
    "r_label_tmp = y_train\n",
    "\n",
    "print('Getting Marker Genes.......')\n",
    "train_x, test_x, val_x, train_y = get_expression(r_data_tmp,\n",
    "                                                q_data_tmp,\n",
    "                                                v_data_tmp,\n",
    "                                                r_label_tmp,\n",
    "                                                thrh=config['gene_expression']['highly_expressed_threshold'],\n",
    "                                                thrl=config['gene_expression']['lowly_expressed_threshold'],\n",
    "                                                normalization=config['gene_expression']['normalization'],\n",
    "                                                marker=config['gene_expression']['marker'])\n",
    "    \n",
    "print('Getting Pathway Genes.........')\n",
    "pathway_genes = get_gene_pathways(config['pathways_network']['ensemble_pathway_relation'], species=config['pathways_network']['species'])\n",
    "\n",
    "\n",
    "print('Getting Masking.........')\n",
    "masking, layers_node, train_x, test_x,val_x = get_masking(config['pathways_network']['pathway_names'],\n",
    "                                                        pathway_genes,\n",
    "                                                        config['pathways_network']['pathway_relation'],\n",
    "                                                        train_x,\n",
    "                                                        test_x,\n",
    "                                                        val_x,\n",
    "                                                        train_y,\n",
    "                                                        config['pathways_network']['datatype'],\n",
    "                                                        config['pathways_network']['species'],\n",
    "                                                        config['pathways_network']['n_hidden_layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e76ec569-6cef-42b7-b125-a682aa974d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    masking = list(masking.values())\n",
    "    layers_node = list(layers_node.values())\n",
    "except:\n",
    "    print('already_done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0433817-6cf3-4408-b83c-315d7b7c1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, count_matrix, label):\n",
    "        # Read the CSV file\n",
    "        self.data = count_matrix\n",
    "        # Separate features and target\n",
    "        self.features = self.data.values\n",
    "        self.target = label.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get features and target for a given index\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.target[idx], dtype=torch.float32)\n",
    "        return features, target\n",
    "\n",
    "train_dataset = TabularDataset(train_x.T,train_y)\n",
    "val_dataset = TabularDataset(val_x.T,y_val)\n",
    "test_dataset = TabularDataset(test_x.T,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4263e234-8d58-4466-aa05-3441f622838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train']['batch_size'], shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['train']['batch_size'], shuffle= True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['train']['batch_size'], shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f44017-e6fe-4a75-a3f8-f47658bf316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_list = []\n",
    "    labels_list = []\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = 0\n",
    "    with torch.no_grad():  # No need to compute gradients during evaluation\n",
    "        for features, labels in dataloader:\n",
    "            outputs = model(features)\n",
    "            #print(outputs)\n",
    "            predicted = torch.round(torch.sigmoid(outputs.data))\n",
    "            #print(outputs)\n",
    "            #print(predicted)\n",
    "            loss += criterion(outputs, labels)\n",
    "            #_, predicted = torch.sigmoid(outputs.data)\n",
    "            predicted_list.append(predicted)\n",
    "            labels_list.append(labels)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    #print(total)\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, loss, predicted_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a2c2dd6-e64d-4d5b-aaa8-205fb679604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/12tb_dsk1/danish/Pytorch_Biologically_Informed_Neural_Network/model_save/excitory_neurons/Exc_L2-3_CBLN2_LINC02306/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['model_output']['model_save_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7f7655c-664f-46b0-a7d5-238de1eea605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = dict()\n",
    "models_state_dict = dict()\n",
    "for i in os.listdir(config['model_output']['model_save_dir']+ '2024_07_27_15_17_55'):\n",
    "    if 'state' in i:\n",
    "        continue\n",
    "        \n",
    "    elif '.pth' in i:\n",
    "        models[i] = torch.load(config['model_output']['model_save_dir']+ '2024_07_27_15_17_55'+'/' + i)\n",
    "        k = i.split('.')[0] + '_state_dict.' + i.split('.')[1]\n",
    "        models_state_dict[i] = torch.load(config['model_output']['model_save_dir']+ '2024_07_27_15_17_55'+'/' + k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e4e2762-a43b-47e9-9c3b-36d8f92e7553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0055, 0.0000],\n",
       "        [0.0000, -0.0000, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  ..., 0.0000, 0.0000, -0.0000],\n",
       "        ...,\n",
       "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, 0.0000, 0.0000],\n",
       "        [-0.0000, -0.0000, 0.0000,  ..., 0.0000, 0.0000, -0.0000]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['best_model_2.pth'].layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8dc5ea95-d714-40c2-bca6-f159b6dd8007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=582, out_features=843, bias=False)\n",
       "    (1): Linear(in_features=843, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models['best_model_2.pth']\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a56b760-ab80-4843-b961-a8c2d0a0f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.131345402910895"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, loss, predicted_list, labels_list = evaluate(models['best_model_2.pth'], train_dataloader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33574e1f-0a24-4c3f-879d-bdd86a33baaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=582, out_features=843, bias=False)\n",
       "    (1): Linear(in_features=843, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5a320-b44b-408c-92d3-ca993abb04e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_dataloader , val_dataloader, test_dataloader, layers_node, masking, output_layer,model_save_dir, date_string, learning_rate=0.001, num_epochs=50, weight_decay = 0, Train = True):\n",
    "    \n",
    "    model = CustomNetwork(layers_node, output_layer, masking)\n",
    "    if Train:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate,weight_decay = weight_decay )  # Using SGD with momentum\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "        patience = 20\n",
    "        best_val_accuracy = 0.0\n",
    "        epochs_no_improve = 0\n",
    "        early_stop = False\n",
    "        csv_file_path = f'{model_save_dir}{date_string}/training_log_{output_layer}.csv'\n",
    "    \n",
    "        try:\n",
    "            os.makedirs(f'{model_save_dir}{date_string}')\n",
    "        except:\n",
    "            print(('...'))\n",
    "    \n",
    "        with open(csv_file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Epoch', 'Loss', 'Train_accuracy', 'Val_accuracy'])\n",
    "        \n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            if early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            epoch_cost = 0.\n",
    "            \n",
    "            total_loss = 0\n",
    "            for batch_features,batch_targets in train_dataloader:\n",
    "                outputs = model(batch_features)\n",
    "                #print(outputs)\n",
    "                #print(batch_targets)\n",
    "                #print(outputs)\n",
    "                loss = criterion(outputs, batch_targets)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                \n",
    "            \n",
    "            train_accuracy, train_loss, predicted_list_train, labels_list_train = evaluate(model, train_dataloader)\n",
    "            val_accuracy, val_loss, predicted_list_val, labels_list_val = evaluate(model, val_dataloader)\n",
    "            #scheduler.step(val_accuracy)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Train_accuracy: {train_accuracy}, Val Loss: {val_loss.item():.4f}, Val_accuracy: {val_accuracy}')\n",
    "            with open(csv_file_path, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([epoch + 1, loss.item(), train_accuracy, val_accuracy])\n",
    "            \n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                epochs_no_improve = 0\n",
    "            # Save the best model\n",
    "                torch.save(model, f'{model_save_dir}{date_string}/best_model_{output_layer}.pth')\n",
    "                torch.save(model.state_dict(), f'{model_save_dir}{date_string}/best_model_{output_layer}_state_dict.pth')\n",
    "                print('Model saved.')\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "        \n",
    "            # Early stopping\n",
    "            '''if epochs_no_improve >= patience:\n",
    "                early_stop = True\n",
    "                print(\"Early stopping triggered\")'''\n",
    "            \n",
    "    if Train:\n",
    "        train_accuracy, train_loss, predicted_list_train, labels_list_train = evaluate(model, train_dataloader)\n",
    "        val_accuracy, val_loss, predicted_list_val, labels_list_val = evaluate(model, val_dataloader)\n",
    "        test_accuracy, test_loss, predicted_list_test, labels_list_test = evaluate(model, test_dataloader)\n",
    "        print('Test Accucary', test_accuracy)\n",
    "        output_train = (predicted_list_train, labels_list_train)\n",
    "        output_val = (predicted_list_val, labels_list_val)\n",
    "        \n",
    "        return output_train, output_val,model\n",
    "\n",
    "    else:\n",
    "        test_accuracy, test_loss, predicted_list_test, labels_list_test = evaluate(model, test_dataloader)\n",
    "        return test_accuracy, test_loss, predicted_list_test, labels_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe72a24-3905-4609-8801-4f18ab2e0fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8dee7d77-8175-40f4-a986-afe79f76fac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for output_layer in range(2, len(masking) + 2):\n",
    "    if config['gene_expression']['print_information']:\n",
    "        print(\"Current sub-neural network has \" + str(output_layer - 1) + \" hidden layers.\")\n",
    "    output_train, output_val,model_dict[output_layer] = model(train_dataloader,\n",
    "                                            val_dataloader,test_dataloader,\n",
    "                                            layers_node,\n",
    "                                            masking,\n",
    "                                            output_layer,\n",
    "                                            model_save_dir = config['model_output']['model_save_dir'],date_string = date_string,\n",
    "                                            learning_rate=config['train']['learning_rate'],num_epochs=config['train']['epochs'],weight_decay = config['train']['weight_decay']\n",
    "                                            )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074417d-5532-4e8e-ba7d-e2e0d087d23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
