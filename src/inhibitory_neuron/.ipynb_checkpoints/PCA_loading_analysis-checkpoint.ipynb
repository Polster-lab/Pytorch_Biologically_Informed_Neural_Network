{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c04c928-6e2d-4a58-ad98-43d32466f8f2",
   "metadata": {},
   "source": [
    "# Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "850a5d7f-872f-485a-9cf8-f5a4c7ca4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2e2e7-361c-46f8-a807-b6caec1b492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biomart import BiomartServer\n",
    "\n",
    "# Connect to the Ensembl Biomart server\n",
    "server = BiomartServer(\"http://www.ensembl.org/biomart\")\n",
    "\n",
    "# Access the Ensembl Genes dataset for Homo sapiens\n",
    "dataset = server.datasets['hsapiens_gene_ensembl']\n",
    "\n",
    "# Query the dataset for Ensembl IDs and gene names\n",
    "response = dataset.search({\n",
    "    'attributes': [\n",
    "        'ensembl_gene_id', \n",
    "        'external_gene_name'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Convert the response to a dataframe\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data_ensemble_gene = StringIO(response.text)\n",
    "\n",
    "df = pd.read_csv(data_ensemble_gene , sep=\"\\t\",header = None)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "# Nice\n",
    "\n",
    "import numpy as np\n",
    "def return_ensemble_id(x):\n",
    "    \n",
    "    try:\n",
    "        return df[df[1]==x][0].values[0]\n",
    "    except: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4cb6a-667c-49b1-b0d6-fad97b625b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load the DataFrame from the pickle file\n",
    "#data = pd.read_csv('../preprocessed_data/mat.csv')\n",
    "l = 0\n",
    "for j in range(1,11):\n",
    "    for i in os.listdir('../../preprocessed_data/inhibitory_neuron/split_chunks/'):\n",
    "        try:\n",
    "            if i.split('.')[1] == 'pkl':\n",
    "                print(i)\n",
    "                pickle_file_path = '../../preprocessed_data/inhibitory_neuron/split_chunks/' + i\n",
    "                if l == 0: \n",
    "                    data = pd.read_pickle(pickle_file_path)\n",
    "                    # to load data in the RAM (not possible to load all data once)\n",
    "                    selected_columns = np.random.choice(data.columns, size=int(len(data.columns)*0.5), replace=False)\n",
    "                    data = data[selected_columns]\n",
    "                else:\n",
    "                    df = pd.read_pickle(pickle_file_path)\n",
    "                    df_selected = df[selected_columns] # selected columns coming from first time loaded data\n",
    "                    data = pd.concat([data,df_selected],axis = 0)\n",
    "                \n",
    "                print(\"Pickle file has been loaded into a DataFrame:\")\n",
    "                l = l + 1\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    single_cell_metadata = pd.read_csv('../../preprocessed_data/inhibitory_neuron/metadata_inhibitory_neurons.csv', index_col = 0)\n",
    "        \n",
    "    single_cell_metadata = single_cell_metadata[single_cell_metadata.clinical_pathological_AD != 'False']\n",
    "    single_cell_metadata = single_cell_metadata[single_cell_metadata.index.isin(data.columns)]\n",
    "    data = data[single_cell_metadata.index.tolist()]\n",
    "    x = data.reset_index()['index'].apply(return_ensemble_id)\n",
    "    \n",
    "    data['ensemble_gene_name'] = x.tolist()\n",
    "    data = data.dropna()\n",
    "        \n",
    "    data.set_index('ensemble_gene_name', inplace = True)\n",
    "    clinical_data = pd.read_csv('/12tb_dsk1/danish/preprocessed_data/clinical/clinical_single_cell.csv')\n",
    "    single_cell_metadata.reset_index(inplace = True)\n",
    "    single_cell_metadata = pd.merge(single_cell_metadata,clinical_data[['subject','pmi_df2','age_death','msex','educ','age_first_ad_dx','cogdx','ceradsc','braaksc','apoe_genotype']], on = 'subject', how = 'left')\n",
    "    single_cell_metadata = single_cell_metadata.drop(columns=['apoe_genotype'])         \n",
    "    single_cell_metadata = single_cell_metadata[~single_cell_metadata.pmi_df2.isna()]\n",
    "    single_cell_metadata.drop_duplicates(inplace = True)\n",
    "    data = data.T\n",
    "\n",
    "    covariates_dataframe = pd.merge(data.reset_index()['index'],single_cell_metadata[['cell_id','pmi_df2','age_death','msex','educ','cogdx','ceradsc','braaksc',\n",
    "                                                                                                ]] , left_on='index', right_on='cell_id', how='inner')\n",
    "    data = data[data.index.isin(covariates_dataframe.cell_id)]\n",
    "    data = data.sort_index()\n",
    "    try:\n",
    "        covariates_dataframe.drop(columns=['index'],inplace = True)\n",
    "    except:\n",
    "        print('no such columns, probably I am running this snippet second time')\n",
    "    covariates_dataframe.drop_duplicates(inplace = True)\n",
    "    covariates_dataframe.set_index('cell_id', inplace = True)\n",
    "    covariates_dataframe = covariates_dataframe.sort_index()\n",
    "    data = data.sort_index()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "            \n",
    "            # Perform PCA\n",
    "    pca = PCA(n_components=100)  # Choose number of components\n",
    "    principal_components = pca.fit_transform(scaled_data)\n",
    "            \n",
    "    df_explained_variance_ratio = pd.DataFrame(pca.explained_variance_ratio_, columns=['Explained Variance Ratio'])\n",
    "    \n",
    "    loadings = pca.components_\n",
    "    loadings_df = pd.DataFrame(loadings.T, columns=[f'PC{i+1}' for i in range(loadings.shape[0])], index=data.columns)\n",
    "\n",
    "    loadings_df.to_csv(f'../../../../usman/Single_Cell_Microglia_Project/results/inhibitory_neuron/loadings_pca_output_{j}.txt', sep='\\t')\n",
    "    df_explained_variance_ratio.to_csv(f'../../../../usman/Single_Cell_Microglia_Project/results/inhibitory_neuron/pca_explained_variance_{j}.txt', sep='\\t')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c7ec9-0a0d-4ead-b6c7-9969a19813c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Assuming merged_data_clinical_pathological is your data matrix (samples x features)\n",
    "        # and labels is a list/array of labels corresponding to each sample\n",
    "        \n",
    "        # Standardize the data (important for PCA)\n",
    "\n",
    "\n",
    "\n",
    "        #correlation_matrix = np.corrcoef(principal_components.T, covariates_dataframe.T)[:principal_components.shape[1], principal_components.shape[1]:]\n",
    "        #print(loadings_df)\n",
    "        \n",
    "        #fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Plot Heatmap\n",
    "        #sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', xticklabels=covariates_dataframe.columns,\n",
    "                    #yticklabels=[f'PC {i+1}' for i in range(principal_components.shape[1])], ax=ax1)\n",
    "        #ax1.set_title('Correlation between PCs and Covariates') \n",
    "        #plt.savefig(f'../../../../usman/Single_Cell_Microglia_Project/results/inhibitory_neuron/correlation_heatmap_{j}.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
