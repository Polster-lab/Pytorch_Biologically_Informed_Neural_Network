{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c04c928-6e2d-4a58-ad98-43d32466f8f2",
   "metadata": {},
   "source": [
    "# Index\n",
    "### 1. Merging single cell data with clinical data (label)\n",
    "\n",
    "\n",
    "\n",
    "### 2. Train-Test Split: Making sure train and test sets have different subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850a5d7f-872f-485a-9cf8-f5a4c7ca4fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd70785-4b0c-461b-a727-46d3b821e3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2b0f94-0b82-48fb-a249-cdcee542576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d69dfe9-6f1f-478f-b580-fcca5d835c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_file_path = '../preprocessed_data/count_matrix_microglia.pkl'\n",
    "#data.to_pickle(pickle_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47cf49e-1c36-40ed-97d3-316ab2707a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in tqdm(os.listdir('../../preprocessed_data/inhibitory_neuron/split_chunks/')):\\n   \\n    print(i)\\n    #print(pd.read_csv('../../preprocessed_data/inhibitory_neuron/split_chunks/'+i,nrows=2,index_col=0))\\n    data = pd.read_csv('../../preprocessed_data/inhibitory_neuron/split_chunks/'+i,index_col=0)\\n    pickle_file_path = '../../preprocessed_data/'+i.split('.')[0]+'.pkl'\\n    data.to_pickle(pickle_file_path) \\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "for i in tqdm(os.listdir('../../preprocessed_data/inhibitory_neuron/split_chunks/')):\n",
    "   \n",
    "    print(i)\n",
    "    #print(pd.read_csv('../../preprocessed_data/inhibitory_neuron/split_chunks/'+i,nrows=2,index_col=0))\n",
    "    data = pd.read_csv('../../preprocessed_data/inhibitory_neuron/split_chunks/'+i,index_col=0)\n",
    "    pickle_file_path = '../../preprocessed_data/'+i.split('.')[0]+'.pkl'\n",
    "    data.to_pickle(pickle_file_path) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead4cb6a-667c-49b1-b0d6-fad97b625b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inhibitory_neurons_mat_chunk_2.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_3.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_13.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_9.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_1.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_5.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_6.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_16.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_11.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_14.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_7.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_4.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_15.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_12.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_8.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_10.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n",
      "inhibitory_neurons_mat_chunk_17.pkl\n",
      "Pickle file has been loaded into a DataFrame:\n"
     ]
    }
   ],
   "source": [
    "#pickle module used for serialization and deserialization\n",
    "import pickle\n",
    "# Load the DataFrame from the pickle file\n",
    "#data = pd.read_csv('../preprocessed_data/mat.csv')\n",
    "l = 0\n",
    "for i in os.listdir('../../preprocessed_data/inhibitory_neuron/split_chunks/'):\n",
    "    try:\n",
    "        if i.split('.')[1] == 'pkl':\n",
    "            print(i)\n",
    "            pickle_file_path = '../../preprocessed_data/inhibitory_neuron/split_chunks/' + i\n",
    "            if l == 0: \n",
    "                data = pd.read_pickle(pickle_file_path)\n",
    "                # to load data in the RAM (not possible to load all data once)\n",
    "                selected_columns = np.random.choice(data.columns, size=int(len(data.columns) *0.5), replace=False)\n",
    "                data = data[selected_columns]\n",
    "            else:\n",
    "                df = pd.read_pickle(pickle_file_path)\n",
    "                df_selected = df[selected_columns] # selected columns comimg from first time loaded data\n",
    "                data = pd.concat([data,df_selected],axis = 0)\n",
    "            \n",
    "            print(\"Pickle file has been loaded into a DataFrame:\")\n",
    "            l = l + 1       \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84773bd-2096-43b6-a5dc-9c58896a5bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTATCTAAGCGTGCTC.2.14</th>\n",
       "      <th>AGACACTTCAATCCGA.9.2</th>\n",
       "      <th>AGACACTCACAATGAA.1.9</th>\n",
       "      <th>GTCTAGACATGCGTGC.31.11</th>\n",
       "      <th>CATCGAATCCCATTAT.32.1</th>\n",
       "      <th>TCATTACCATCTCAAG.19.10</th>\n",
       "      <th>TGAGCGCCACCAGTAT.7.14</th>\n",
       "      <th>TAGAGTCAGTAAGCAT.8.7</th>\n",
       "      <th>GAGGGATCACATTGTG.11.3</th>\n",
       "      <th>GTGCTTCAGGGAGAAT.27.11</th>\n",
       "      <th>...</th>\n",
       "      <th>GATGAAACAGTCGATT.38.1</th>\n",
       "      <th>TCCTCTTTCCACCTGT.6.4</th>\n",
       "      <th>ACGCAGCTCTGTCTAT.39.1</th>\n",
       "      <th>AGCGTATTCCTTGCCA.1.1</th>\n",
       "      <th>GTAGATCAGTTTGTCG.22.2</th>\n",
       "      <th>CATGGATGTATGTCCA.16.4</th>\n",
       "      <th>AAAGGTAGTGGACCAA.26.10</th>\n",
       "      <th>AAAGTGAAGGAAAGGT.16.11</th>\n",
       "      <th>GCGAGAATCGCTAATG.16.7</th>\n",
       "      <th>TCCGGGATCTAGTTCT.21.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KRTCAP2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL713999.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRIM46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUC1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC234582.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC233755.2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC233755.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC240274.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC213203.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAM231C</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33538 rows × 164849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CTATCTAAGCGTGCTC.2.14  AGACACTTCAATCCGA.9.2  AGACACTCACAATGAA.1.9  \\\n",
       "KRTCAP2                         0                     0                     0   \n",
       "AL713999.1                      0                     0                     0   \n",
       "TRIM46                          0                     0                     0   \n",
       "MUC1                            0                     0                     0   \n",
       "AC234582.1                      0                     0                     0   \n",
       "...                           ...                   ...                   ...   \n",
       "AC233755.2                      0                     0                     0   \n",
       "AC233755.1                      0                     0                     0   \n",
       "AC240274.1                      0                     0                     0   \n",
       "AC213203.1                      0                     0                     0   \n",
       "FAM231C                         0                     0                     0   \n",
       "\n",
       "            GTCTAGACATGCGTGC.31.11  CATCGAATCCCATTAT.32.1  \\\n",
       "KRTCAP2                          0                      0   \n",
       "AL713999.1                       0                      0   \n",
       "TRIM46                           0                      0   \n",
       "MUC1                             0                      0   \n",
       "AC234582.1                       0                      0   \n",
       "...                            ...                    ...   \n",
       "AC233755.2                       0                      0   \n",
       "AC233755.1                       0                      0   \n",
       "AC240274.1                       0                      0   \n",
       "AC213203.1                       0                      0   \n",
       "FAM231C                          0                      0   \n",
       "\n",
       "            TCATTACCATCTCAAG.19.10  TGAGCGCCACCAGTAT.7.14  \\\n",
       "KRTCAP2                          0                      0   \n",
       "AL713999.1                       0                      0   \n",
       "TRIM46                           0                      0   \n",
       "MUC1                             0                      0   \n",
       "AC234582.1                       0                      0   \n",
       "...                            ...                    ...   \n",
       "AC233755.2                       0                      0   \n",
       "AC233755.1                       0                      0   \n",
       "AC240274.1                       0                      0   \n",
       "AC213203.1                       0                      0   \n",
       "FAM231C                          0                      0   \n",
       "\n",
       "            TAGAGTCAGTAAGCAT.8.7  GAGGGATCACATTGTG.11.3  \\\n",
       "KRTCAP2                        0                      0   \n",
       "AL713999.1                     0                      0   \n",
       "TRIM46                         0                      0   \n",
       "MUC1                           0                      0   \n",
       "AC234582.1                     0                      0   \n",
       "...                          ...                    ...   \n",
       "AC233755.2                     0                      0   \n",
       "AC233755.1                     0                      0   \n",
       "AC240274.1                     0                      0   \n",
       "AC213203.1                     0                      0   \n",
       "FAM231C                        0                      0   \n",
       "\n",
       "            GTGCTTCAGGGAGAAT.27.11  ...  GATGAAACAGTCGATT.38.1  \\\n",
       "KRTCAP2                          0  ...                      0   \n",
       "AL713999.1                       0  ...                      0   \n",
       "TRIM46                           1  ...                      0   \n",
       "MUC1                             0  ...                      0   \n",
       "AC234582.1                       0  ...                      0   \n",
       "...                            ...  ...                    ...   \n",
       "AC233755.2                       0  ...                      0   \n",
       "AC233755.1                       0  ...                      0   \n",
       "AC240274.1                       0  ...                      0   \n",
       "AC213203.1                       0  ...                      0   \n",
       "FAM231C                          0  ...                      0   \n",
       "\n",
       "            TCCTCTTTCCACCTGT.6.4  ACGCAGCTCTGTCTAT.39.1  AGCGTATTCCTTGCCA.1.1  \\\n",
       "KRTCAP2                        0                      0                     0   \n",
       "AL713999.1                     0                      0                     0   \n",
       "TRIM46                         0                      0                     0   \n",
       "MUC1                           0                      0                     0   \n",
       "AC234582.1                     0                      0                     0   \n",
       "...                          ...                    ...                   ...   \n",
       "AC233755.2                     0                      0                     0   \n",
       "AC233755.1                     0                      0                     0   \n",
       "AC240274.1                     0                      0                     0   \n",
       "AC213203.1                     0                      0                     0   \n",
       "FAM231C                        0                      0                     0   \n",
       "\n",
       "            GTAGATCAGTTTGTCG.22.2  CATGGATGTATGTCCA.16.4  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            AAAGGTAGTGGACCAA.26.10  AAAGTGAAGGAAAGGT.16.11  \\\n",
       "KRTCAP2                          0                       0   \n",
       "AL713999.1                       0                       0   \n",
       "TRIM46                           0                       0   \n",
       "MUC1                             0                       0   \n",
       "AC234582.1                       0                       0   \n",
       "...                            ...                     ...   \n",
       "AC233755.2                       0                       0   \n",
       "AC233755.1                       0                       0   \n",
       "AC240274.1                       0                       1   \n",
       "AC213203.1                       0                       0   \n",
       "FAM231C                          0                       0   \n",
       "\n",
       "            GCGAGAATCGCTAATG.16.7  TCCGGGATCTAGTTCT.21.9  \n",
       "KRTCAP2                         0                      0  \n",
       "AL713999.1                      0                      0  \n",
       "TRIM46                          0                      0  \n",
       "MUC1                            0                      0  \n",
       "AC234582.1                      1                      0  \n",
       "...                           ...                    ...  \n",
       "AC233755.2                      0                      0  \n",
       "AC233755.1                      0                      0  \n",
       "AC240274.1                      0                      0  \n",
       "AC213203.1                      0                      0  \n",
       "FAM231C                         0                      0  \n",
       "\n",
       "[33538 rows x 164849 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "#columns represent cells, rows represent genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296de2ff-8bca-42aa-94ac-e33441a94232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33538, 164849)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75223d8a-0fef-4812-945c-0289aac2d5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of             ATCCTATGTGGCAACA.31.6  AGTAGTCGTTGGAGGT.9.3  \\\n",
       "KRTCAP2                         0                     0   \n",
       "AL713999.1                      0                     0   \n",
       "TRIM46                          0                     0   \n",
       "MUC1                            0                     0   \n",
       "AC234582.1                      0                     0   \n",
       "...                           ...                   ...   \n",
       "AC233755.2                      0                     0   \n",
       "AC233755.1                      0                     0   \n",
       "AC240274.1                      0                     0   \n",
       "AC213203.1                      0                     0   \n",
       "FAM231C                         0                     0   \n",
       "\n",
       "            TCCTCTTGTTGGGTTT.6.12  AGAACAAAGTGATAGT.16.14  \\\n",
       "KRTCAP2                         0                       0   \n",
       "AL713999.1                      0                       0   \n",
       "TRIM46                          0                       1   \n",
       "MUC1                            0                       0   \n",
       "AC234582.1                      0                       0   \n",
       "...                           ...                     ...   \n",
       "AC233755.2                      0                       0   \n",
       "AC233755.1                      0                       0   \n",
       "AC240274.1                      0                       0   \n",
       "AC213203.1                      0                       0   \n",
       "FAM231C                         0                       0   \n",
       "\n",
       "            TCTTGCGCAAGCCCAC.15.14  GAACGTTTCGAAACAA.3.4  \\\n",
       "KRTCAP2                          0                     0   \n",
       "AL713999.1                       0                     0   \n",
       "TRIM46                           0                     0   \n",
       "MUC1                             0                     0   \n",
       "AC234582.1                       0                     0   \n",
       "...                            ...                   ...   \n",
       "AC233755.2                       0                     0   \n",
       "AC233755.1                       0                     0   \n",
       "AC240274.1                       0                     0   \n",
       "AC213203.1                       0                     0   \n",
       "FAM231C                          0                     0   \n",
       "\n",
       "            GCGCAACCAGCTTCGG.26.1  AACTCCCTCGCACTCT.6.1  \\\n",
       "KRTCAP2                         0                     0   \n",
       "AL713999.1                      0                     0   \n",
       "TRIM46                          0                     0   \n",
       "MUC1                            0                     0   \n",
       "AC234582.1                      0                     0   \n",
       "...                           ...                   ...   \n",
       "AC233755.2                      0                     0   \n",
       "AC233755.1                      0                     0   \n",
       "AC240274.1                      0                     0   \n",
       "AC213203.1                      0                     0   \n",
       "FAM231C                         0                     0   \n",
       "\n",
       "            GTCCTCACAGCACAAG.10.4  ACTGCTCTCATCACCC.18.1  ...  \\\n",
       "KRTCAP2                         0                      0  ...   \n",
       "AL713999.1                      0                      0  ...   \n",
       "TRIM46                          0                      0  ...   \n",
       "MUC1                            0                      0  ...   \n",
       "AC234582.1                      0                      0  ...   \n",
       "...                           ...                    ...  ...   \n",
       "AC233755.2                      0                      0  ...   \n",
       "AC233755.1                      0                      0  ...   \n",
       "AC240274.1                      0                      0  ...   \n",
       "AC213203.1                      0                      0  ...   \n",
       "FAM231C                         0                      0  ...   \n",
       "\n",
       "            GTAGCTATCCCGAGGT.15.8  TCCACACAGGGTGTGT.23.1  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            CTGCCTATCATAACCG.13.0  GACGCTGAGATGATTG.4.10  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            AACTTTCCACCCATTC.38.1  TGATTCTAGTGAGTTA.24.8  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            TTACTGTCAGGTGTTT.27.11  CAATACGAGCACTCAT.13.11  \\\n",
       "KRTCAP2                          0                       0   \n",
       "AL713999.1                       0                       0   \n",
       "TRIM46                           0                       1   \n",
       "MUC1                             0                       0   \n",
       "AC234582.1                       0                       0   \n",
       "...                            ...                     ...   \n",
       "AC233755.2                       0                       0   \n",
       "AC233755.1                       0                       0   \n",
       "AC240274.1                       0                       0   \n",
       "AC213203.1                       0                       0   \n",
       "FAM231C                          0                       0   \n",
       "\n",
       "            GTGGCGTAGTATAGAC.8.9  GATGACTGTTCTCACC.5.12  \n",
       "KRTCAP2                        0                      0  \n",
       "AL713999.1                     0                      0  \n",
       "TRIM46                         0                      0  \n",
       "MUC1                           0                      0  \n",
       "AC234582.1                     0                      0  \n",
       "...                          ...                    ...  \n",
       "AC233755.2                     0                      0  \n",
       "AC233755.1                     0                      0  \n",
       "AC240274.1                     0                      0  \n",
       "AC213203.1                     0                      0  \n",
       "FAM231C                        0                      0  \n",
       "\n",
       "[33538 rows x 164849 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc6425b-960d-4ce7-8ed7-10ee9d185b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRTCAP2         739\n",
      "AL713999.1     1882\n",
      "TRIM46        25200\n",
      "MUC1             54\n",
      "AC234582.1     1545\n",
      "              ...  \n",
      "AC233755.2        0\n",
      "AC233755.1        0\n",
      "AC240274.1    10404\n",
      "AC213203.1        1\n",
      "FAM231C           3\n",
      "Length: 33538, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "row_sum = data.sum(axis=1)\n",
    "\n",
    "print(row_sum)\n",
    "#total number of times the gene is expressed for all cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf262a14-34bb-42cf-8225-b8d330a73991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTATCTAAGCGTGCTC.2.14      8627\n",
       "AGACACTTCAATCCGA.9.2      27682\n",
       "AGACACTCACAATGAA.1.9       9713\n",
       "GTCTAGACATGCGTGC.31.11    10470\n",
       "CATCGAATCCCATTAT.32.1      3153\n",
       "                          ...  \n",
       "CATGGATGTATGTCCA.16.4      1261\n",
       "AAAGGTAGTGGACCAA.26.10    20264\n",
       "AAAGTGAAGGAAAGGT.16.11    12329\n",
       "GCGAGAATCGCTAATG.16.7     19212\n",
       "TCCGGGATCTAGTTCT.21.9     14407\n",
       "Length: 164849, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_sum = data.sum(axis=0)\n",
    "col_sum\n",
    "#total gene count for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98355b4-b5fd-4ae7-83d5-d80634f6b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data = pd.read_csv('/12tb_dsk1/danish/preprocessed_data/clinical/clinical_single_cell.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88c360c-2ad7-4ff2-b06b-b93c9522e7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individualID</th>\n",
       "      <th>individualIdSource</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>subject</th>\n",
       "      <th>projid</th>\n",
       "      <th>Study</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>...</th>\n",
       "      <th>age_death</th>\n",
       "      <th>cts_mmse30_first_ad_dx</th>\n",
       "      <th>cts_mmse30_lv</th>\n",
       "      <th>braaksc</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>dcfdx_lv</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2626559</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>ROSMAP-45310</td>\n",
       "      <td>1211411</td>\n",
       "      <td>ROS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.549624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>No AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R9936070</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>ROSMAP-34387</td>\n",
       "      <td>2899847</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.450376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R2367199</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>ROSMAP-69520</td>\n",
       "      <td>3713990</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.928816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R9891381</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>ROSMAP-53306</td>\n",
       "      <td>3889845</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R9033345</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>ROSMAP-79585</td>\n",
       "      <td>6107196</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  individualID individualIdSource     sex  ethnicity   pmi_df2       subject  \\\n",
       "0     R2626559               Rush    male        NaN  6.500000  ROSMAP-45310   \n",
       "1     R9936070               Rush    male        NaN  7.016667  ROSMAP-34387   \n",
       "2     R2367199               Rush    male        NaN  4.333333  ROSMAP-69520   \n",
       "3     R9891381               Rush  female        NaN  6.916667  ROSMAP-53306   \n",
       "4     R9033345               Rush    male        NaN  4.166667  ROSMAP-79585   \n",
       "\n",
       "    projid Study  msex  educ  ...  age_death  cts_mmse30_first_ad_dx  \\\n",
       "0  1211411   ROS   1.0  12.0  ...  85.549624                     NaN   \n",
       "1  2899847   MAP   1.0  14.0  ...  74.450376                     NaN   \n",
       "2  3713990   MAP   1.0  12.0  ...  87.928816                     NaN   \n",
       "3  3889845   MAP   0.0  13.0  ...  90.000000                     NaN   \n",
       "4  6107196   MAP   1.0  15.0  ...  90.000000                     NaN   \n",
       "\n",
       "  cts_mmse30_lv braaksc  ceradsc  cogdx  dcfdx_lv  clinical_diagnosis  \\\n",
       "0          24.0     1.0      4.0    4.0       4.0                  AD   \n",
       "1          27.0     2.0      2.0    3.0       3.0               False   \n",
       "2          30.0     4.0      2.0    1.0       1.0                 NCI   \n",
       "3          22.0     2.0      1.0    2.0       2.0               False   \n",
       "4          22.0     5.0      1.0    4.0       4.0                  AD   \n",
       "\n",
       "   pathological_diagnosis  clinical_pathological_AD  \n",
       "0                   No AD                     False  \n",
       "1                   False                     False  \n",
       "2                   False                     False  \n",
       "3                      AD                     False  \n",
       "4                      AD           AD_with_Plaques  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69eba35b-654f-49a7-aca4-46e1704d7bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data.shape\n",
    "#we have 514 subjects. there are 24 columns that give the characteristics of these subjects and whether or not they are in the AD group or control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e826f3dc-2890-4721-acea-38b94839dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_metadata = pd.read_csv('../../preprocessed_data/inhibitory_neuron/metadata_inhibitory_neurons.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a886831-150c-4131-8908-a4c4890e6c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAACGCGT.6.6</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>2651</td>\n",
       "      <td>1533</td>\n",
       "      <td>8.185590</td>\n",
       "      <td>0.452659</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-90639</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAACTGAT.10.12</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAGCGGG.31.8</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAATCCCT.14.8</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15297</td>\n",
       "      <td>4688</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-68841</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTAGCAG.7.9</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9309</td>\n",
       "      <td>3459</td>\n",
       "      <td>2.062520</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.891670</td>\n",
       "      <td>Inh VIP TSHZ2</td>\n",
       "      <td>ROSMAP-77886</td>\n",
       "      <td>no</td>\n",
       "      <td>R2554598</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTCCCGA.28.6</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTCGACC.3.13</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>16770</td>\n",
       "      <td>5431</td>\n",
       "      <td>2.098986</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-53472</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTGGTGA.8.11</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTTGCAT.22.8</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15282</td>\n",
       "      <td>4330</td>\n",
       "      <td>3.291454</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>0.869104</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-22203</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329699 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       orig.ident  nCount_RNA  nFeature_RNA  percent.mt  \\\n",
       "cell_id                                                                   \n",
       "AAACCCAAGAAATCCA.12.9      ROSMAP       13490          4276    0.237213   \n",
       "AAACCCAAGAACGCGT.6.6       ROSMAP        2651          1533    8.185590   \n",
       "AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764    4.809160   \n",
       "AAACCCAAGAAGCGGG.31.8      ROSMAP       11658          4377    5.738549   \n",
       "AAACCCAAGAATCCCT.14.8      ROSMAP       15297          4688    0.921749   \n",
       "...                           ...         ...           ...         ...   \n",
       "TTTGTTGTCTTAGCAG.7.9       ROSMAP        9309          3459    2.062520   \n",
       "TTTGTTGTCTTCCCGA.28.6      ROSMAP       22844          5507    0.153213   \n",
       "TTTGTTGTCTTCGACC.3.13      ROSMAP       16770          5431    2.098986   \n",
       "TTTGTTGTCTTGGTGA.8.11      ROSMAP        9475          3447    0.147757   \n",
       "TTTGTTGTCTTTGCAT.22.8      ROSMAP       15282          4330    3.291454   \n",
       "\n",
       "                        percent.rb  log10GenesPerUMI  \\\n",
       "cell_id                                                \n",
       "AAACCCAAGAAATCCA.12.9     0.289103          0.879183   \n",
       "AAACCCAAGAACGCGT.6.6      0.452659          0.930517   \n",
       "AAACCCAAGAACTGAT.10.12    0.274809          0.901814   \n",
       "AAACCCAAGAAGCGGG.31.8     0.394579          0.895381   \n",
       "AAACCCAAGAATCCCT.14.8     0.307250          0.877260   \n",
       "...                            ...               ...   \n",
       "TTTGTTGTCTTAGCAG.7.9      0.225588          0.891670   \n",
       "TTTGTTGTCTTCCCGA.28.6     0.358956          0.858250   \n",
       "TTTGTTGTCTTCGACC.3.13     0.679785          0.884093   \n",
       "TTTGTTGTCTTGGTGA.8.11     0.179420          0.889569   \n",
       "TTTGTTGTCTTTGCAT.22.8     0.261746          0.869104   \n",
       "\n",
       "                       cell_type_high_resolution       subject  \\\n",
       "cell_id                                                          \n",
       "AAACCCAAGAAATCCA.12.9          Inh L3-5 SST MAFB  ROSMAP-65967   \n",
       "AAACCCAAGAACGCGT.6.6           Inh L3-5 SST MAFB  ROSMAP-90639   \n",
       "AAACCCAAGAACTGAT.10.12            Inh LAMP5 RELN  ROSMAP-57958   \n",
       "AAACCCAAGAAGCGGG.31.8             Inh VIP CLSTN2  ROSMAP-40761   \n",
       "AAACCCAAGAATCCCT.14.8             Inh VIP CLSTN2  ROSMAP-68841   \n",
       "...                                          ...           ...   \n",
       "TTTGTTGTCTTAGCAG.7.9               Inh VIP TSHZ2  ROSMAP-77886   \n",
       "TTTGTTGTCTTCCCGA.28.6            Inh PVALB SULF1  ROSMAP-38931   \n",
       "TTTGTTGTCTTCGACC.3.13              Inh CUX2 MSR1  ROSMAP-53472   \n",
       "TTTGTTGTCTTGGTGA.8.11             Inh VIP ABI3BP  ROSMAP-44788   \n",
       "TTTGTTGTCTTTGCAT.22.8             Inh PVALB HTR4  ROSMAP-22203   \n",
       "\n",
       "                       Pathologic_diagnosis_of_AD individualID  \\\n",
       "cell_id                                                          \n",
       "AAACCCAAGAAATCCA.12.9                         yes     R3857147   \n",
       "AAACCCAAGAACGCGT.6.6                          yes     R7090624   \n",
       "AAACCCAAGAACTGAT.10.12                        yes     R2347173   \n",
       "AAACCCAAGAAGCGGG.31.8                         yes     R1287407   \n",
       "AAACCCAAGAATCCCT.14.8                         yes     R3757880   \n",
       "...                                           ...          ...   \n",
       "TTTGTTGTCTTAGCAG.7.9                           no     R2554598   \n",
       "TTTGTTGTCTTCCCGA.28.6                          no     R6292415   \n",
       "TTTGTTGTCTTCGACC.3.13                         yes     R3863249   \n",
       "TTTGTTGTCTTGGTGA.8.11                          no     R5221394   \n",
       "TTTGTTGTCTTTGCAT.22.8                         yes     R7583108   \n",
       "\n",
       "                       clinical_diagnosis pathological_diagnosis  \\\n",
       "cell_id                                                            \n",
       "AAACCCAAGAAATCCA.12.9                  AD                     AD   \n",
       "AAACCCAAGAACGCGT.6.6                  NCI                     AD   \n",
       "AAACCCAAGAACTGAT.10.12                NCI                     AD   \n",
       "AAACCCAAGAAGCGGG.31.8               False                     AD   \n",
       "AAACCCAAGAATCCCT.14.8                 NCI                     AD   \n",
       "...                                   ...                    ...   \n",
       "TTTGTTGTCTTAGCAG.7.9                  NCI                  False   \n",
       "TTTGTTGTCTTCCCGA.28.6                 NCI                  No AD   \n",
       "TTTGTTGTCTTCGACC.3.13               False                  False   \n",
       "TTTGTTGTCTTGGTGA.8.11                 NCI                  No AD   \n",
       "TTTGTTGTCTTTGCAT.22.8                  AD                     AD   \n",
       "\n",
       "                       clinical_pathological_AD  \\\n",
       "cell_id                                           \n",
       "AAACCCAAGAAATCCA.12.9           AD_with_Plaques   \n",
       "AAACCCAAGAACGCGT.6.6                      False   \n",
       "AAACCCAAGAACTGAT.10.12                    False   \n",
       "AAACCCAAGAAGCGGG.31.8                     False   \n",
       "AAACCCAAGAATCCCT.14.8                     False   \n",
       "...                                         ...   \n",
       "TTTGTTGTCTTAGCAG.7.9                      False   \n",
       "TTTGTTGTCTTCCCGA.28.6       NCI_with_No_Plaques   \n",
       "TTTGTTGTCTTCGACC.3.13                     False   \n",
       "TTTGTTGTCTTGGTGA.8.11       NCI_with_No_Plaques   \n",
       "TTTGTTGTCTTTGCAT.22.8           AD_with_Plaques   \n",
       "\n",
       "                       train_test_clinical_and_pathological  \n",
       "cell_id                                                      \n",
       "AAACCCAAGAAATCCA.12.9                                 train  \n",
       "AAACCCAAGAACGCGT.6.6                                    NaN  \n",
       "AAACCCAAGAACTGAT.10.12                                  NaN  \n",
       "AAACCCAAGAAGCGGG.31.8                                   NaN  \n",
       "AAACCCAAGAATCCCT.14.8                                   NaN  \n",
       "...                                                     ...  \n",
       "TTTGTTGTCTTAGCAG.7.9                                    NaN  \n",
       "TTTGTTGTCTTCCCGA.28.6                                 train  \n",
       "TTTGTTGTCTTCGACC.3.13                                   NaN  \n",
       "TTTGTTGTCTTGGTGA.8.11                                  test  \n",
       "TTTGTTGTCTTTGCAT.22.8                                 train  \n",
       "\n",
       "[329699 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7fac08b-dc32-40d9-80f0-c523be8c79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably not needed to do\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAACGCGT.6.6</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>2651</td>\n",
       "      <td>1533</td>\n",
       "      <td>8.185590</td>\n",
       "      <td>0.452659</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-90639</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAACTGAT.10.12</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAGCGGG.31.8</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAATCCCT.14.8</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15297</td>\n",
       "      <td>4688</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-68841</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       orig.ident  nCount_RNA  nFeature_RNA  percent.mt  \\\n",
       "cell_id                                                                   \n",
       "AAACCCAAGAAATCCA.12.9      ROSMAP       13490          4276    0.237213   \n",
       "AAACCCAAGAACGCGT.6.6       ROSMAP        2651          1533    8.185590   \n",
       "AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764    4.809160   \n",
       "AAACCCAAGAAGCGGG.31.8      ROSMAP       11658          4377    5.738549   \n",
       "AAACCCAAGAATCCCT.14.8      ROSMAP       15297          4688    0.921749   \n",
       "\n",
       "                        percent.rb  log10GenesPerUMI  \\\n",
       "cell_id                                                \n",
       "AAACCCAAGAAATCCA.12.9     0.289103          0.879183   \n",
       "AAACCCAAGAACGCGT.6.6      0.452659          0.930517   \n",
       "AAACCCAAGAACTGAT.10.12    0.274809          0.901814   \n",
       "AAACCCAAGAAGCGGG.31.8     0.394579          0.895381   \n",
       "AAACCCAAGAATCCCT.14.8     0.307250          0.877260   \n",
       "\n",
       "                       cell_type_high_resolution       subject  \\\n",
       "cell_id                                                          \n",
       "AAACCCAAGAAATCCA.12.9          Inh L3-5 SST MAFB  ROSMAP-65967   \n",
       "AAACCCAAGAACGCGT.6.6           Inh L3-5 SST MAFB  ROSMAP-90639   \n",
       "AAACCCAAGAACTGAT.10.12            Inh LAMP5 RELN  ROSMAP-57958   \n",
       "AAACCCAAGAAGCGGG.31.8             Inh VIP CLSTN2  ROSMAP-40761   \n",
       "AAACCCAAGAATCCCT.14.8             Inh VIP CLSTN2  ROSMAP-68841   \n",
       "\n",
       "                       Pathologic_diagnosis_of_AD individualID  \\\n",
       "cell_id                                                          \n",
       "AAACCCAAGAAATCCA.12.9                         yes     R3857147   \n",
       "AAACCCAAGAACGCGT.6.6                          yes     R7090624   \n",
       "AAACCCAAGAACTGAT.10.12                        yes     R2347173   \n",
       "AAACCCAAGAAGCGGG.31.8                         yes     R1287407   \n",
       "AAACCCAAGAATCCCT.14.8                         yes     R3757880   \n",
       "\n",
       "                       clinical_diagnosis pathological_diagnosis  \\\n",
       "cell_id                                                            \n",
       "AAACCCAAGAAATCCA.12.9                  AD                     AD   \n",
       "AAACCCAAGAACGCGT.6.6                  NCI                     AD   \n",
       "AAACCCAAGAACTGAT.10.12                NCI                     AD   \n",
       "AAACCCAAGAAGCGGG.31.8               False                     AD   \n",
       "AAACCCAAGAATCCCT.14.8                 NCI                     AD   \n",
       "\n",
       "                       clinical_pathological_AD  \\\n",
       "cell_id                                           \n",
       "AAACCCAAGAAATCCA.12.9           AD_with_Plaques   \n",
       "AAACCCAAGAACGCGT.6.6                      False   \n",
       "AAACCCAAGAACTGAT.10.12                    False   \n",
       "AAACCCAAGAAGCGGG.31.8                     False   \n",
       "AAACCCAAGAATCCCT.14.8                     False   \n",
       "\n",
       "                       train_test_clinical_and_pathological  \n",
       "cell_id                                                      \n",
       "AAACCCAAGAAATCCA.12.9                                 train  \n",
       "AAACCCAAGAACGCGT.6.6                                    NaN  \n",
       "AAACCCAAGAACTGAT.10.12                                  NaN  \n",
       "AAACCCAAGAAGCGGG.31.8                                   NaN  \n",
       "AAACCCAAGAATCCCT.14.8                                   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    single_cell_metadata['cell_id'] = single_cell_metadata['cell_id'].str.replace('-', '.')\n",
    "except:\n",
    "    print('probably not needed to do')\n",
    "single_cell_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16b34770-c60e-41fa-bcdc-2df464924ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAACGCGT.6.6</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>2651</td>\n",
       "      <td>1533</td>\n",
       "      <td>8.185590</td>\n",
       "      <td>0.452659</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-90639</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAACTGAT.10.12</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAGCGGG.31.8</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAATCCCT.14.8</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15297</td>\n",
       "      <td>4688</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-68841</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTAGCAG.7.9</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9309</td>\n",
       "      <td>3459</td>\n",
       "      <td>2.062520</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.891670</td>\n",
       "      <td>Inh VIP TSHZ2</td>\n",
       "      <td>ROSMAP-77886</td>\n",
       "      <td>no</td>\n",
       "      <td>R2554598</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTCCCGA.28.6</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTCGACC.3.13</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>16770</td>\n",
       "      <td>5431</td>\n",
       "      <td>2.098986</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-53472</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTGGTGA.8.11</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTTGCAT.22.8</th>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15282</td>\n",
       "      <td>4330</td>\n",
       "      <td>3.291454</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>0.869104</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-22203</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329699 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       orig.ident  nCount_RNA  nFeature_RNA  percent.mt  \\\n",
       "cell_id                                                                   \n",
       "AAACCCAAGAAATCCA.12.9      ROSMAP       13490          4276    0.237213   \n",
       "AAACCCAAGAACGCGT.6.6       ROSMAP        2651          1533    8.185590   \n",
       "AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764    4.809160   \n",
       "AAACCCAAGAAGCGGG.31.8      ROSMAP       11658          4377    5.738549   \n",
       "AAACCCAAGAATCCCT.14.8      ROSMAP       15297          4688    0.921749   \n",
       "...                           ...         ...           ...         ...   \n",
       "TTTGTTGTCTTAGCAG.7.9       ROSMAP        9309          3459    2.062520   \n",
       "TTTGTTGTCTTCCCGA.28.6      ROSMAP       22844          5507    0.153213   \n",
       "TTTGTTGTCTTCGACC.3.13      ROSMAP       16770          5431    2.098986   \n",
       "TTTGTTGTCTTGGTGA.8.11      ROSMAP        9475          3447    0.147757   \n",
       "TTTGTTGTCTTTGCAT.22.8      ROSMAP       15282          4330    3.291454   \n",
       "\n",
       "                        percent.rb  log10GenesPerUMI  \\\n",
       "cell_id                                                \n",
       "AAACCCAAGAAATCCA.12.9     0.289103          0.879183   \n",
       "AAACCCAAGAACGCGT.6.6      0.452659          0.930517   \n",
       "AAACCCAAGAACTGAT.10.12    0.274809          0.901814   \n",
       "AAACCCAAGAAGCGGG.31.8     0.394579          0.895381   \n",
       "AAACCCAAGAATCCCT.14.8     0.307250          0.877260   \n",
       "...                            ...               ...   \n",
       "TTTGTTGTCTTAGCAG.7.9      0.225588          0.891670   \n",
       "TTTGTTGTCTTCCCGA.28.6     0.358956          0.858250   \n",
       "TTTGTTGTCTTCGACC.3.13     0.679785          0.884093   \n",
       "TTTGTTGTCTTGGTGA.8.11     0.179420          0.889569   \n",
       "TTTGTTGTCTTTGCAT.22.8     0.261746          0.869104   \n",
       "\n",
       "                       cell_type_high_resolution       subject  \\\n",
       "cell_id                                                          \n",
       "AAACCCAAGAAATCCA.12.9          Inh L3-5 SST MAFB  ROSMAP-65967   \n",
       "AAACCCAAGAACGCGT.6.6           Inh L3-5 SST MAFB  ROSMAP-90639   \n",
       "AAACCCAAGAACTGAT.10.12            Inh LAMP5 RELN  ROSMAP-57958   \n",
       "AAACCCAAGAAGCGGG.31.8             Inh VIP CLSTN2  ROSMAP-40761   \n",
       "AAACCCAAGAATCCCT.14.8             Inh VIP CLSTN2  ROSMAP-68841   \n",
       "...                                          ...           ...   \n",
       "TTTGTTGTCTTAGCAG.7.9               Inh VIP TSHZ2  ROSMAP-77886   \n",
       "TTTGTTGTCTTCCCGA.28.6            Inh PVALB SULF1  ROSMAP-38931   \n",
       "TTTGTTGTCTTCGACC.3.13              Inh CUX2 MSR1  ROSMAP-53472   \n",
       "TTTGTTGTCTTGGTGA.8.11             Inh VIP ABI3BP  ROSMAP-44788   \n",
       "TTTGTTGTCTTTGCAT.22.8             Inh PVALB HTR4  ROSMAP-22203   \n",
       "\n",
       "                       Pathologic_diagnosis_of_AD individualID  \\\n",
       "cell_id                                                          \n",
       "AAACCCAAGAAATCCA.12.9                         yes     R3857147   \n",
       "AAACCCAAGAACGCGT.6.6                          yes     R7090624   \n",
       "AAACCCAAGAACTGAT.10.12                        yes     R2347173   \n",
       "AAACCCAAGAAGCGGG.31.8                         yes     R1287407   \n",
       "AAACCCAAGAATCCCT.14.8                         yes     R3757880   \n",
       "...                                           ...          ...   \n",
       "TTTGTTGTCTTAGCAG.7.9                           no     R2554598   \n",
       "TTTGTTGTCTTCCCGA.28.6                          no     R6292415   \n",
       "TTTGTTGTCTTCGACC.3.13                         yes     R3863249   \n",
       "TTTGTTGTCTTGGTGA.8.11                          no     R5221394   \n",
       "TTTGTTGTCTTTGCAT.22.8                         yes     R7583108   \n",
       "\n",
       "                       clinical_diagnosis pathological_diagnosis  \\\n",
       "cell_id                                                            \n",
       "AAACCCAAGAAATCCA.12.9                  AD                     AD   \n",
       "AAACCCAAGAACGCGT.6.6                  NCI                     AD   \n",
       "AAACCCAAGAACTGAT.10.12                NCI                     AD   \n",
       "AAACCCAAGAAGCGGG.31.8               False                     AD   \n",
       "AAACCCAAGAATCCCT.14.8                 NCI                     AD   \n",
       "...                                   ...                    ...   \n",
       "TTTGTTGTCTTAGCAG.7.9                  NCI                  False   \n",
       "TTTGTTGTCTTCCCGA.28.6                 NCI                  No AD   \n",
       "TTTGTTGTCTTCGACC.3.13               False                  False   \n",
       "TTTGTTGTCTTGGTGA.8.11                 NCI                  No AD   \n",
       "TTTGTTGTCTTTGCAT.22.8                  AD                     AD   \n",
       "\n",
       "                       clinical_pathological_AD  \\\n",
       "cell_id                                           \n",
       "AAACCCAAGAAATCCA.12.9           AD_with_Plaques   \n",
       "AAACCCAAGAACGCGT.6.6                      False   \n",
       "AAACCCAAGAACTGAT.10.12                    False   \n",
       "AAACCCAAGAAGCGGG.31.8                     False   \n",
       "AAACCCAAGAATCCCT.14.8                     False   \n",
       "...                                         ...   \n",
       "TTTGTTGTCTTAGCAG.7.9                      False   \n",
       "TTTGTTGTCTTCCCGA.28.6       NCI_with_No_Plaques   \n",
       "TTTGTTGTCTTCGACC.3.13                     False   \n",
       "TTTGTTGTCTTGGTGA.8.11       NCI_with_No_Plaques   \n",
       "TTTGTTGTCTTTGCAT.22.8           AD_with_Plaques   \n",
       "\n",
       "                       train_test_clinical_and_pathological  \n",
       "cell_id                                                      \n",
       "AAACCCAAGAAATCCA.12.9                                 train  \n",
       "AAACCCAAGAACGCGT.6.6                                    NaN  \n",
       "AAACCCAAGAACTGAT.10.12                                  NaN  \n",
       "AAACCCAAGAAGCGGG.31.8                                   NaN  \n",
       "AAACCCAAGAATCCCT.14.8                                   NaN  \n",
       "...                                                     ...  \n",
       "TTTGTTGTCTTAGCAG.7.9                                    NaN  \n",
       "TTTGTTGTCTTCCCGA.28.6                                 train  \n",
       "TTTGTTGTCTTCGACC.3.13                                   NaN  \n",
       "TTTGTTGTCTTGGTGA.8.11                                  test  \n",
       "TTTGTTGTCTTTGCAT.22.8                                 train  \n",
       "\n",
       "[329699 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7768eb-0d29-4512-9ccd-f257243727f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_metadata = single_cell_metadata.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a12b331b-bae9-4bc6-9ee3-064b7da56575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cell_id', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt',\n",
      "       'percent.rb', 'log10GenesPerUMI', 'cell_type_high_resolution',\n",
      "       'subject', 'Pathologic_diagnosis_of_AD', 'individualID',\n",
      "       'clinical_diagnosis', 'pathological_diagnosis',\n",
      "       'clinical_pathological_AD', 'train_test_clinical_and_pathological'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(single_cell_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c7d21ff-143a-4135-ae07-d095b401f4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.columns) - set(single_cell_metadata['cell_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91279b97-d755-4061-a386-ebf72e57bdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TTGACTTAGGCTAGGT.17.1',\n",
       " 'AGATCCAAGCATCGAG.15.2',\n",
       " 'TCATCCGCAGCTGGTC.26.8',\n",
       " 'GGCTGTGTCATTCTTG.31.8',\n",
       " 'AGGTCTAAGAAGAGCA.23.6',\n",
       " 'TTTACTGAGCTGTACT.19.5',\n",
       " 'TCAGCAAGTAGCTGCC.11.8',\n",
       " 'GTGAAGGTCTGTACGA.23.1',\n",
       " 'GATCATGAGTGATTCC.10.11',\n",
       " 'GACGTTAAGCCTGAAG.29.2',\n",
       " 'GCACGGTAGACCATTC.7.11',\n",
       " 'AATGAAGCATGTGTCA.26.4',\n",
       " 'TAGACTGCATCCTGTC.15.11',\n",
       " 'TTGGATGTCGTCGGGT.13.11',\n",
       " 'GATCACACATCAGCTA.28.4',\n",
       " 'GAGACCCTCATTGCCC.16.2',\n",
       " 'GTCATGATCTGCTCTG.16.11',\n",
       " 'GTGTAACCAAATGGCG.23.2',\n",
       " 'CATTGCCTCATAGCAC.28.2',\n",
       " 'CTCAGGGAGATACATG.4.14',\n",
       " 'GTGGTTAGTGTTGACT.26.6',\n",
       " 'ATAGGCTAGACAACAT.5.7',\n",
       " 'CTTCTCTCACGTCATA.32.11',\n",
       " 'TCCTGCATCCCTGTTG.14.14',\n",
       " 'AGCCACGCAGTATACC.7.9',\n",
       " 'GATGTTGTCAAGAATG.31.9',\n",
       " 'ACAGAAACAATGTGGG.21.11',\n",
       " 'TAAGCGTGTGCCTGAC.4.5',\n",
       " 'CATGACAAGGGTGTTG.4.1',\n",
       " 'ATACCGAAGTTGAAGT.18.4',\n",
       " 'TGCTCCATCGAACGGA.26.10',\n",
       " 'TAACCAGCACGTAGTT.31.9',\n",
       " 'TGAGCATCACGAGGAT.27.11',\n",
       " 'CCTAACCGTTCTCCTG.24.3',\n",
       " 'ATCACGATCCGTAATG.24.7',\n",
       " 'CTATCCGCATAGCTGT.13.11',\n",
       " 'CATCAAGCAAAGCTCT.6.12',\n",
       " 'TAACTTCGTTCCGCAG.12.7',\n",
       " 'GAGTGTTCAGTTTCAG.10.12',\n",
       " 'CCAATGAAGGGTTGCA.11.14',\n",
       " 'AGAATAGCATTAGCCA.32.0',\n",
       " 'GCGACCACACCTCGGA.32.0',\n",
       " 'TTCCTAATCTCGCAGG.21.6',\n",
       " 'TCCCACACATCGGAGA.10.2',\n",
       " 'GCAACCGGTACTTGTG.29.6',\n",
       " 'AAAGGATTCAAGCTTG.24.11',\n",
       " 'GGGAAGTGTCTACGAT.19.10',\n",
       " 'CTACCCAAGTCTGCGC.8.12',\n",
       " 'CATCAGAAGAAGGGTA.35.1',\n",
       " 'ACGGGTCCAAGGCCTC.24.2',\n",
       " 'TATACCTCATGTCAGT.16.3',\n",
       " 'AGCTTCCCAAGATCCT.11.11',\n",
       " 'GGTGTTAGTAAGGTCG.1.13',\n",
       " 'TTGGTTTTCATGCCGG.13.14',\n",
       " 'TGTGATGTCACCCTTG.28.11',\n",
       " 'TCACAAGTCTTGATTC.30.2',\n",
       " 'GTATTTCCATTGAGGG.6.3',\n",
       " 'CGTGTCTAGCGCCCAT.27.8',\n",
       " 'CTCCAACCATACAGGG.28.2',\n",
       " 'ACTATGGAGCAGTAAT.12.10',\n",
       " 'ACAGCCGAGTTGAGAT.15.0',\n",
       " 'AGCGCTGGTAATTGGA.18.11',\n",
       " 'CCGTTCATCGAGTACT.22.10',\n",
       " 'TACTTGTAGTGGTTGG.7.9',\n",
       " 'ATTATCCTCACTGTCC.25.9',\n",
       " 'TTGTGGAAGTGATCGG.32.5',\n",
       " 'ACTGATGAGCCACGTC.21.0',\n",
       " 'GATGATCTCTTCCCAG.10.9',\n",
       " 'CCGGGTACAGCACAAG.31.5',\n",
       " 'AGATCCACAGAACTCT.7.6',\n",
       " 'CAGTTCCCACAAATCC.13.11',\n",
       " 'AAATGGACAGCTTTCC.25.10',\n",
       " 'TCATCCGAGAGTGGCT.24.6',\n",
       " 'TCCCATGAGCGGTATG.10.4',\n",
       " 'CCCGAAGCACCCAACG.2.7',\n",
       " 'ACCAACATCGTCAGAT.17.10',\n",
       " 'ATGCGATGTATCACCA.7.13',\n",
       " 'CAAAGAACATACAGCT.14.2',\n",
       " 'ATGATCGAGTCATTGC.13.6',\n",
       " 'TTCCAATAGCAAGTCG.32.11',\n",
       " 'GGGCATCCATTGCGGC.19.1',\n",
       " 'ATATCCTGTGTACATC.21.6',\n",
       " 'CGATCGGGTAGATTGA.13.11',\n",
       " 'CCACTACCAGTTTACG.33.1',\n",
       " 'CATCAAGTCCTAGAAC.34.1',\n",
       " 'CTCAGTCAGCTGGCTC.11.11',\n",
       " 'CCTCTCCTCCTGTAGA.31.6',\n",
       " 'GGGTTATTCTGCTCTG.20.6',\n",
       " 'GAGTCTAAGACCAAAT.25.5',\n",
       " 'ATATCCTCATGTGGTT.7.13',\n",
       " 'AGTAGTCCACGCTATA.11.11',\n",
       " 'GTTGTGACAAGCTCTA.5.5',\n",
       " 'CCCAGTTAGGAGTTTA.16.1',\n",
       " 'AGAGCAGTCGATCCAA.11.9',\n",
       " 'GCCCAGAAGCGACATG.8.9',\n",
       " 'ATCGTAGGTTTGGGTT.16.2',\n",
       " 'AGAAGTAGTTGCCGAC.43.2',\n",
       " 'GTAATGCTCCTGCCAT.1.9',\n",
       " 'CCATAAGAGACGAGCT.9.7',\n",
       " 'GCACGGTAGATCGCTT.26.5',\n",
       " 'TCACAAGCAAGTATAG.15.4',\n",
       " 'CCTCCTCAGGATACAT.2.9',\n",
       " 'TCCATGCCAAGCGCTC.21.6',\n",
       " 'TCGCTCAAGGGTAATT.9.14',\n",
       " 'TACTTACCAATAGGAT.10.9',\n",
       " 'CATCAAGCAGCCTACG.5.2',\n",
       " 'GCATGATTCAAGTAAG.2.11',\n",
       " 'CTCGAGGAGACCTCCG.1.12',\n",
       " 'AGCTTGATCGAGAACG.30.1',\n",
       " 'GTTATGGTCTCAATCT.19.4',\n",
       " 'ATTTCACAGCGCCTCA.6.11',\n",
       " 'ATTCCTAGTAGACAGC.27.2',\n",
       " 'GTTTGGACAAATCGGG.7.14',\n",
       " 'AGCATCACATGACGAG.12.14',\n",
       " 'CGGAATTCACTTCCTG.4.14',\n",
       " 'CACAGATGTTTCGTGA.12.10',\n",
       " 'TTCACCGAGGAAGTCC.1.12',\n",
       " 'TTCCAATTCCACACCT.21.4',\n",
       " 'ATGCATGAGCCTTCTC.20.3',\n",
       " 'TTTCCTCAGCATACTC.20.6',\n",
       " 'GGCGTCAGTACTGCCG.12.10',\n",
       " 'GTTGTCCAGTGTAGAT.6.9',\n",
       " 'TTCTGTACAAGGCGTA.32.6',\n",
       " 'CATGCTCTCACGATCA.15.14',\n",
       " 'CGTGATATCACTGTTT.31.8',\n",
       " 'TTGCTGCAGTGGAAGA.1.9',\n",
       " 'CGCATAAAGTCAACAA.47.2',\n",
       " 'CAAGGCCCAGCTTAAC.2.1',\n",
       " 'CAAGAGGCATGATCTG.8.3',\n",
       " 'TCATGCCTCCCTGGTT.20.3',\n",
       " 'TGTTCATTCGTGCGAC.13.11',\n",
       " 'TGCGATAGTCGAGTGA.27.8',\n",
       " 'CCCTCTCGTGATACTC.24.7',\n",
       " 'GACAGCCCAGCTCCTT.4.11',\n",
       " 'GGACGTCGTTGCTCAA.25.3',\n",
       " 'GGTGTTACAGCTTCGG.20.6',\n",
       " 'TATTGCTTCTTCCAGC.2.2',\n",
       " 'TTTGATCAGGGTTAAT.25.2',\n",
       " 'AGTGCCGCAATGCTCA.2.14',\n",
       " 'CAGTCCTGTCGACTGC.21.1',\n",
       " 'CTCCACAGTGGGCTTC.23.8',\n",
       " 'TCAGCAAGTAGATCGG.10.12',\n",
       " 'ATTGGGTCATGCGGTC.1.9',\n",
       " 'CGAATTGGTTAGCGGA.21.9',\n",
       " 'TCAGTTTCAGTAGGAC.5.13',\n",
       " 'TTCCTAAAGATAGCTA.21.11',\n",
       " 'TATCGCCCAAAGACTA.2.7',\n",
       " 'CTCGTACCACGGCGTT.25.1',\n",
       " 'CTAGACACAGACCCGT.1.6',\n",
       " 'TGTGTGAAGACGGAAA.13.11',\n",
       " 'GTATTTCAGGTTAGTA.22.8',\n",
       " 'AGGCCACTCTCTGAGA.3.11',\n",
       " 'CACACAATCCGGACGT.19.6',\n",
       " 'AGACCCGGTACGGTTT.28.5',\n",
       " 'ACAACCAAGCATTTGC.22.2',\n",
       " 'ACGGGTCGTATGCTTG.21.1',\n",
       " 'CCCGGAAGTTTCGATG.24.4',\n",
       " 'TACCCGTAGTAAACTG.24.11',\n",
       " 'AGCTTCCCATGAAGGC.24.11',\n",
       " 'GTCCTCACATTGAAGA.16.14',\n",
       " 'CAGTGCGAGGCAGCTA.6.9',\n",
       " 'TGCTTGCAGACTTAAG.27.11',\n",
       " 'AGTTCGAGTCATAAAG.4.8',\n",
       " 'AGGGTGACATCGTTCC.40.2',\n",
       " 'CCTGCATCAGCCTATA.37.2',\n",
       " 'GAGGGTAAGGGATCAC.14.3',\n",
       " 'GGGCATCCATTTCACT.35.1',\n",
       " 'GTTACAGCACGGACAA.2.1',\n",
       " 'ACGATCATCTGCTTAT.19.10',\n",
       " 'GTTGTGAAGCTTCTAG.26.3',\n",
       " 'AACAACCCACAGTGAG.6.12',\n",
       " 'ACCCTTGAGTGGAATT.28.3',\n",
       " 'CCCGAAGAGGAGCAAA.21.2',\n",
       " 'AGAACAAGTGCAACGA.2.5',\n",
       " 'AAGCGAGGTACTGTTG.14.7',\n",
       " 'GATCAGTAGGCGTCCT.30.6',\n",
       " 'TCGGGTGTCGCCAGAC.15.9',\n",
       " 'TAGGCATAGGCTCAGA.35.1',\n",
       " 'TTTCACATCCCTTCCC.10.12',\n",
       " 'TTTATGCAGCTCCCAG.19.1',\n",
       " 'GGCAATTAGATCCCGC.2.1',\n",
       " 'GACGTTACAATTTCTC.14.2',\n",
       " 'TAACGACCATCTGTTT.8.11',\n",
       " 'GTCCACTTCAGCGCGT.17.3',\n",
       " 'AGAGCTTCATCGATTG.39.1',\n",
       " 'CGGGTGTAGGTCCCTG.6.7',\n",
       " 'AGTAGTCGTTGTGTTG.32.8',\n",
       " 'TGAGACTCATGGAATA.16.13',\n",
       " 'GTTACGATCATCGACA.34.2',\n",
       " 'TGTGATGTCGAAATCC.3.14',\n",
       " 'TACTTGTTCAACGAGG.28.8',\n",
       " 'TCGGATAAGCTCTGTA.9.3',\n",
       " 'AAGTGAACAGCTAACT.7.12',\n",
       " 'TCATGAGCATACATCG.23.11',\n",
       " 'CAGAATCTCATGGTCA.2.0',\n",
       " 'ACTCCCACAGAATTCC.27.5',\n",
       " 'GTCCCATCATTGTGCA.32.2',\n",
       " 'TCTTGCGTCAGGGATG.2.14',\n",
       " 'AAGCGAGCATCGGTTA.14.11',\n",
       " 'CTGCTCAAGTCCCTAA.12.13',\n",
       " 'GTCTCACAGTCGGGAT.15.6',\n",
       " 'ACAGGGATCCTTATGT.19.6',\n",
       " 'ACTGCAACAATACAGA.6.3',\n",
       " 'TCTCACGTCACACCCT.21.4',\n",
       " 'TTTATGCTCTGTGCAA.18.8',\n",
       " 'TCCTCGAAGTAACCTC.27.6',\n",
       " 'GAGTTTGCAGCCGTTG.6.8',\n",
       " 'CCTGCATAGGACGCTA.30.8',\n",
       " 'CTCCTCCTCCGTCCTA.28.5',\n",
       " 'TTCCGGTAGCGACTAG.1.6',\n",
       " 'CCACCATCAATGACCT.10.12',\n",
       " 'GAGCTGCGTAACGCGA.31.9',\n",
       " 'CGCCATTTCGGTCATA.41.2',\n",
       " 'GGGTTATCAGCGTTTA.7.4',\n",
       " 'CGGGCATAGGTTGACG.21.11',\n",
       " 'AATCGACAGTAACAGT.10.5',\n",
       " 'TTAGGGTCATACATCG.30.10',\n",
       " 'GCATCGGTCATGCCGG.27.2',\n",
       " 'GACACGCGTTCTTCAT.11.4',\n",
       " 'TCCTCCCAGGGACTGT.13.10',\n",
       " 'TGCCGAGTCTTGGATG.14.9',\n",
       " 'GAACACTCAAATGAAC.10.2',\n",
       " 'CATACAGCACTACCCT.9.9',\n",
       " 'TCAAGACCAAGTGCTT.4.6',\n",
       " 'GTCACAATCGCATGAT.22.1',\n",
       " 'GGAGGTAAGACTTCGT.15.12',\n",
       " 'ATCCTATGTGCCCGTA.15.13',\n",
       " 'AAAGGGCAGTTAGTAG.9.2',\n",
       " 'ATTTCTGTCCACGGAC.18.6',\n",
       " 'ATATCCTGTCGTCATA.2.2',\n",
       " 'TGCGACGCAAGGCAAC.26.3',\n",
       " 'CTTCCGAGTTTGCCGG.15.13',\n",
       " 'TACGTCCGTCGCTGCA.2.8',\n",
       " 'CTCAATTTCTGCATAG.13.3',\n",
       " 'CACAGTACATATGCTG.38.1',\n",
       " 'TGCAGGCTCTGGTTGA.28.3',\n",
       " 'ATTCCTAGTAGTACGG.15.11',\n",
       " 'AGTAGCTGTGATCATC.25.5',\n",
       " 'GTAAGTCCATCCGTGG.12.7',\n",
       " 'GGGATGATCTGAGGTT.2.13',\n",
       " 'GAGTGTTAGGAGCAAA.43.2',\n",
       " 'TTGCCTGCACCCTAAA.13.8',\n",
       " 'GACTGATTCCTCAGGG.16.4',\n",
       " 'AGACCATTCCTACACC.14.9',\n",
       " 'CCGGGTAGTGCGAACA.5.8',\n",
       " 'CCCTCCTAGTGAACAT.37.1',\n",
       " 'CTGCCTAGTCTTCTCG.24.1',\n",
       " 'GGGCTCATCCACAGCG.21.2',\n",
       " 'TGTGAGTCAGCAAGAC.25.10',\n",
       " 'TGAATCGGTAGGTACG.28.9',\n",
       " 'GGTTCTCGTGCCGGTT.4.7',\n",
       " 'AGGAAATCAGGTACGA.20.5',\n",
       " 'TAAGCCACATGCGTGC.15.9',\n",
       " 'CACAACATCTCATTTG.21.7',\n",
       " 'ATCGTCCAGGCGTTGA.16.9',\n",
       " 'GTGTGGCTCATTCCTA.9.2',\n",
       " 'TGCATCCTCCGTAGGC.33.2',\n",
       " 'CCTCCAACAGGTATGG.2.13',\n",
       " 'CGTTGGGGTAACTAAG.16.7',\n",
       " 'GAGGGTAGTCGAGATG.4.6',\n",
       " 'GTTCATTGTCTGTAAC.29.6',\n",
       " 'GAGCAGATCCACTCCA.44.1',\n",
       " 'TTCCTAAGTGCCGTTG.1.4',\n",
       " 'CCATCACTCGAGTTGT.18.8',\n",
       " 'GTCATCCAGGTACCTT.30.10',\n",
       " 'AAGGAATAGGCTTCCG.15.6',\n",
       " 'TATTCCATCCGGGACT.27.2',\n",
       " 'CACGGGTAGTCTGGTT.31.9',\n",
       " 'CCGTGGACAAAGGTGC.2.1',\n",
       " 'TTTAGTCAGGTCATCT.25.11',\n",
       " 'ATCACTTGTTATAGCC.29.10',\n",
       " 'ATAGGCTAGTACGTCT.8.13',\n",
       " 'GTTGCTCTCAAGCTGT.8.11',\n",
       " 'GTGTTCCCAAAGAGTT.19.10',\n",
       " 'ATGTCCCCATACTGTG.27.2',\n",
       " 'TTTGGTTAGTTGCTGT.32.10',\n",
       " 'CCGGGTATCACAACCA.7.14',\n",
       " 'AAGTCTGCACCCAGTG.3.1',\n",
       " 'TGATGCAAGTGCCTCG.3.6',\n",
       " 'AACGAAATCGGTAAGG.2.13',\n",
       " 'GGGTTTACAAAGTGTA.27.10',\n",
       " 'GTTTACTGTTCCAAAC.2.11',\n",
       " 'CGGCAGTCACCTCGTT.5.11',\n",
       " 'AACGTCAGTTACAGCT.8.14',\n",
       " 'TTTACGTCAGCTGAAG.13.8',\n",
       " 'AAGAACATCGGTAACT.29.6',\n",
       " 'TCCACCATCATGAAAG.2.11',\n",
       " 'TTCTTCCCAAGTGTCT.19.4',\n",
       " 'CTCCTCCCATAGGTTC.22.10',\n",
       " 'TAACGACGTATCCCTC.9.14',\n",
       " 'TCCATCGGTAACAGTA.31.2',\n",
       " 'GGACGTCGTAGTATAG.26.5',\n",
       " 'GTTAGACCAAGCACAG.2.2',\n",
       " 'CAAGAGGCACAGCCAC.15.6',\n",
       " 'TTCGCTGTCGTAGGAG.6.6',\n",
       " 'GTGTTCCGTACGTAGG.17.11',\n",
       " 'TGCATCCCATACAGGG.3.5',\n",
       " 'GGTGGCTGTCGTTATG.14.11',\n",
       " 'CATGGATGTCTGCCTT.6.4',\n",
       " 'AATGGAATCCTGCTAC.26.2',\n",
       " 'CCTCTCCTCTCTCGCA.38.2',\n",
       " 'TTGCCTGCATTCACAG.9.6',\n",
       " 'TCTTAGTGTGGAAATT.4.3',\n",
       " 'TCTAACTGTATGATCC.8.12',\n",
       " 'TGAGCATAGTGACTCT.29.1',\n",
       " 'AGCATCAAGCGTGTCC.13.14',\n",
       " 'CTCATCGTCCCAGGAC.24.3',\n",
       " 'CACTGAAGTGCACAAG.21.9',\n",
       " 'CACTAAGTCGTCGATA.2.4',\n",
       " 'GTGCGTGCAGTAACGG.6.8',\n",
       " 'AGTCACAAGTTACGGG.16.2',\n",
       " 'TTAGTCTAGTTGGGAC.23.10',\n",
       " 'TCCCACATCGAAGGAC.35.2',\n",
       " 'ATGAGTCTCCTCTCTT.3.9',\n",
       " 'CTGCTCACATCCGTTC.20.3',\n",
       " 'GGCTTTCCAATTGCGT.24.4',\n",
       " 'CCTCACACACCCATAA.5.5',\n",
       " 'AGTGTTGGTTCCAAAC.14.6',\n",
       " 'ACGGTCGAGTACTGTC.11.9',\n",
       " 'TTCAGGATCGAAGCCC.30.10',\n",
       " 'TACCCGTTCCCATTTA.29.7',\n",
       " 'AATCGTGTCACCGGGT.2.14',\n",
       " 'AGAGAATAGAGGCGGA.35.2',\n",
       " 'TGGGTTAAGCTCACTA.31.9',\n",
       " 'ACGGGTCTCACCGGTG.13.4',\n",
       " 'CAAAGAAGTATCGATC.18.8',\n",
       " 'ATTTACCAGGCTGGAT.46.2',\n",
       " 'ATCACGACAGCGCTTG.1.7',\n",
       " 'ATACCTTAGGACGGAG.14.6',\n",
       " 'GTTGTGAAGCCGATTT.9.6',\n",
       " 'CGCGTGAGTTCGGTCG.5.11',\n",
       " 'TAGTGCAAGCTGGCCT.13.3',\n",
       " 'CCTTACGAGGATGGTC.15.0',\n",
       " 'TTCGATTAGGTGCCTC.24.4',\n",
       " 'TCCTAATAGTATCTGC.14.11',\n",
       " 'TGCTCGTCAGGAGGTT.4.12',\n",
       " 'GGGACAAGTCAGGTGA.10.10',\n",
       " 'TGAATCGTCGCTTTAT.32.2',\n",
       " 'AATCACGTCTCTAGGA.10.12',\n",
       " 'TCACATTCAGTTTCGA.8.5',\n",
       " 'TACCGGGCAAATGGAT.24.5',\n",
       " 'AGCATCAGTCTGTGTA.18.8',\n",
       " 'GGTATTGCAATGGATA.1.1',\n",
       " 'ATCGGCGCACTACTTT.9.2',\n",
       " 'TACGGTACAGCGTCCA.23.1',\n",
       " 'AATGGCTAGCGCTTCG.21.8',\n",
       " 'GACGTTACAGCCCAGT.4.8',\n",
       " 'GAGTGAGGTTGCTCAA.18.6',\n",
       " 'TTTGGAGTCGAGCTGC.17.11',\n",
       " 'ACTATCTCAGGACGTA.32.1',\n",
       " 'CATGGATAGCTGCCTG.6.2',\n",
       " 'CATGGATTCCTTGGAA.21.4',\n",
       " 'GTGCTTCTCATTCGGA.30.6',\n",
       " 'GCCAGGTAGTAGTCTC.3.11',\n",
       " 'AAGATAGGTAACATCC.4.14',\n",
       " 'CCTAACCAGGCGAACT.5.9',\n",
       " 'GCTGAATAGTGATCGG.4.2',\n",
       " 'ACATCAGTCCTTAATC.33.1',\n",
       " 'CATCCCAGTGATAGTA.19.5',\n",
       " 'AATCGACAGTGGAAGA.9.2',\n",
       " 'CAAGGCCGTCGACTGC.30.1',\n",
       " 'CCTCCAAAGTCTGCGC.1.13',\n",
       " 'AACCTGAGTGGCTTAT.27.11',\n",
       " 'TGGGATTGTCATATGC.1.13',\n",
       " 'CCTCCAACACCTAAAC.7.5',\n",
       " 'TTGGGCGGTGAGGAAA.32.3',\n",
       " 'TAAGCCAAGGAGGGTG.15.2',\n",
       " 'TCAGCCTCATAGATGA.19.4',\n",
       " 'CTTACCGAGAGGTTAT.32.1',\n",
       " 'TAAGTCGTCTACGCAA.27.5',\n",
       " 'GTTATGGAGTGGCAGT.12.4',\n",
       " 'CAGATACCAAAGTATG.23.10',\n",
       " 'GTAACACGTATACCCA.2.2',\n",
       " 'TTCCGGTAGCGACAGT.1.5',\n",
       " 'AATCACGCAAGTCCCG.29.11',\n",
       " 'TGGAGGACACCCAAGC.10.12',\n",
       " 'CAAGGGACAGTTTCGA.2.9',\n",
       " 'AGCATCAAGGACAGTC.24.4',\n",
       " 'TCAGTCCTCTAGACAC.1.12',\n",
       " 'AAGCGAGTCCAAGGGA.7.11',\n",
       " 'GGGATGAGTAATGTGA.26.3',\n",
       " 'ATGACCACAGCTGTTA.21.6',\n",
       " 'GGACGTCGTAAATGTG.42.1',\n",
       " 'GATTGGTCACGTGAGA.26.11',\n",
       " 'CCGTTCATCTGTGCTC.1.9',\n",
       " 'AATCGTGAGTGTTGTC.21.6',\n",
       " 'ACCACAACACCCTCTA.27.2',\n",
       " 'CCTCCAAAGCTGGCTC.29.11',\n",
       " 'TCTAACTTCTCAAAGC.32.6',\n",
       " 'AGCTACAAGGTCGTCC.11.11',\n",
       " 'GTCTCACTCACAGTGT.2.11',\n",
       " 'ATTCCTATCCTAAGTG.14.4',\n",
       " 'GTTACAGAGTACAGCG.7.7',\n",
       " 'GGCAGTCAGAACGCGT.23.10',\n",
       " 'CAACAACAGCATCCCG.7.12',\n",
       " 'GCTTGGGTCGATCCAA.27.6',\n",
       " 'AGGGAGTTCGTGGGTC.14.14',\n",
       " 'CCTCTAGTCATAGACC.32.6',\n",
       " 'GCACATAAGTACCGGA.12.1',\n",
       " 'TAAGCACTCACCCATC.6.9',\n",
       " 'GTGTTAGGTTACCGAT.15.1',\n",
       " 'TGGGAAGCACTAGGTT.13.14',\n",
       " 'GTGCAGCAGTCGAAAT.2.14',\n",
       " 'ACTTCGCGTATCTCGA.14.7',\n",
       " 'ATTCAGGCACGTCTCT.19.3',\n",
       " 'GGGTTATGTGCGGTAA.19.2',\n",
       " 'ATGGGAGCATGGTACT.9.13',\n",
       " 'GGGTGTCCATGGGCAA.26.3',\n",
       " 'ACATGCATCCCGAACG.24.7',\n",
       " 'TTAGTTCAGATCCGAG.6.1',\n",
       " 'TCCACCACACATCCCT.28.5',\n",
       " 'GTACAGTAGTCTCGTA.8.5',\n",
       " 'GGAACCCTCAGCTTGA.3.13',\n",
       " 'AACAACCGTACGGCAA.10.7',\n",
       " 'AGGAGGTCACGACAAG.16.11',\n",
       " 'CACGAATCATTGAAAG.35.2',\n",
       " 'ACTTTCATCGTCTACC.19.6',\n",
       " 'GCCAGCATCTCAACCC.20.6',\n",
       " 'TTCGCTGCATGATGCT.21.9',\n",
       " 'TAGATCGAGTTTGCTG.11.11',\n",
       " 'GGTATTGAGAGTCTGG.14.1',\n",
       " 'TTGACTTAGAGTGAGA.42.1',\n",
       " 'GCCAAATCAATTGCTG.28.1',\n",
       " 'TGAATCGTCAACTGGT.32.8',\n",
       " 'GAGGCCTAGACGTCCC.14.11',\n",
       " 'AACCTTTAGACCTGGA.16.3',\n",
       " 'ATTACCTCACAATGTC.27.5',\n",
       " 'GGGTTTAAGCGAGGAG.19.4',\n",
       " 'TAGCACATCACTCGAA.8.9',\n",
       " 'GGGAGTAGTAATTGGA.19.6',\n",
       " 'ACAAGCTCACAGTACT.28.11',\n",
       " 'AGGCCACAGATAGCTA.10.11',\n",
       " 'GGGTTTACAGCAAGAC.13.11',\n",
       " 'CGGAACCTCAGGACAG.33.2',\n",
       " 'TTGTGTTAGATGGCGT.11.10',\n",
       " 'TTGCGTCAGTTCCTGA.13.8',\n",
       " 'GTGTGCGAGAGGGCTT.36.1',\n",
       " 'GGTGTCGCATACTGTG.8.13',\n",
       " 'CCTACCAAGATCTGCT.18.1',\n",
       " 'ATCCGAAAGGAGCGAG.19.1',\n",
       " 'GGAATAAAGGTGCACA.4.0',\n",
       " 'GTCAGCGTCTAGACAC.8.6',\n",
       " 'TTGAACGCAAATGGTA.27.10',\n",
       " 'TCAGGTAAGGTGATCG.3.8',\n",
       " 'GTGTCCTGTACTGGGA.16.10',\n",
       " 'TTGAACGCAGGACCCT.14.1',\n",
       " 'TTCCACGCATACTGAC.32.3',\n",
       " 'GTACAACGTAGAGCTG.13.4',\n",
       " 'TCGATTTAGTGATAGT.21.8',\n",
       " 'GACCAATTCATTCGTT.1.2',\n",
       " 'GGTCTGGAGGACACTG.28.2',\n",
       " 'TACTTACTCGCGGTAC.19.2',\n",
       " 'CGGACACGTCGAGTGA.25.4',\n",
       " 'GCACTAACATACTTTC.32.11',\n",
       " 'GTGCAGCTCTTGGATG.28.10',\n",
       " 'AAGCGAGAGGTGCGAT.27.6',\n",
       " 'TTGGTTTAGATTGAGT.8.12',\n",
       " 'ACTCCCATCACGGACC.22.9',\n",
       " 'AACCTTTAGGTATAGT.8.13',\n",
       " 'GGAATGGTCGAAATCC.7.2',\n",
       " 'ACCAAACCATCCCACT.1.11',\n",
       " 'GGTAACTAGGACTATA.4.14',\n",
       " 'TTGCCTGAGCCAGAGT.10.14',\n",
       " 'TCAAGACCAAGTTCCA.32.4',\n",
       " 'CACACAACACTGAGTT.10.9',\n",
       " 'TTGGGTAAGAGTGACC.24.8',\n",
       " 'AACCATGGTGCATACT.14.13',\n",
       " 'GGATGTTTCGTCACCT.10.6',\n",
       " 'GCTTGGGTCTAGTGAC.27.2',\n",
       " 'CGAAGTTAGTCACTAC.19.3',\n",
       " 'TAACGACGTGTAACGG.24.2',\n",
       " 'AATGGCTGTTGACTGT.14.6',\n",
       " 'CTGTGGGTCTTGGGCG.10.11',\n",
       " 'GGGCTCACACCTGAAT.23.4',\n",
       " 'CTTCTAACACTTGAGT.9.2',\n",
       " 'CACTGAAAGCCTCACG.24.10',\n",
       " 'TATCGCCGTCATCCGG.47.2',\n",
       " 'GATGTTGTCCTTTAGT.2.4',\n",
       " 'TTAGGACTCTACGAGT.23.1',\n",
       " 'TCACTATAGGTAGGCT.18.4',\n",
       " 'TGAGCGCGTCCCTAAA.12.6',\n",
       " 'AATCGTGTCTTTCAGT.11.11',\n",
       " 'GGCACGTGTAATCAGA.2.9',\n",
       " 'AGCTTCCGTTTCGGCG.2.14',\n",
       " 'GTCTACCTCCGCACTT.13.12',\n",
       " 'TAAGTCGGTTATAGCC.19.11',\n",
       " 'GGGATCCAGAAGATCT.15.12',\n",
       " 'GTATTCTTCAGGTAAA.21.0',\n",
       " 'GAGGCCTTCGACGTCG.30.2',\n",
       " 'CATTGTTTCTGATGGT.4.8',\n",
       " 'ACTACGAGTGCTCTCT.18.7',\n",
       " 'TCATTGTCATGACGAG.1.9',\n",
       " 'TTCACCGCAGCTTTGA.6.11',\n",
       " 'GGCTTTCCAATACAGA.21.3',\n",
       " 'CTTACCGAGATGCAGC.4.2',\n",
       " 'GTGAGGAAGACATCCT.4.13',\n",
       " 'AGGGTCCCAACGGCTC.30.11',\n",
       " 'GACCTTCCACAGAGCA.12.10',\n",
       " 'TACTCGCAGGAGCGTT.30.1',\n",
       " 'GGGTCTGCATCTCGTC.31.5',\n",
       " 'TTGTGTTCACAAATCC.29.4',\n",
       " 'TTGTGTTGTTACACAC.11.7',\n",
       " 'TACCCACTCTCTCCGA.32.2',\n",
       " 'AGTAACCTCAGTGATC.14.2',\n",
       " 'CTGTAGACATTCACAG.38.2',\n",
       " 'AGGTCTAAGTAGTCAA.16.14',\n",
       " 'ACTACGAAGCTTAAGA.29.10',\n",
       " 'CGTTCTGCATGAGCGA.21.1',\n",
       " 'ACTATTCTCAATGCAC.15.2',\n",
       " 'AGAACCTAGTATAACG.11.2',\n",
       " 'GTCATGAAGAGTTGCG.30.8',\n",
       " 'TAGGAGGGTATGAAAC.9.9',\n",
       " 'GTCATGAAGGGACTGT.9.12',\n",
       " 'CCACGAGAGAATACAC.31.6',\n",
       " 'ATCGTAGAGTTGCGAG.25.3',\n",
       " 'AAAGGATCAAGGTTGG.12.13',\n",
       " 'TATTACCTCAGTCCCT.22.1',\n",
       " 'GTCTTTATCCTCAGAA.32.9',\n",
       " 'TTGTGGAAGAGAGGGC.47.2',\n",
       " 'CATCAAGTCCTAGCTC.27.9',\n",
       " 'CAACGGCAGACTCTAC.14.11',\n",
       " 'GGATGTTCAGCGTTTA.16.6',\n",
       " 'CCATCACCAGGTTCGC.19.5',\n",
       " 'TAGACCAAGGTAGGCT.24.3',\n",
       " 'CTACCCACAGCCGTCA.27.6',\n",
       " 'TCAAGTGTCGGAATGG.8.10',\n",
       " 'TCGGGCAGTATTAAGG.7.9',\n",
       " 'TTCATTGAGGTAGCCA.21.11',\n",
       " 'ACCCTTGAGCAGCCCT.11.7',\n",
       " 'CCACCATCAGCTCTGG.1.5',\n",
       " 'GAATCACGTATCGCAT.27.5',\n",
       " 'TCATGCCAGAGTAACT.30.8',\n",
       " 'GAGTTGTTCGAAACAA.22.2',\n",
       " 'GTGCGGTGTATAGGTA.26.0',\n",
       " 'CCTTTCTTCGAATGGG.19.1',\n",
       " 'TGACGGCGTGCATCTA.30.1',\n",
       " 'AGGATAAAGTTGAAAC.4.9',\n",
       " 'ACCTACCTCGGCTTGG.20.10',\n",
       " 'AGCTTCCGTAGACAAT.5.5',\n",
       " 'GGACAAGTCGAACGGA.4.0',\n",
       " 'ACCTGAACACCCTAAA.9.9',\n",
       " 'CCTTCCCTCCGCTGTT.33.1',\n",
       " 'GCAACCGTCGGAAACG.6.9',\n",
       " 'CACAGGCTCTCTGGTC.1.2',\n",
       " 'TAAGCACAGACGAGCT.14.2',\n",
       " 'AAACGCTGTTTCGTAG.9.10',\n",
       " 'GTAGCTACAATCTGCA.32.2',\n",
       " 'TGCGATAGTAGATCGG.23.8',\n",
       " 'TGCCGAGTCGGTGTAT.12.4',\n",
       " 'ATCACAGCAACTGAAA.32.7',\n",
       " 'CGATCGGCAAATGAAC.27.3',\n",
       " 'GGGTAGAAGCGGTATG.18.9',\n",
       " 'TGTAGACCAATCGCGC.27.11',\n",
       " 'CACGTGGCACCAACAT.7.2',\n",
       " 'GCAGTTATCTGCAAGT.40.1',\n",
       " 'TTCTAGTCATGACCCG.31.3',\n",
       " 'ATCACAGCATTGACAC.2.2',\n",
       " 'GTGTGATCAGCATCTA.21.6',\n",
       " 'ATTCCATGTGCATGTT.24.4',\n",
       " 'TTACCGCCACACCTTC.27.2',\n",
       " 'GTCTTTAAGTCGGCAA.16.12',\n",
       " 'AACTCAGAGCGATGAC.1.1',\n",
       " 'TAGTTGGTCAAGCCTA.47.1',\n",
       " 'GGGAGATTCGGAAATA.40.1',\n",
       " 'TCTTGCGTCAATGTCG.13.14',\n",
       " 'TACTTCACAAGACCTT.10.9',\n",
       " 'AAATGCCAGGAGCGTT.40.1',\n",
       " 'ACTTAGGCATGTTTGG.18.8',\n",
       " 'GTTACAGGTCTACGTA.13.7',\n",
       " 'TTTGATCGTCAAGGCA.6.4',\n",
       " 'GTGCACGGTACCTATG.21.9',\n",
       " 'ATCATTCAGTCGAGGT.23.8',\n",
       " 'CCTTTGGAGTTGGCGA.30.10',\n",
       " 'TCAGGTAGTAGACGGT.10.13',\n",
       " 'GACCCTTTCACTGTCC.22.9',\n",
       " 'GTCACGGAGGTCCTGC.8.8',\n",
       " 'GGCGTCATCAAAGAAC.20.11',\n",
       " 'GCAGCCATCGCCAGTG.28.4',\n",
       " 'TGATGCACAATACCTG.26.3',\n",
       " 'GTCACTCGTCACTCAA.26.10',\n",
       " 'ACACTGATCCTTGGTC.14.0',\n",
       " 'ATCGTAGAGACCCTTA.47.2',\n",
       " 'GGCGTGTAGTTAGGTA.44.0',\n",
       " 'CTGAGCGGTATCCCTC.4.8',\n",
       " 'ACGTAGTTCACTGTCC.22.9',\n",
       " 'CTCAGGGCAAAGGAGA.26.5',\n",
       " 'TTGCGTCTCGGCTTGG.28.3',\n",
       " 'TGCATGACATCGATAC.20.4',\n",
       " 'CGCCAGAGTAGTAAGT.19.10',\n",
       " 'TCTTCCTGTGTGTCCG.15.6',\n",
       " 'AGTGTTGTCAGACTGT.15.11',\n",
       " 'CGTAAGTTCAGAGCGA.15.6',\n",
       " 'CAACAACAGCTACTGT.6.11',\n",
       " 'GCGCGATTCTTAGCCC.6.1',\n",
       " 'TCATCATGTAAGTTGA.24.11',\n",
       " 'CATCGGGCAATATCCG.10.8',\n",
       " 'TTTCACACATGATAGA.3.7',\n",
       " 'CAGGGCTTCTATACTC.11.9',\n",
       " 'CTGCTCATCACCGGGT.4.2',\n",
       " 'TGTGCGGGTCGTCGGT.26.4',\n",
       " 'GAATAGAAGACCGCCT.27.8',\n",
       " 'GGATGTTTCTTGCCGT.2.1',\n",
       " 'CCTTCAGTCATTTCCA.3.8',\n",
       " 'TTGCATTGTTGCGGCT.25.11',\n",
       " 'AAACGAAGTTGGACCC.17.10',\n",
       " 'TTCCACGAGCGGATCA.2.10',\n",
       " 'GGGTCTGAGACAGCTG.5.7',\n",
       " 'CCGGACAGTCCATCTC.13.4',\n",
       " 'GCCAAATAGGATGGTC.26.1',\n",
       " 'ACTACGAAGACTACGG.27.3',\n",
       " 'TTCGAAGGTGGTAACG.14.0',\n",
       " 'ATGGTTGTCGTGTGGC.17.4',\n",
       " 'GGGACCTAGCCGATCC.25.5',\n",
       " 'TGTGCGGAGAAGTGTT.8.11',\n",
       " 'TGCTTCGAGAAGTCCG.5.13',\n",
       " 'AAGCCATGTAATTGGA.13.8',\n",
       " 'CCCAACTGTAGTAAGT.32.5',\n",
       " 'GTTTGGATCGCCGAGT.32.11',\n",
       " 'AGATCGTGTCACTCAA.12.3',\n",
       " 'GACCTTCGTCAAGCCC.2.4',\n",
       " 'TGACCCTCATCCGCGA.28.11',\n",
       " 'CACTGAAAGTGTTGAA.9.2',\n",
       " 'AGGGTCCAGAGCATTA.27.3',\n",
       " 'CTGATCCAGGACCACA.38.1',\n",
       " 'GATGAGGTCAGCTTAG.1.1',\n",
       " 'GAAGTAACAAATCGTC.10.3',\n",
       " 'CACGAATAGGCTAGCA.19.6',\n",
       " 'CGAGGCTCAGTGTACT.11.8',\n",
       " 'GGTTAACGTTCCACGG.34.2',\n",
       " 'CTGTTTACAGTGAGTG.42.1',\n",
       " 'CAGCCGAGTGTGCGTC.8.1',\n",
       " 'CTCCCTCGTTGCATGT.8.13',\n",
       " 'GGAATCTCAAGACTGG.16.2',\n",
       " 'GCCAGCAGTGGCTTAT.13.6',\n",
       " 'TGTCCCAGTTTAGTCG.16.9',\n",
       " 'ATGTCTTCAACACACT.32.5',\n",
       " 'GCACGTGGTGACATCT.26.8',\n",
       " 'TGGTACATCCTTGAAG.14.9',\n",
       " 'GAGACTTTCAGAGCAG.29.11',\n",
       " 'TAGACTGAGGAGACCT.8.14',\n",
       " 'TAAGTCGTCTCGGCTT.12.12',\n",
       " 'TTTATGCCAATTGAAG.23.7',\n",
       " 'GACACGCGTGCCTTTC.11.3',\n",
       " 'GGCTTGGAGACCAGCA.8.12',\n",
       " 'GTTGTCCGTCGATGCC.4.8',\n",
       " 'AATTTCCAGCCGAACA.4.7',\n",
       " 'ACCGTAATCCTTGCCA.34.1',\n",
       " 'TAGACTGGTATCAAGA.12.6',\n",
       " 'AAGACTCAGATGACCG.9.8',\n",
       " 'TGATCAGAGCGATGAC.31.7',\n",
       " 'GGCTGTGGTGTACATC.7.11',\n",
       " 'ATAGACCCAGAGACTG.1.9',\n",
       " 'CGAATTGCAGATCCTA.7.9',\n",
       " 'GTCAAGTTCACGGGCT.12.9',\n",
       " 'TCCCACAGTGGTCTAT.1.6',\n",
       " 'GTAAGTCCAACAGCCC.24.7',\n",
       " 'AGAAATGAGATTTGCC.3.7',\n",
       " 'GTGCATACATCGTCGG.2.1',\n",
       " 'AGATTGCCAGACACTT.6.1',\n",
       " 'CTTAGGACAGACAAAT.46.1',\n",
       " 'AATCGACAGAGTCCGA.27.11',\n",
       " 'TATACCTGTGCCGTTG.14.13',\n",
       " 'GCGGATCGTCACTTCC.27.5',\n",
       " 'CTGTCGTTCATAAGGA.9.13',\n",
       " 'AGACACTGTGTCCTAA.28.11',\n",
       " 'TAGCACATCGAACGCC.28.3',\n",
       " 'TGGTACATCCAATCCC.7.4',\n",
       " 'GTAGCTAGTCGAGTTT.20.5',\n",
       " 'CATCAAGTCAGGGATG.16.4',\n",
       " 'TCAATTCCACCAGCGT.29.9',\n",
       " 'CCTCCTCGTACCTGTA.4.8',\n",
       " 'CCGATCTTCGGTTCAA.5.10',\n",
       " 'AACCCAAGTAGGACCA.13.11',\n",
       " 'TTACCATGTAGAGACC.13.8',\n",
       " 'AAGGAATTCCATCTAT.15.3',\n",
       " 'CCACACTAGCGACTTT.6.9',\n",
       " 'TCGCTTGTCCATCAGA.12.11',\n",
       " 'TCATGAGGTCAAGCGA.4.4',\n",
       " 'GCTACAACAGTCGTTA.12.14',\n",
       " 'TGCACGGCATGACACT.1.11',\n",
       " 'TGACGCGGTCTAGGTT.30.11',\n",
       " 'ACAAGCTCAGACCATT.30.10',\n",
       " 'CTTCAATAGCCGATTT.8.9',\n",
       " 'GTAGCTAGTGGACCTC.1.2',\n",
       " 'TGATTTCAGCCGGATA.27.8',\n",
       " 'CACCAAAAGCATCCTA.2.9',\n",
       " 'GGAGAACGTGGTCTAT.9.2',\n",
       " 'CAGTTAGTCTAGGCAT.17.2',\n",
       " 'AGCGTATCAAGAGCTG.2.11',\n",
       " 'AACCTGACACCAGCGT.6.12',\n",
       " 'CAACAGTCATGCCGGT.2.13',\n",
       " 'CATAGACGTCAAGTTC.2.2',\n",
       " 'GTCAAGTGTTACAGAA.44.1',\n",
       " 'TAAGCACTCTCACCCA.19.8',\n",
       " 'GGAGCAAGTGGAATGC.5.9',\n",
       " 'AACGTCACATCATTTC.12.2',\n",
       " 'CATTGTTAGAACGCGT.31.10',\n",
       " 'TCCTTCTCATGTGGTT.7.11',\n",
       " 'CCTCCAATCGAGTCTA.7.10',\n",
       " 'TATTTCGCAGGTGAGT.28.3',\n",
       " 'GAGAGGTCATCTCGTC.30.6',\n",
       " 'CCGGGATGTGTCAATC.7.1',\n",
       " 'TTTACGTCAGCTACAT.5.13',\n",
       " 'CTTGAGATCTTTCTAG.13.14',\n",
       " 'GAGGCAAGTCAACCTA.31.5',\n",
       " 'TATCTTGTCAACTACG.8.5',\n",
       " 'TGGTACACAGGCCTGT.19.6',\n",
       " 'CACTAAGTCATGAGGG.13.2',\n",
       " 'CAACAACTCATCCTGC.8.12',\n",
       " 'TCACGGGCAGTAGATA.11.9',\n",
       " 'TCTACATCAAGAGTTA.7.9',\n",
       " 'ACAAAGAGTTGTCTAG.5.4',\n",
       " 'TGATTTCCACGTACAT.27.3',\n",
       " 'CTACTATAGCAGCCCT.21.5',\n",
       " 'TGAGGAGTCCAAGGGA.15.6',\n",
       " 'ACAGCCGGTACTCAAC.5.4',\n",
       " 'ACGGAAGGTTTACCAG.27.9',\n",
       " 'GGCGTCACAGCATGCC.7.13',\n",
       " 'CATAGACGTGAGATAT.12.9',\n",
       " 'GGATCTATCTCAGTCC.30.4',\n",
       " 'CGATGGCCAACACCTA.12.1',\n",
       " 'GCATCGGTCAAGAGTA.24.5',\n",
       " 'TGAGGGAGTGCCGGTT.31.11',\n",
       " 'TGAGGGAGTGCTCGTG.12.2',\n",
       " 'GGCTGTGCACATTGTG.27.7',\n",
       " 'GTGATGTCACCTGAAT.1.14',\n",
       " 'CAGCAGCTCTGCTTAT.8.10',\n",
       " 'GGAGAACTCGCGTCGA.7.8',\n",
       " 'CAGTTCCGTCAGACGA.3.5',\n",
       " 'GATCGTATCGCTCTAC.15.9',\n",
       " 'GTTCATTCAATTAGGA.11.3',\n",
       " 'GAGGTGAAGTCCGTAT.45.1',\n",
       " 'AATCACGTCTAGACAC.4.4',\n",
       " 'GGCAGTCCATCGTGCG.20.11',\n",
       " 'CCTGCATAGTAGAATC.19.3',\n",
       " 'GAGGCAAAGTAGTCCT.30.4',\n",
       " 'GTCAAACAGCGTTCAT.17.2',\n",
       " 'ATAGGCTCAGGAGGTT.17.4',\n",
       " 'TAATCTCCACATGTTG.4.5',\n",
       " 'TGCTGAACAGACTGCC.13.8',\n",
       " 'CACTGTCCATAGGTAA.24.4',\n",
       " 'CAAAGAATCTCAGTCC.28.5',\n",
       " 'TACGTCCGTAAGATCA.4.13',\n",
       " 'AACCTGATCCCTCTCC.26.8',\n",
       " 'TTTCATGTCTGTGTGA.29.10',\n",
       " 'TTACGCCCAAGCGGAT.18.9',\n",
       " 'CAGTGCGTCATGCCCT.9.13',\n",
       " 'TCTGCCACAGGCTACC.11.7',\n",
       " 'GTTGTGATCGCGTGAC.2.5',\n",
       " 'TCATTACAGATCGCCC.8.2',\n",
       " 'GCCAAATCATGTCTCC.40.1',\n",
       " 'CGCATGGGTGTGACCC.24.8',\n",
       " 'ACACGCGCATGACGTT.27.3',\n",
       " 'TCATACTAGCCTTTCC.14.11',\n",
       " 'CATCGTCAGAGTTGTA.14.3',\n",
       " 'GTACAGTCAGTTACCA.15.4',\n",
       " 'AGGCCACGTAGTGATA.1.12',\n",
       " 'GTTGTGAGTGAGCAGT.31.7',\n",
       " 'AGGCTGCGTAGGAGGG.47.2',\n",
       " 'TGTTACTCAGATACCT.28.4',\n",
       " 'GGATGTTAGGGTGAAA.17.8',\n",
       " 'CTACTATGTGAAGCGT.22.3',\n",
       " 'TGTAACGTCGGCATTA.7.2',\n",
       " 'AGCGTATTCTCCGAGG.28.2',\n",
       " 'ACTGCAATCCTCGATC.9.10',\n",
       " 'GGGACTCTCAGGGTAG.3.6',\n",
       " 'TGTAAGCAGACAACTA.5.9',\n",
       " 'ATAGAGATCCTTATGT.26.2',\n",
       " 'ATCCCTGAGCACTAAA.21.11',\n",
       " 'CCAATGAGTACCTTCC.4.4',\n",
       " 'GGCGTCACACAAACGG.22.5',\n",
       " 'GGAACCCAGGCAGTCA.10.10',\n",
       " 'TTGTTCACAGAGGCTA.26.2',\n",
       " 'GGAATCTGTTGGTGTT.5.6',\n",
       " 'AACTCTTAGAAACCAT.40.1',\n",
       " 'AGGCATTTCCCTAGGG.1.11',\n",
       " 'TGCTTGCGTCCACGCA.19.6',\n",
       " 'TTGTGTTCATGCCGAC.10.8',\n",
       " 'CCGCAAGCATGGGAAC.12.14',\n",
       " 'CAGATCAAGCAGGGAG.19.11',\n",
       " 'CAGCACGGTACGAGTG.4.14',\n",
       " 'TCAAGACGTACAACGG.28.11',\n",
       " 'CTGCGAGAGAACCCGA.1.12',\n",
       " 'CCTCCTCTCCGAGCTG.31.8',\n",
       " 'AATTTCCCAATATCCG.15.14',\n",
       " 'TGTCCTGGTCACAATC.30.10',\n",
       " 'TCTCTGGCAAGTACCT.32.5',\n",
       " 'GCTTTCGAGTGTTGAA.22.10',\n",
       " 'CTAGGTAAGGGCGAGA.9.4',\n",
       " 'TCTTGCGGTATTGAGA.14.11',\n",
       " 'TTTACTGGTCCAAGTT.47.0',\n",
       " 'GCACATAAGAAGGCCT.36.1',\n",
       " 'GACCCTTCACCACTGG.30.6',\n",
       " 'CCACGTTCATCATTGG.4.14',\n",
       " 'CCTTTGGAGACCGCCT.25.2',\n",
       " 'GCTGCAGGTCCGTTAA.11.1',\n",
       " 'TTCCGGTCAACTGAAA.5.9',\n",
       " 'CACGTGGTCCGCAGTG.1.11',\n",
       " 'GACACGCTCGACCATA.15.9',\n",
       " 'AATCGTGCAAGTATCC.32.8',\n",
       " 'TTTACCAAGATCGCTT.10.10',\n",
       " 'CAACGATCATGGCACC.3.13',\n",
       " 'CACACAACAATCTGCA.22.1',\n",
       " 'CGTGTCTGTTCGAAGG.10.6',\n",
       " 'AGACTCATCTGTCGCT.27.11',\n",
       " 'AGAAATGAGGGACAGG.6.3',\n",
       " 'AGTAGTCTCACGCATA.39.1',\n",
       " 'TTTGGAGAGGGAGAAT.3.8',\n",
       " 'GATGAAACAAGAGGCT.35.1',\n",
       " 'CTCCAACAGTAGTCAA.16.11',\n",
       " 'AGCGTCGAGGTATCTC.6.8',\n",
       " 'ATGTCCCTCACTCTTA.8.9',\n",
       " 'TGTTCTAGTAACGTTC.21.6',\n",
       " 'CTTGATTCACCTGAAT.26.3',\n",
       " 'ATCATTCTCAAGCCCG.1.7',\n",
       " 'GTCACGGTCCTACAGA.15.1',\n",
       " 'TCAGGGCGTGTTACAC.3.8',\n",
       " 'GGTTGTACAGGTACGA.21.4',\n",
       " 'TCACGCTGTACCGCGT.21.3',\n",
       " 'GTAGGCCAGAATTGTG.19.0',\n",
       " 'CCTTCAGGTACTTGTG.9.9',\n",
       " 'GAGTTTGAGCTAGATA.6.12',\n",
       " 'AGGGTCCTCGCCGAGT.6.11',\n",
       " 'CAAGAGGCATAATGCC.13.7',\n",
       " 'CTGTATTAGCTGTACT.16.4',\n",
       " 'CTATAGGGTGTTTCTT.32.4',\n",
       " 'TGTAAGCTCGACATCA.10.4',\n",
       " 'TGAGACTAGTTGGCTT.7.3',\n",
       " 'TACGCTCCATGGAACG.1.11',\n",
       " 'ATTCTACTCAGTAGGG.11.9',\n",
       " 'GGATGTTAGCAACAAT.26.3',\n",
       " 'TGTGGTAGTACCGAGA.13.1',\n",
       " 'TCTACATGTAGTGATA.8.13',\n",
       " 'ACGTACATCGCGTCGA.22.3',\n",
       " 'ACTTATCTCTCACGAA.4.13',\n",
       " 'CTTCTAAAGTGGACTG.25.10',\n",
       " 'ATGAGGGGTGGGTATG.47.1',\n",
       " 'TCAAGACAGCATCGAG.18.6',\n",
       " 'CCACTTGAGTACAACA.8.10',\n",
       " 'GTCAGCGTCGCGTCGA.31.5',\n",
       " 'TATCGCCCAGAGGTTG.22.4',\n",
       " 'GCACGGTCAGCTACCG.8.10',\n",
       " 'ATTCATCAGAAACTAC.11.7',\n",
       " 'CCACGAGGTGTCCATA.5.6',\n",
       " 'CGAAGTTTCCTTCTGG.32.7',\n",
       " 'TATCTTGAGACTGTTC.41.2',\n",
       " 'ACCCAAACACATATGC.2.14',\n",
       " 'CCAAGCGTCGGCACTG.7.8',\n",
       " 'GTTATGGTCCGTGACG.11.10',\n",
       " 'ACGTACATCCCTATTA.9.14',\n",
       " 'GGGTTTACACGCTGCA.32.6',\n",
       " 'GCGTGCAAGATGCAGC.15.11',\n",
       " 'GTGCGTGCATGATCTG.17.7',\n",
       " 'TACATTCAGCTAAACA.22.9',\n",
       " 'CAAGACTCATGAATAG.19.6',\n",
       " 'TGAACGTGTCATGACT.5.9',\n",
       " 'TCATGCCCAGATCCTA.28.3',\n",
       " 'CGGAGTCCACGTGAGA.21.0',\n",
       " 'ATCGCCTGTGCGGTAA.4.7',\n",
       " 'GGAGATGGTCGAAACG.15.9',\n",
       " 'CTTTCGGAGAGCATTA.27.8',\n",
       " 'AAGTACCCACAGTCAT.28.11',\n",
       " 'ATGCCTCGTAGGTCAG.9.4',\n",
       " 'ACGGTCGTCGTGACTA.6.13',\n",
       " 'ATCACGAAGCCGTTGC.3.11',\n",
       " 'GTGGTTATCTACCTTA.12.12',\n",
       " 'GAAGTAATCTGCGAGC.13.7',\n",
       " 'CTACTATGTCCGCAGT.13.11',\n",
       " 'AAATGGACAAACCACT.16.2',\n",
       " 'TTCTAACAGTGCTCGC.3.8',\n",
       " 'CTCAGTCTCCCAACTC.12.12',\n",
       " 'TCGACGGTCGACCATA.12.2',\n",
       " 'CACGTTCGTTCAGGTT.6.9',\n",
       " 'GGGATGAGTGAACGGT.12.10',\n",
       " 'ATCCGTCAGATCACTC.31.4',\n",
       " 'AAAGGGCAGTGCAACG.11.9',\n",
       " 'ATTCCATAGGCTGTAG.5.8',\n",
       " 'GGGTCACCATCGGATT.2.14',\n",
       " 'CAACAGTCATGACTCA.22.2',\n",
       " 'CTGCCATCATTCTTCA.27.10',\n",
       " 'TTACAGGGTCCTGGGT.42.2',\n",
       " 'AGGTTACTCTAGTACG.12.7',\n",
       " 'TTGTGTTCATGCTGCG.12.7',\n",
       " 'GAATCGTCACCCGTAG.10.7',\n",
       " 'TGTAACGTCAGATGCT.17.10',\n",
       " 'TTGGTTTCAAAGGATT.32.5',\n",
       " 'CTCAGTCGTGTATACC.47.2',\n",
       " 'TCGGGACCAAGAGATT.5.11',\n",
       " 'CATCCCACATGACGGA.24.11',\n",
       " 'TCTCAGCCAGTCACGC.33.2',\n",
       " 'GAAATGAAGATCCAAA.13.11',\n",
       " 'GCTGCTTTCTACGAGT.39.1',\n",
       " 'AAACGCTCACATATCG.31.7',\n",
       " 'TATCGCCCACCGAATT.27.2',\n",
       " 'TCTGGCTGTACATTGC.29.2',\n",
       " 'GACTTCCCATACCGTA.32.11',\n",
       " 'TAAGAGAGTACCCAAT.37.1',\n",
       " 'CATTGCCCAAGACCTT.37.2',\n",
       " 'CTTAACTCATACTACG.6.0',\n",
       " 'GACCGTGAGACTTCCA.26.4',\n",
       " 'TGAGGAGAGATCCGAG.27.11',\n",
       " 'GAGACCCTCTGATTCT.17.11',\n",
       " 'TAAGCCAGTGCAACAG.1.3',\n",
       " 'ACTGTGAAGATGCCGA.19.6',\n",
       " 'TCCACCACACTAAACC.10.3',\n",
       " 'CATTCCGAGCAGGGAG.7.2',\n",
       " 'TTCAGGAAGGCCTGAA.6.11',\n",
       " 'AGAGCCCCATCGGCCA.2.9',\n",
       " 'AGTGCCGCATCTTAGG.8.9',\n",
       " 'AGTCTTTCATGCCACG.32.1',\n",
       " 'GTCACGGCAAATACGA.13.11',\n",
       " 'TGATTCTAGCCACTCG.2.7',\n",
       " 'TGAGGAGGTACCCACG.16.11',\n",
       " 'TGCGGCATCCGATAGT.14.6',\n",
       " 'AAGGTAATCGATGCTA.26.2',\n",
       " 'AGGTCTAGTCATCACA.28.11',\n",
       " 'TTCTTGAAGCCAAGCA.10.10',\n",
       " 'AGGTCATGTAGGCAAC.21.8',\n",
       " 'ATCACTTTCTTCACAT.34.2',\n",
       " 'TCATCATTCTGCACCT.21.9',\n",
       " 'TCTTCCTTCCTTACCG.2.2',\n",
       " 'AAAGTCCTCCTCACTG.3.13',\n",
       " 'TGTCCCACAGAAGCGT.2.7',\n",
       " 'ATCGTGAGTCACTGAT.11.13',\n",
       " 'AGCTCAAGTTCGGACC.10.8',\n",
       " 'CATATTCGTATCAGTC.14.0',\n",
       " 'TGGGCTGCACAACGCC.9.13',\n",
       " 'CGCCATTTCAGGCGAA.13.6',\n",
       " 'GTTATGGGTATGCTTG.30.9',\n",
       " 'TTCCTTCAGGCTAGCA.20.9',\n",
       " 'AATTTCCAGTTCGCAT.9.8',\n",
       " 'ACAAGCTGTCTTGTCC.15.5',\n",
       " 'ACCCAAAAGTGCGACA.7.14',\n",
       " 'ACTTATCTCAGAGTTC.28.6',\n",
       " 'TCCGATCGTGGGACAT.9.14',\n",
       " 'AAGCCATGTTTCGTGA.19.11',\n",
       " 'ACTGCTCGTAAACGCG.43.0',\n",
       " 'ATATCCTAGTCAGCCC.19.7',\n",
       " 'GTCATTTAGCTCCTTC.42.1',\n",
       " 'GTCATGAGTGTTACAC.28.11',\n",
       " 'GCCAGGTTCCATACAG.28.6',\n",
       " 'AGGGTGAGTGAGAACC.28.6',\n",
       " 'AGGTAGGAGGCCCGTT.24.4',\n",
       " 'GGGAGTAGTAAGGCTG.27.11',\n",
       " 'CTAGGTATCCACTTTA.39.2',\n",
       " 'GATGGAGGTACGGCAA.1.3',\n",
       " 'ACATTTCTCGCAATTG.9.11',\n",
       " 'GATGAGGGTCTTCATT.4.12',\n",
       " 'TGAGGAGTCCTATTGT.13.14',\n",
       " 'CTAGACATCGCCGATG.13.6',\n",
       " 'TTCCGGTAGAATTGTG.12.10',\n",
       " 'GTTCCGTGTATTTCTC.6.6',\n",
       " 'TCTCTGGGTCTCCCTA.6.9',\n",
       " 'CGTTAGATCTTAGCTT.11.9',\n",
       " 'CATATTCTCCACTGGG.14.0',\n",
       " 'TCTGGCTAGCATCAGG.31.9',\n",
       " 'AGATCCAAGACCTCCG.22.5',\n",
       " 'GTAACACGTCTATGAC.22.4',\n",
       " 'AAGCGAGCACTACGGC.12.10',\n",
       " 'ATAGAGATCCATCTGC.6.13',\n",
       " 'TGGATGTGTGCTGCAC.20.11',\n",
       " 'CTCATGCTCCTGGGAC.25.2',\n",
       " 'GAAGCGAAGCGCGTTC.23.4',\n",
       " 'TGCAGGCGTATGTCTG.31.11',\n",
       " 'ATTTCACAGGGCAGGA.41.2',\n",
       " 'TTTGGAGGTACAAACA.38.2',\n",
       " 'GACCAATGTACTAACC.16.9',\n",
       " 'ATAACGCAGCCAACAG.46.0',\n",
       " 'TACCCACCAGCAATTC.16.4',\n",
       " 'TCCCACAAGGTCGTAG.4.9',\n",
       " 'TCCATCGGTCTAGGTT.11.11',\n",
       " 'TGCTTCGAGAAGCTGC.1.5',\n",
       " 'AGGGCCTCAGTCAACT.7.14',\n",
       " 'AGGACGAAGAAACTAC.44.2',\n",
       " 'AAGTTCGTCAGCTTCC.4.14',\n",
       " 'CATCGGGAGAGCCCAA.47.0',\n",
       " 'GATTCGAGTGTCCTAA.26.5',\n",
       " 'TCATTCATCAATCTCT.31.3',\n",
       " 'GCGAGAAGTACCTAGT.1.11',\n",
       " 'AAGTTCGCATGGAACG.15.2',\n",
       " 'AGTGATCGTCCACACG.27.9',\n",
       " 'GCTCAAACATAACTCG.8.7',\n",
       " 'AAGGAATCAACGAGGT.21.10',\n",
       " 'CTGTCGTAGCTGAGCA.27.6',\n",
       " 'ATGTCCCAGATAGCTA.30.6',\n",
       " 'ATCGTGACAGAGTTGG.20.2',\n",
       " 'ACAGCCGGTAGCTGAG.1.9',\n",
       " 'AGTCATGCACTACAGT.29.11',\n",
       " 'TTGTGGAAGATGTAGT.14.8',\n",
       " 'TCTAACTTCCACACCT.8.8',\n",
       " 'TGGGATTAGTTGTAGA.22.10',\n",
       " 'TTCACGCAGCAAGCCA.9.8',\n",
       " 'CGTTGGGAGGTCGCCT.31.9',\n",
       " 'TTTCATGCATGAGATA.10.2',\n",
       " 'CCTAAGATCGCGCCAA.9.6',\n",
       " 'GATGAAAGTGGTAACG.7.1',\n",
       " 'TCCCATGCAAGGGTCA.14.4',\n",
       " 'TAGATCGAGCCTTTCC.5.3',\n",
       " 'TATTCCATCTGCTCTG.28.6',\n",
       " 'GGCTTTCAGTGGTCAG.16.9',\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(single_cell_metadata['cell_id']) - set(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58de492e-2def-477f-8a09-70281fe9963c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individualID</th>\n",
       "      <th>individualIdSource</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>subject</th>\n",
       "      <th>projid</th>\n",
       "      <th>Study</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>...</th>\n",
       "      <th>age_death</th>\n",
       "      <th>cts_mmse30_first_ad_dx</th>\n",
       "      <th>cts_mmse30_lv</th>\n",
       "      <th>braaksc</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>dcfdx_lv</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2626559</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>ROSMAP-45310</td>\n",
       "      <td>1211411</td>\n",
       "      <td>ROS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.549624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>No AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R9936070</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>ROSMAP-34387</td>\n",
       "      <td>2899847</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.450376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R2367199</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>ROSMAP-69520</td>\n",
       "      <td>3713990</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.928816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R9891381</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>ROSMAP-53306</td>\n",
       "      <td>3889845</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R9033345</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>ROSMAP-79585</td>\n",
       "      <td>6107196</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>R9738414</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>ROSMAP-90149</td>\n",
       "      <td>20976799</td>\n",
       "      <td>ROS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>No AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>R7737688</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69866926</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.104038</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>R7844746</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29286432</td>\n",
       "      <td>ROS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>R6692433</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48331728</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.715948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>R5309342</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.733333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10371937</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.032170</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    individualID individualIdSource     sex  ethnicity   pmi_df2  \\\n",
       "0       R2626559               Rush    male        NaN  6.500000   \n",
       "1       R9936070               Rush    male        NaN  7.016667   \n",
       "2       R2367199               Rush    male        NaN  4.333333   \n",
       "3       R9891381               Rush  female        NaN  6.916667   \n",
       "4       R9033345               Rush    male        NaN  4.166667   \n",
       "..           ...                ...     ...        ...       ...   \n",
       "509     R9738414               Rush  female        NaN  9.250000   \n",
       "510     R7737688               Rush  female        NaN  7.000000   \n",
       "511     R7844746               Rush    male        NaN  0.866667   \n",
       "512     R6692433               Rush  female        NaN  6.583333   \n",
       "513     R5309342               Rush  female        NaN  7.733333   \n",
       "\n",
       "          subject    projid Study  msex  educ  ...  age_death  \\\n",
       "0    ROSMAP-45310   1211411   ROS   1.0  12.0  ...  85.549624   \n",
       "1    ROSMAP-34387   2899847   MAP   1.0  14.0  ...  74.450376   \n",
       "2    ROSMAP-69520   3713990   MAP   1.0  12.0  ...  87.928816   \n",
       "3    ROSMAP-53306   3889845   MAP   0.0  13.0  ...  90.000000   \n",
       "4    ROSMAP-79585   6107196   MAP   1.0  15.0  ...  90.000000   \n",
       "..            ...       ...   ...   ...   ...  ...        ...   \n",
       "509  ROSMAP-90149  20976799   ROS   0.0  18.0  ...  90.000000   \n",
       "510           NaN  69866926   MAP   0.0  13.0  ...  84.104038   \n",
       "511           NaN  29286432   ROS   1.0  24.0  ...  90.000000   \n",
       "512           NaN  48331728   MAP   0.0  14.0  ...  82.715948   \n",
       "513           NaN  10371937   MAP   0.0  18.0  ...  81.032170   \n",
       "\n",
       "     cts_mmse30_first_ad_dx cts_mmse30_lv braaksc  ceradsc  cogdx  dcfdx_lv  \\\n",
       "0                       NaN          24.0     1.0      4.0    4.0       4.0   \n",
       "1                       NaN          27.0     2.0      2.0    3.0       3.0   \n",
       "2                       NaN          30.0     4.0      2.0    1.0       1.0   \n",
       "3                       NaN          22.0     2.0      1.0    2.0       2.0   \n",
       "4                       NaN          22.0     5.0      1.0    4.0       4.0   \n",
       "..                      ...           ...     ...      ...    ...       ...   \n",
       "509                     NaN          19.0     2.0      4.0    2.0       2.0   \n",
       "510                    20.0           3.0     6.0      1.0    4.0       4.0   \n",
       "511                     NaN          29.0     5.0      2.0    2.0       2.0   \n",
       "512                     NaN          27.0     2.0      4.0    1.0       1.0   \n",
       "513                    25.0          25.0     5.0      1.0    4.0       4.0   \n",
       "\n",
       "     clinical_diagnosis  pathological_diagnosis  clinical_pathological_AD  \n",
       "0                    AD                   No AD                     False  \n",
       "1                 False                   False                     False  \n",
       "2                   NCI                   False                     False  \n",
       "3                 False                      AD                     False  \n",
       "4                    AD                      AD           AD_with_Plaques  \n",
       "..                  ...                     ...                       ...  \n",
       "509               False                   No AD                     False  \n",
       "510                  AD                      AD           AD_with_Plaques  \n",
       "511               False                   False                     False  \n",
       "512                 NCI                   No AD       NCI_with_No_Plaques  \n",
       "513                  AD                      AD           AD_with_Plaques  \n",
       "\n",
       "[514 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5c386d1-69c7-4ff5-93b6-90b59a5336d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(single_cell_metadata.subject))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41b890d1-50ac-4d48-bbe7-0a7c5b6f60fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROSMAP-19345', 'ROSMAP-60910', 'ROSMAP-61723', 'ROSMAP-67297', nan}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(clinical_data.subject)-set(single_cell_metadata.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "458cfe00-51d3-4af3-a7ec-22c95e069d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_metadata = pd.merge(single_cell_metadata, clinical_data[['subject', 'individualID','clinical_diagnosis','pathological_diagnosis','clinical_pathological_AD']], on='subject', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a938d354-cb35-420d-a809-04c0688a0bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424431, 19)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata.shape\n",
    "#number of rows increased from 329000 something to this. means that there can be duplicate rows in the clinical data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c358b8c4-10ea-478f-995b-3ab1d4439eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID_x</th>\n",
       "      <th>clinical_diagnosis_x</th>\n",
       "      <th>pathological_diagnosis_x</th>\n",
       "      <th>clinical_pathological_AD_x</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "      <th>individualID_y</th>\n",
       "      <th>clinical_diagnosis_y</th>\n",
       "      <th>pathological_diagnosis_y</th>\n",
       "      <th>clinical_pathological_AD_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGAACGCGT.6.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>2651</td>\n",
       "      <td>1533</td>\n",
       "      <td>8.185590</td>\n",
       "      <td>0.452659</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-90639</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGAACTGAT.10.12</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGAAGCGGG.31.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGAATCCCT.14.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15297</td>\n",
       "      <td>4688</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-68841</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424426</th>\n",
       "      <td>TTTGTTGTCTTCCCGA.28.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424427</th>\n",
       "      <td>TTTGTTGTCTTCGACC.3.13</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>16770</td>\n",
       "      <td>5431</td>\n",
       "      <td>2.098986</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-53472</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424428</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424429</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424430</th>\n",
       "      <td>TTTGTTGTCTTTGCAT.22.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15282</td>\n",
       "      <td>4330</td>\n",
       "      <td>3.291454</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>0.869104</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-22203</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424431 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "1         AAACCCAAGAACGCGT.6.6     ROSMAP        2651          1533   \n",
       "2       AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764   \n",
       "3        AAACCCAAGAAGCGGG.31.8     ROSMAP       11658          4377   \n",
       "4        AAACCCAAGAATCCCT.14.8     ROSMAP       15297          4688   \n",
       "...                        ...        ...         ...           ...   \n",
       "424426   TTTGTTGTCTTCCCGA.28.6     ROSMAP       22844          5507   \n",
       "424427   TTTGTTGTCTTCGACC.3.13     ROSMAP       16770          5431   \n",
       "424428   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "424429   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "424430   TTTGTTGTCTTTGCAT.22.8     ROSMAP       15282          4330   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "1         8.185590    0.452659          0.930517         Inh L3-5 SST MAFB   \n",
       "2         4.809160    0.274809          0.901814            Inh LAMP5 RELN   \n",
       "3         5.738549    0.394579          0.895381            Inh VIP CLSTN2   \n",
       "4         0.921749    0.307250          0.877260            Inh VIP CLSTN2   \n",
       "...            ...         ...               ...                       ...   \n",
       "424426    0.153213    0.358956          0.858250           Inh PVALB SULF1   \n",
       "424427    2.098986    0.679785          0.884093             Inh CUX2 MSR1   \n",
       "424428    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "424429    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "424430    3.291454    0.261746          0.869104            Inh PVALB HTR4   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD individualID_x  \\\n",
       "0       ROSMAP-65967                        yes       R3857147   \n",
       "1       ROSMAP-90639                        yes       R7090624   \n",
       "2       ROSMAP-57958                        yes       R2347173   \n",
       "3       ROSMAP-40761                        yes       R1287407   \n",
       "4       ROSMAP-68841                        yes       R3757880   \n",
       "...              ...                        ...            ...   \n",
       "424426  ROSMAP-38931                         no       R6292415   \n",
       "424427  ROSMAP-53472                        yes       R3863249   \n",
       "424428  ROSMAP-44788                         no       R5221394   \n",
       "424429  ROSMAP-44788                         no       R5221394   \n",
       "424430  ROSMAP-22203                        yes       R7583108   \n",
       "\n",
       "       clinical_diagnosis_x pathological_diagnosis_x  \\\n",
       "0                        AD                       AD   \n",
       "1                       NCI                       AD   \n",
       "2                       NCI                       AD   \n",
       "3                     False                       AD   \n",
       "4                       NCI                       AD   \n",
       "...                     ...                      ...   \n",
       "424426                  NCI                    No AD   \n",
       "424427                False                    False   \n",
       "424428                  NCI                    No AD   \n",
       "424429                  NCI                    No AD   \n",
       "424430                   AD                       AD   \n",
       "\n",
       "       clinical_pathological_AD_x train_test_clinical_and_pathological  \\\n",
       "0                 AD_with_Plaques                                train   \n",
       "1                           False                                  NaN   \n",
       "2                           False                                  NaN   \n",
       "3                           False                                  NaN   \n",
       "4                           False                                  NaN   \n",
       "...                           ...                                  ...   \n",
       "424426        NCI_with_No_Plaques                                train   \n",
       "424427                      False                                  NaN   \n",
       "424428        NCI_with_No_Plaques                                 test   \n",
       "424429        NCI_with_No_Plaques                                 test   \n",
       "424430            AD_with_Plaques                                train   \n",
       "\n",
       "       individualID_y clinical_diagnosis_y pathological_diagnosis_y  \\\n",
       "0            R3857147                   AD                       AD   \n",
       "1            R7090624                  NCI                       AD   \n",
       "2            R2347173                  NCI                       AD   \n",
       "3            R1287407                False                       AD   \n",
       "4            R3757880                  NCI                       AD   \n",
       "...               ...                  ...                      ...   \n",
       "424426       R6292415                  NCI                    No AD   \n",
       "424427       R3863249                False                    False   \n",
       "424428       R5221394                  NCI                    No AD   \n",
       "424429       R5221394                  NCI                    No AD   \n",
       "424430       R7583108                   AD                       AD   \n",
       "\n",
       "       clinical_pathological_AD_y  \n",
       "0                 AD_with_Plaques  \n",
       "1                           False  \n",
       "2                           False  \n",
       "3                           False  \n",
       "4                           False  \n",
       "...                           ...  \n",
       "424426        NCI_with_No_Plaques  \n",
       "424427                      False  \n",
       "424428        NCI_with_No_Plaques  \n",
       "424429        NCI_with_No_Plaques  \n",
       "424430            AD_with_Plaques  \n",
       "\n",
       "[424431 rows x 19 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d55caf8-db9f-4176-9ce6-a2deb647c34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID_x</th>\n",
       "      <th>clinical_diagnosis_x</th>\n",
       "      <th>pathological_diagnosis_x</th>\n",
       "      <th>clinical_pathological_AD_x</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "      <th>individualID_y</th>\n",
       "      <th>clinical_diagnosis_y</th>\n",
       "      <th>pathological_diagnosis_y</th>\n",
       "      <th>clinical_pathological_AD_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGAACGCGT.6.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>2651</td>\n",
       "      <td>1533</td>\n",
       "      <td>8.185590</td>\n",
       "      <td>0.452659</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-90639</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGAACTGAT.10.12</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGAAGCGGG.31.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGAATCCCT.14.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15297</td>\n",
       "      <td>4688</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-68841</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424425</th>\n",
       "      <td>TTTGTTGTCTTAGCAG.7.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9309</td>\n",
       "      <td>3459</td>\n",
       "      <td>2.062520</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.891670</td>\n",
       "      <td>Inh VIP TSHZ2</td>\n",
       "      <td>ROSMAP-77886</td>\n",
       "      <td>no</td>\n",
       "      <td>R2554598</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R2554598</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424426</th>\n",
       "      <td>TTTGTTGTCTTCCCGA.28.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424427</th>\n",
       "      <td>TTTGTTGTCTTCGACC.3.13</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>16770</td>\n",
       "      <td>5431</td>\n",
       "      <td>2.098986</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-53472</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424428</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424430</th>\n",
       "      <td>TTTGTTGTCTTTGCAT.22.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15282</td>\n",
       "      <td>4330</td>\n",
       "      <td>3.291454</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>0.869104</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-22203</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329699 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "1         AAACCCAAGAACGCGT.6.6     ROSMAP        2651          1533   \n",
       "2       AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764   \n",
       "3        AAACCCAAGAAGCGGG.31.8     ROSMAP       11658          4377   \n",
       "4        AAACCCAAGAATCCCT.14.8     ROSMAP       15297          4688   \n",
       "...                        ...        ...         ...           ...   \n",
       "424425    TTTGTTGTCTTAGCAG.7.9     ROSMAP        9309          3459   \n",
       "424426   TTTGTTGTCTTCCCGA.28.6     ROSMAP       22844          5507   \n",
       "424427   TTTGTTGTCTTCGACC.3.13     ROSMAP       16770          5431   \n",
       "424428   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "424430   TTTGTTGTCTTTGCAT.22.8     ROSMAP       15282          4330   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "1         8.185590    0.452659          0.930517         Inh L3-5 SST MAFB   \n",
       "2         4.809160    0.274809          0.901814            Inh LAMP5 RELN   \n",
       "3         5.738549    0.394579          0.895381            Inh VIP CLSTN2   \n",
       "4         0.921749    0.307250          0.877260            Inh VIP CLSTN2   \n",
       "...            ...         ...               ...                       ...   \n",
       "424425    2.062520    0.225588          0.891670             Inh VIP TSHZ2   \n",
       "424426    0.153213    0.358956          0.858250           Inh PVALB SULF1   \n",
       "424427    2.098986    0.679785          0.884093             Inh CUX2 MSR1   \n",
       "424428    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "424430    3.291454    0.261746          0.869104            Inh PVALB HTR4   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD individualID_x  \\\n",
       "0       ROSMAP-65967                        yes       R3857147   \n",
       "1       ROSMAP-90639                        yes       R7090624   \n",
       "2       ROSMAP-57958                        yes       R2347173   \n",
       "3       ROSMAP-40761                        yes       R1287407   \n",
       "4       ROSMAP-68841                        yes       R3757880   \n",
       "...              ...                        ...            ...   \n",
       "424425  ROSMAP-77886                         no       R2554598   \n",
       "424426  ROSMAP-38931                         no       R6292415   \n",
       "424427  ROSMAP-53472                        yes       R3863249   \n",
       "424428  ROSMAP-44788                         no       R5221394   \n",
       "424430  ROSMAP-22203                        yes       R7583108   \n",
       "\n",
       "       clinical_diagnosis_x pathological_diagnosis_x  \\\n",
       "0                        AD                       AD   \n",
       "1                       NCI                       AD   \n",
       "2                       NCI                       AD   \n",
       "3                     False                       AD   \n",
       "4                       NCI                       AD   \n",
       "...                     ...                      ...   \n",
       "424425                  NCI                    False   \n",
       "424426                  NCI                    No AD   \n",
       "424427                False                    False   \n",
       "424428                  NCI                    No AD   \n",
       "424430                   AD                       AD   \n",
       "\n",
       "       clinical_pathological_AD_x train_test_clinical_and_pathological  \\\n",
       "0                 AD_with_Plaques                                train   \n",
       "1                           False                                  NaN   \n",
       "2                           False                                  NaN   \n",
       "3                           False                                  NaN   \n",
       "4                           False                                  NaN   \n",
       "...                           ...                                  ...   \n",
       "424425                      False                                  NaN   \n",
       "424426        NCI_with_No_Plaques                                train   \n",
       "424427                      False                                  NaN   \n",
       "424428        NCI_with_No_Plaques                                 test   \n",
       "424430            AD_with_Plaques                                train   \n",
       "\n",
       "       individualID_y clinical_diagnosis_y pathological_diagnosis_y  \\\n",
       "0            R3857147                   AD                       AD   \n",
       "1            R7090624                  NCI                       AD   \n",
       "2            R2347173                  NCI                       AD   \n",
       "3            R1287407                False                       AD   \n",
       "4            R3757880                  NCI                       AD   \n",
       "...               ...                  ...                      ...   \n",
       "424425       R2554598                  NCI                    False   \n",
       "424426       R6292415                  NCI                    No AD   \n",
       "424427       R3863249                False                    False   \n",
       "424428       R5221394                  NCI                    No AD   \n",
       "424430       R7583108                   AD                       AD   \n",
       "\n",
       "       clinical_pathological_AD_y  \n",
       "0                 AD_with_Plaques  \n",
       "1                           False  \n",
       "2                           False  \n",
       "3                           False  \n",
       "4                           False  \n",
       "...                           ...  \n",
       "424425                      False  \n",
       "424426        NCI_with_No_Plaques  \n",
       "424427                      False  \n",
       "424428        NCI_with_No_Plaques  \n",
       "424430            AD_with_Plaques  \n",
       "\n",
       "[329699 rows x 19 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata= single_cell_metadata.drop_duplicates()\n",
    "single_cell_metadata\n",
    "#we have dropped duplicates and now we are back to the original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfd744c3-1ed6-44d5-b338-9072ad3825f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cell_id', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt',\n",
      "       'percent.rb', 'log10GenesPerUMI', 'cell_type_high_resolution',\n",
      "       'subject', 'Pathologic_diagnosis_of_AD', 'individualID_x',\n",
      "       'clinical_diagnosis_x', 'pathological_diagnosis_x',\n",
      "       'clinical_pathological_AD_x', 'train_test_clinical_and_pathological',\n",
      "       'individualID_y', 'clinical_diagnosis_y', 'pathological_diagnosis_y',\n",
      "       'clinical_pathological_AD_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(single_cell_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f62d5df-ab59-4f2a-8eff-d6d4850f786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    single_cell_metadata.clinical_diagnosis_x.value_counts()\n",
    "except:\n",
    "    print('no_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69fb86c8-747d-417b-a620-a6e60d5624d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clinical_diagnosis_x\n",
       "NCI      134893\n",
       "AD       110222\n",
       "False     84584\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata.clinical_diagnosis_x.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b3c6d-553e-4e56-be32-c7e76d41018a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c322a84a-9e38-45d5-8353-accc2ff11143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_columns\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    single_cell_metadata.clinical_pathological_AD.value_counts()\n",
    "except:\n",
    "    print('no_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4e54d4c-1f7d-4613-a4f6-1cfffcaee0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pathologic_diagnosis_of_AD\n",
       "yes    175222\n",
       "no     154477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata.Pathologic_diagnosis_of_AD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16ac4de0-5592-444e-beb9-7c947d2551e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathological_diagnosis_y\n",
       "False    124037\n",
       "No AD    115507\n",
       "AD        90155\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata.pathological_diagnosis_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd338bc4-ad6e-47ce-891e-13137fe87ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rosmap_subject_single_cell_metadata = pd.merge(pd.DataFrame(single_cell_metadata.subject.value_counts()).reset_index(),clinical_data[['subject','clinical_pathological_AD']], on='subject', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04a91d9a-b391-4217-82da-bf2360db04a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>count</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROSMAP-20815</td>\n",
       "      <td>2826</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROSMAP-20815</td>\n",
       "      <td>2826</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROSMAP-32462</td>\n",
       "      <td>2769</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROSMAP-32462</td>\n",
       "      <td>2769</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROSMAP-74690</td>\n",
       "      <td>2727</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>ROSMAP-51607</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>ROSMAP-30204</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>ROSMAP-56773</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ROSMAP-14312</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>ROSMAP-71139</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject  count clinical_pathological_AD\n",
       "0    ROSMAP-20815   2826      NCI_with_No_Plaques\n",
       "1    ROSMAP-20815   2826      NCI_with_No_Plaques\n",
       "2    ROSMAP-32462   2769                    False\n",
       "3    ROSMAP-32462   2769                    False\n",
       "4    ROSMAP-74690   2727      NCI_with_No_Plaques\n",
       "..            ...    ...                      ...\n",
       "485  ROSMAP-51607      3                    False\n",
       "486  ROSMAP-30204      2                    False\n",
       "487  ROSMAP-56773      1                    False\n",
       "488  ROSMAP-14312      1                    False\n",
       "489  ROSMAP-71139      1                    False\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosmap_subject_single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3b0f546-1ce9-42e9-a53f-48aa0da1891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>count</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROSMAP-20815</td>\n",
       "      <td>2826</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROSMAP-20815</td>\n",
       "      <td>2826</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROSMAP-74690</td>\n",
       "      <td>2727</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ROSMAP-74690</td>\n",
       "      <td>2727</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ROSMAP-83589</td>\n",
       "      <td>2550</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>ROSMAP-97816</td>\n",
       "      <td>71</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ROSMAP-18944</td>\n",
       "      <td>59</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>ROSMAP-80730</td>\n",
       "      <td>38</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>ROSMAP-78083</td>\n",
       "      <td>22</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>ROSMAP-72912</td>\n",
       "      <td>22</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject  count clinical_pathological_AD\n",
       "0    ROSMAP-20815   2826      NCI_with_No_Plaques\n",
       "1    ROSMAP-20815   2826      NCI_with_No_Plaques\n",
       "4    ROSMAP-74690   2727      NCI_with_No_Plaques\n",
       "5    ROSMAP-74690   2727      NCI_with_No_Plaques\n",
       "8    ROSMAP-83589   2550          AD_with_Plaques\n",
       "..            ...    ...                      ...\n",
       "467  ROSMAP-97816     71      NCI_with_No_Plaques\n",
       "472  ROSMAP-18944     59          AD_with_Plaques\n",
       "477  ROSMAP-80730     38          AD_with_Plaques\n",
       "481  ROSMAP-78083     22          AD_with_Plaques\n",
       "482  ROSMAP-72912     22          AD_with_Plaques\n",
       "\n",
       "[173 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosmap_subject_single_cell_metadata = rosmap_subject_single_cell_metadata[~rosmap_subject_single_cell_metadata.isin(['False']).any(axis=1)]\n",
    "rosmap_subject_single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4333b6c2-30dd-4818-9a7d-2fd1ad1cec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_set_size = 0.80*np.sum(list(rosmap_subject_single_cell_metadata['count']))\n",
    "test_set_size = 0.20*np.sum(list(rosmap_subject_single_cell_metadata['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424a547-0a95-481b-8340-9238fee2e0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a557bd8-f97a-449d-adfc-b921b3a2ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = rosmap_subject_single_cell_metadata[rosmap_subject_single_cell_metadata.clinical_pathological_AD == 'NCI_with_No_Plaques']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5fac3f4-0ebb-45f4-90da-0cbd2ffc16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_samples = rosmap_subject_single_cell_metadata[rosmap_subject_single_cell_metadata.clinical_pathological_AD == 'AD_with_Plaques']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "724ba8b9-2557-4dd6-a32f-3272a1538776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>count</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROSMAP-20815</td>\n",
       "      <td>2826</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROSMAP-20815</td>\n",
       "      <td>2826</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROSMAP-74690</td>\n",
       "      <td>2727</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ROSMAP-74690</td>\n",
       "      <td>2727</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ROSMAP-61304</td>\n",
       "      <td>2495</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>ROSMAP-92734</td>\n",
       "      <td>127</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>ROSMAP-61943</td>\n",
       "      <td>88</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>ROSMAP-84621</td>\n",
       "      <td>86</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>ROSMAP-97816</td>\n",
       "      <td>71</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>ROSMAP-97816</td>\n",
       "      <td>71</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject  count clinical_pathological_AD\n",
       "0    ROSMAP-20815   2826      NCI_with_No_Plaques\n",
       "1    ROSMAP-20815   2826      NCI_with_No_Plaques\n",
       "4    ROSMAP-74690   2727      NCI_with_No_Plaques\n",
       "5    ROSMAP-74690   2727      NCI_with_No_Plaques\n",
       "10   ROSMAP-61304   2495      NCI_with_No_Plaques\n",
       "..            ...    ...                      ...\n",
       "448  ROSMAP-92734    127      NCI_with_No_Plaques\n",
       "460  ROSMAP-61943     88      NCI_with_No_Plaques\n",
       "462  ROSMAP-84621     86      NCI_with_No_Plaques\n",
       "466  ROSMAP-97816     71      NCI_with_No_Plaques\n",
       "467  ROSMAP-97816     71      NCI_with_No_Plaques\n",
       "\n",
       "[89 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd2a7eee-123b-4d54-aff0-f973eedf7df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>count</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ROSMAP-83589</td>\n",
       "      <td>2550</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ROSMAP-83589</td>\n",
       "      <td>2550</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ROSMAP-40248</td>\n",
       "      <td>2403</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ROSMAP-40248</td>\n",
       "      <td>2403</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ROSMAP-87836</td>\n",
       "      <td>1988</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>ROSMAP-25704</td>\n",
       "      <td>76</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ROSMAP-18944</td>\n",
       "      <td>59</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>ROSMAP-80730</td>\n",
       "      <td>38</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>ROSMAP-78083</td>\n",
       "      <td>22</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>ROSMAP-72912</td>\n",
       "      <td>22</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject  count clinical_pathological_AD\n",
       "8    ROSMAP-83589   2550          AD_with_Plaques\n",
       "9    ROSMAP-83589   2550          AD_with_Plaques\n",
       "17   ROSMAP-40248   2403          AD_with_Plaques\n",
       "18   ROSMAP-40248   2403          AD_with_Plaques\n",
       "28   ROSMAP-87836   1988          AD_with_Plaques\n",
       "..            ...    ...                      ...\n",
       "464  ROSMAP-25704     76          AD_with_Plaques\n",
       "472  ROSMAP-18944     59          AD_with_Plaques\n",
       "477  ROSMAP-80730     38          AD_with_Plaques\n",
       "481  ROSMAP-78083     22          AD_with_Plaques\n",
       "482  ROSMAP-72912     22          AD_with_Plaques\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "355cae0d-a487-4542-bf60-8b37ccc09c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sort the DataFrame by the count column\n",
    "neg_samples = neg_samples.sort_values(by='count', ascending=True)\n",
    "neg_samples['serial_number'] = [i for i in range(len(neg_samples))]\n",
    "# Calculate cumulative counts\n",
    "neg_samples['cumulative_count'] = neg_samples['count'].cumsum()\n",
    "\n",
    "# Normalize cumulative counts to get percentages\n",
    "neg_samples['cumulative_percent'] = neg_samples['cumulative_count'] / neg_samples['count'].sum() * 100\n",
    "\n",
    "# Plot cumulative counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(neg_samples['serial_number'], neg_samples['cumulative_percent'], marker='o', linestyle='-')\n",
    "\n",
    "# Add 80 percent horizontal line\n",
    "plt.axhline(y=80, color='r', linestyle='--')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Cumulative Percentage')\n",
    "plt.title('Cumulative Plot with 80% Horizontal Line')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5605a561-91e2-486c-bf22-8ddf8cc195ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>count</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>cumulative_count</th>\n",
       "      <th>cumulative_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ROSMAP-66658</td>\n",
       "      <td>1712</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>69</td>\n",
       "      <td>59165</td>\n",
       "      <td>58.677391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ROSMAP-77461</td>\n",
       "      <td>1719</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>70</td>\n",
       "      <td>60884</td>\n",
       "      <td>60.382224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ROSMAP-77461</td>\n",
       "      <td>1719</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>71</td>\n",
       "      <td>62603</td>\n",
       "      <td>62.087057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ROSMAP-28539</td>\n",
       "      <td>1764</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>72</td>\n",
       "      <td>64367</td>\n",
       "      <td>63.836519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ROSMAP-28539</td>\n",
       "      <td>1764</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>73</td>\n",
       "      <td>66131</td>\n",
       "      <td>65.585981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ROSMAP-27818</td>\n",
       "      <td>1801</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>74</td>\n",
       "      <td>67932</td>\n",
       "      <td>67.372138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ROSMAP-27818</td>\n",
       "      <td>1801</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>75</td>\n",
       "      <td>69733</td>\n",
       "      <td>69.158295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ROSMAP-78527</td>\n",
       "      <td>1839</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>76</td>\n",
       "      <td>71572</td>\n",
       "      <td>70.982138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ROSMAP-96129</td>\n",
       "      <td>1915</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>77</td>\n",
       "      <td>73487</td>\n",
       "      <td>72.881356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ROSMAP-96129</td>\n",
       "      <td>1915</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>78</td>\n",
       "      <td>75402</td>\n",
       "      <td>74.780573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ROSMAP-82353</td>\n",
       "      <td>1946</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>79</td>\n",
       "      <td>77348</td>\n",
       "      <td>76.710535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ROSMAP-25736</td>\n",
       "      <td>2421</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>80</td>\n",
       "      <td>79769</td>\n",
       "      <td>79.111583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>2483</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>81</td>\n",
       "      <td>82252</td>\n",
       "      <td>81.574119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>2483</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>82</td>\n",
       "      <td>84735</td>\n",
       "      <td>84.036655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ROSMAP-61304</td>\n",
       "      <td>2495</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>83</td>\n",
       "      <td>87230</td>\n",
       "      <td>86.511093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ROSMAP-61304</td>\n",
       "      <td>2495</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>84</td>\n",
       "      <td>89725</td>\n",
       "      <td>88.985530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ROSMAP-74690</td>\n",
       "      <td>2727</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>85</td>\n",
       "      <td>92452</td>\n",
       "      <td>91.690056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROSMAP-74690</td>\n",
       "      <td>2727</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>86</td>\n",
       "      <td>95179</td>\n",
       "      <td>94.394581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROSMAP-20815</td>\n",
       "      <td>2826</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>87</td>\n",
       "      <td>98005</td>\n",
       "      <td>97.197291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROSMAP-20815</td>\n",
       "      <td>2826</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>88</td>\n",
       "      <td>100831</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject  count clinical_pathological_AD  serial_number  \\\n",
       "54  ROSMAP-66658   1712      NCI_with_No_Plaques             69   \n",
       "51  ROSMAP-77461   1719      NCI_with_No_Plaques             70   \n",
       "50  ROSMAP-77461   1719      NCI_with_No_Plaques             71   \n",
       "49  ROSMAP-28539   1764      NCI_with_No_Plaques             72   \n",
       "48  ROSMAP-28539   1764      NCI_with_No_Plaques             73   \n",
       "43  ROSMAP-27818   1801      NCI_with_No_Plaques             74   \n",
       "42  ROSMAP-27818   1801      NCI_with_No_Plaques             75   \n",
       "37  ROSMAP-78527   1839      NCI_with_No_Plaques             76   \n",
       "32  ROSMAP-96129   1915      NCI_with_No_Plaques             77   \n",
       "31  ROSMAP-96129   1915      NCI_with_No_Plaques             78   \n",
       "30  ROSMAP-82353   1946      NCI_with_No_Plaques             79   \n",
       "16  ROSMAP-25736   2421      NCI_with_No_Plaques             80   \n",
       "13  ROSMAP-44788   2483      NCI_with_No_Plaques             81   \n",
       "12  ROSMAP-44788   2483      NCI_with_No_Plaques             82   \n",
       "11  ROSMAP-61304   2495      NCI_with_No_Plaques             83   \n",
       "10  ROSMAP-61304   2495      NCI_with_No_Plaques             84   \n",
       "5   ROSMAP-74690   2727      NCI_with_No_Plaques             85   \n",
       "4   ROSMAP-74690   2727      NCI_with_No_Plaques             86   \n",
       "1   ROSMAP-20815   2826      NCI_with_No_Plaques             87   \n",
       "0   ROSMAP-20815   2826      NCI_with_No_Plaques             88   \n",
       "\n",
       "    cumulative_count  cumulative_percent  \n",
       "54             59165           58.677391  \n",
       "51             60884           60.382224  \n",
       "50             62603           62.087057  \n",
       "49             64367           63.836519  \n",
       "48             66131           65.585981  \n",
       "43             67932           67.372138  \n",
       "42             69733           69.158295  \n",
       "37             71572           70.982138  \n",
       "32             73487           72.881356  \n",
       "31             75402           74.780573  \n",
       "30             77348           76.710535  \n",
       "16             79769           79.111583  \n",
       "13             82252           81.574119  \n",
       "12             84735           84.036655  \n",
       "11             87230           86.511093  \n",
       "10             89725           88.985530  \n",
       "5              92452           91.690056  \n",
       "4              95179           94.394581  \n",
       "1              98005           97.197291  \n",
       "0             100831          100.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9909afc1-3ac9-4b0c-9a16-1e88fd34ce4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Sort the DataFrame by the count column\n",
    "pos_samples = pos_samples.sort_values(by='count', ascending=True)\n",
    "pos_samples['serial_number'] = [i for i in range(len(pos_samples))]\n",
    "# Calculate cumulative counts\n",
    "pos_samples['cumulative_count'] = pos_samples['count'].cumsum()\n",
    "\n",
    "# Normalize cumulative counts to get percentages\n",
    "pos_samples['cumulative_percent'] = pos_samples['cumulative_count'] / pos_samples['count'].sum() * 100\n",
    "\n",
    "# Plot cumulative counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pos_samples['serial_number'], pos_samples['cumulative_percent'], marker='o', linestyle='-')\n",
    "\n",
    "# Add 80 percent horizontal line\n",
    "plt.axhline(y=80, color='r', linestyle='--')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Cumulative Percentage')\n",
    "plt.title('Cumulative Plot with 80% Horizontal Line')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cf9c6eb-5392-4e61-8680-5a6c20930cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>count</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>cumulative_count</th>\n",
       "      <th>cumulative_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>ROSMAP-37253</td>\n",
       "      <td>1099</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>64</td>\n",
       "      <td>38180</td>\n",
       "      <td>55.171816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ROSMAP-79151</td>\n",
       "      <td>1104</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>65</td>\n",
       "      <td>39284</td>\n",
       "      <td>56.767145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>ROSMAP-79151</td>\n",
       "      <td>1104</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>66</td>\n",
       "      <td>40388</td>\n",
       "      <td>58.362475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>ROSMAP-31874</td>\n",
       "      <td>1148</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>67</td>\n",
       "      <td>41536</td>\n",
       "      <td>60.021387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>ROSMAP-10132</td>\n",
       "      <td>1149</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>68</td>\n",
       "      <td>42685</td>\n",
       "      <td>61.681743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>ROSMAP-83961</td>\n",
       "      <td>1224</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>69</td>\n",
       "      <td>43909</td>\n",
       "      <td>63.450478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ROSMAP-25922</td>\n",
       "      <td>1244</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>70</td>\n",
       "      <td>45153</td>\n",
       "      <td>65.248114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ROSMAP-53808</td>\n",
       "      <td>1419</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>71</td>\n",
       "      <td>46572</td>\n",
       "      <td>67.298633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ROSMAP-53808</td>\n",
       "      <td>1419</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>72</td>\n",
       "      <td>47991</td>\n",
       "      <td>69.349152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ROSMAP-50941</td>\n",
       "      <td>1431</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>73</td>\n",
       "      <td>49422</td>\n",
       "      <td>71.417011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>ROSMAP-50941</td>\n",
       "      <td>1431</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>74</td>\n",
       "      <td>50853</td>\n",
       "      <td>73.484870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ROSMAP-43882</td>\n",
       "      <td>1459</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>75</td>\n",
       "      <td>52312</td>\n",
       "      <td>75.593191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ROSMAP-85806</td>\n",
       "      <td>1504</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>76</td>\n",
       "      <td>53816</td>\n",
       "      <td>77.766539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>ROSMAP-85806</td>\n",
       "      <td>1504</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>77</td>\n",
       "      <td>55320</td>\n",
       "      <td>79.939886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ROSMAP-87836</td>\n",
       "      <td>1988</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>78</td>\n",
       "      <td>57308</td>\n",
       "      <td>82.812635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ROSMAP-87836</td>\n",
       "      <td>1988</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>79</td>\n",
       "      <td>59296</td>\n",
       "      <td>85.685385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ROSMAP-40248</td>\n",
       "      <td>2403</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>80</td>\n",
       "      <td>61699</td>\n",
       "      <td>89.157828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ROSMAP-40248</td>\n",
       "      <td>2403</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>81</td>\n",
       "      <td>64102</td>\n",
       "      <td>92.630271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ROSMAP-83589</td>\n",
       "      <td>2550</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>82</td>\n",
       "      <td>66652</td>\n",
       "      <td>96.315135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ROSMAP-83589</td>\n",
       "      <td>2550</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>83</td>\n",
       "      <td>69202</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject  count clinical_pathological_AD  serial_number  \\\n",
       "136  ROSMAP-37253   1099          AD_with_Plaques             64   \n",
       "132  ROSMAP-79151   1104          AD_with_Plaques             65   \n",
       "133  ROSMAP-79151   1104          AD_with_Plaques             66   \n",
       "125  ROSMAP-31874   1148          AD_with_Plaques             67   \n",
       "124  ROSMAP-10132   1149          AD_with_Plaques             68   \n",
       "110  ROSMAP-83961   1224          AD_with_Plaques             69   \n",
       "107  ROSMAP-25922   1244          AD_with_Plaques             70   \n",
       "86   ROSMAP-53808   1419          AD_with_Plaques             71   \n",
       "85   ROSMAP-53808   1419          AD_with_Plaques             72   \n",
       "83   ROSMAP-50941   1431          AD_with_Plaques             73   \n",
       "82   ROSMAP-50941   1431          AD_with_Plaques             74   \n",
       "79   ROSMAP-43882   1459          AD_with_Plaques             75   \n",
       "73   ROSMAP-85806   1504          AD_with_Plaques             76   \n",
       "74   ROSMAP-85806   1504          AD_with_Plaques             77   \n",
       "29   ROSMAP-87836   1988          AD_with_Plaques             78   \n",
       "28   ROSMAP-87836   1988          AD_with_Plaques             79   \n",
       "18   ROSMAP-40248   2403          AD_with_Plaques             80   \n",
       "17   ROSMAP-40248   2403          AD_with_Plaques             81   \n",
       "9    ROSMAP-83589   2550          AD_with_Plaques             82   \n",
       "8    ROSMAP-83589   2550          AD_with_Plaques             83   \n",
       "\n",
       "     cumulative_count  cumulative_percent  \n",
       "136             38180           55.171816  \n",
       "132             39284           56.767145  \n",
       "133             40388           58.362475  \n",
       "125             41536           60.021387  \n",
       "124             42685           61.681743  \n",
       "110             43909           63.450478  \n",
       "107             45153           65.248114  \n",
       "86              46572           67.298633  \n",
       "85              47991           69.349152  \n",
       "83              49422           71.417011  \n",
       "82              50853           73.484870  \n",
       "79              52312           75.593191  \n",
       "73              53816           77.766539  \n",
       "74              55320           79.939886  \n",
       "29              57308           82.812635  \n",
       "28              59296           85.685385  \n",
       "18              61699           89.157828  \n",
       "17              64102           92.630271  \n",
       "9               66652           96.315135  \n",
       "8               69202          100.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_samples.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3daa3baa-41ca-429c-9855-389a969e64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_samples = pos_samples[pos_samples.cumulative_percent<=80].subject\n",
    "test_pos_samples = pos_samples[pos_samples.cumulative_percent>80].subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca36913a-e803-4005-840c-0cf7502a3b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    ROSMAP-87836\n",
       "28    ROSMAP-87836\n",
       "18    ROSMAP-40248\n",
       "17    ROSMAP-40248\n",
       "9     ROSMAP-83589\n",
       "8     ROSMAP-83589\n",
       "Name: subject, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pos_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40deadf8-774e-457b-ac91-0543a95af7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_samples = neg_samples[neg_samples.cumulative_percent<=80].subject\n",
    "test_neg_samples = neg_samples[neg_samples.cumulative_percent>80].subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44925449-d148-46d5-8a00-3a5d3b7860c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467    ROSMAP-97816\n",
       "466    ROSMAP-97816\n",
       "462    ROSMAP-84621\n",
       "460    ROSMAP-61943\n",
       "448    ROSMAP-92734\n",
       "           ...     \n",
       "37     ROSMAP-78527\n",
       "32     ROSMAP-96129\n",
       "31     ROSMAP-96129\n",
       "30     ROSMAP-82353\n",
       "16     ROSMAP-25736\n",
       "Name: subject, Length: 81, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b30b218-76ea-40e9-9671-15a738a80a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482    ROSMAP-72912\n",
       "481    ROSMAP-78083\n",
       "477    ROSMAP-80730\n",
       "472    ROSMAP-18944\n",
       "464    ROSMAP-25704\n",
       "           ...     \n",
       "83     ROSMAP-50941\n",
       "82     ROSMAP-50941\n",
       "79     ROSMAP-43882\n",
       "73     ROSMAP-85806\n",
       "74     ROSMAP-85806\n",
       "Name: subject, Length: 78, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06ab6c69-5ecc-4c91-84a2-24c8e2297249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = list(train_pos_samples) + (list(train_neg_samples))\n",
    "test_samples = list(test_pos_samples) + (list(test_neg_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a58606c-add4-4d73-8d18-d495fa91ab4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b12dce4d-2a82-4422-be69-7e4d110e7781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15aef15f-7e6a-46f0-ac22-4b63d544aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_test(x):\n",
    "    if x in train_samples:\n",
    "        return 'train'\n",
    "    elif x in test_samples:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6200f20-e89f-4b6f-b730-8936426d2b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_570474/2784772941.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_cell_metadata['train_test_clinical_and_pathological'] = single_cell_metadata.subject.apply(return_train_test)\n"
     ]
    }
   ],
   "source": [
    "single_cell_metadata['train_test_clinical_and_pathological'] = single_cell_metadata.subject.apply(return_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebf5d919-ce5a-4f27-832c-6a60f2348097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_test_clinical_and_pathological\n",
       "train    106821\n",
       "test      17472\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata.train_test_clinical_and_pathological.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ceccae79-0b37-48d0-b295-87eb9299abd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'clinical_pathological_AD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_570474/1097993735.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msingle_cell_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msingle_cell_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_clinical_and_pathological\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclinical_pathological_AD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'clinical_pathological_AD'"
     ]
    }
   ],
   "source": [
    "single_cell_metadata[single_cell_metadata.train_test_clinical_and_pathological=='train'].clinical_pathological_AD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1bcf353-8567-4783-b7ec-4038dd9c31db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clinical_pathological_AD\n",
       "NCI_with_No_Plaques    10531\n",
       "AD_with_Plaques         6941\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata[single_cell_metadata.train_test_clinical_and_pathological=='test'].clinical_pathological_AD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "760e0dbb-0d12-4ff2-a94a-c4564322b54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGAACGCGT.6.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>2651</td>\n",
       "      <td>1533</td>\n",
       "      <td>8.185590</td>\n",
       "      <td>0.452659</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-90639</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGAACTGAT.10.12</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGAAGCGGG.31.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGAATCCCT.14.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15297</td>\n",
       "      <td>4688</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-68841</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424425</th>\n",
       "      <td>TTTGTTGTCTTAGCAG.7.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9309</td>\n",
       "      <td>3459</td>\n",
       "      <td>2.062520</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.891670</td>\n",
       "      <td>Inh VIP TSHZ2</td>\n",
       "      <td>ROSMAP-77886</td>\n",
       "      <td>no</td>\n",
       "      <td>R2554598</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424426</th>\n",
       "      <td>TTTGTTGTCTTCCCGA.28.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424427</th>\n",
       "      <td>TTTGTTGTCTTCGACC.3.13</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>16770</td>\n",
       "      <td>5431</td>\n",
       "      <td>2.098986</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-53472</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424428</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424430</th>\n",
       "      <td>TTTGTTGTCTTTGCAT.22.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15282</td>\n",
       "      <td>4330</td>\n",
       "      <td>3.291454</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>0.869104</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-22203</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329699 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "1         AAACCCAAGAACGCGT.6.6     ROSMAP        2651          1533   \n",
       "2       AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764   \n",
       "3        AAACCCAAGAAGCGGG.31.8     ROSMAP       11658          4377   \n",
       "4        AAACCCAAGAATCCCT.14.8     ROSMAP       15297          4688   \n",
       "...                        ...        ...         ...           ...   \n",
       "424425    TTTGTTGTCTTAGCAG.7.9     ROSMAP        9309          3459   \n",
       "424426   TTTGTTGTCTTCCCGA.28.6     ROSMAP       22844          5507   \n",
       "424427   TTTGTTGTCTTCGACC.3.13     ROSMAP       16770          5431   \n",
       "424428   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "424430   TTTGTTGTCTTTGCAT.22.8     ROSMAP       15282          4330   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "1         8.185590    0.452659          0.930517         Inh L3-5 SST MAFB   \n",
       "2         4.809160    0.274809          0.901814            Inh LAMP5 RELN   \n",
       "3         5.738549    0.394579          0.895381            Inh VIP CLSTN2   \n",
       "4         0.921749    0.307250          0.877260            Inh VIP CLSTN2   \n",
       "...            ...         ...               ...                       ...   \n",
       "424425    2.062520    0.225588          0.891670             Inh VIP TSHZ2   \n",
       "424426    0.153213    0.358956          0.858250           Inh PVALB SULF1   \n",
       "424427    2.098986    0.679785          0.884093             Inh CUX2 MSR1   \n",
       "424428    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "424430    3.291454    0.261746          0.869104            Inh PVALB HTR4   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD individualID  \\\n",
       "0       ROSMAP-65967                        yes     R3857147   \n",
       "1       ROSMAP-90639                        yes     R7090624   \n",
       "2       ROSMAP-57958                        yes     R2347173   \n",
       "3       ROSMAP-40761                        yes     R1287407   \n",
       "4       ROSMAP-68841                        yes     R3757880   \n",
       "...              ...                        ...          ...   \n",
       "424425  ROSMAP-77886                         no     R2554598   \n",
       "424426  ROSMAP-38931                         no     R6292415   \n",
       "424427  ROSMAP-53472                        yes     R3863249   \n",
       "424428  ROSMAP-44788                         no     R5221394   \n",
       "424430  ROSMAP-22203                        yes     R7583108   \n",
       "\n",
       "       clinical_diagnosis pathological_diagnosis clinical_pathological_AD  \\\n",
       "0                      AD                     AD          AD_with_Plaques   \n",
       "1                     NCI                     AD                    False   \n",
       "2                     NCI                     AD                    False   \n",
       "3                   False                     AD                    False   \n",
       "4                     NCI                     AD                    False   \n",
       "...                   ...                    ...                      ...   \n",
       "424425                NCI                  False                    False   \n",
       "424426                NCI                  No AD      NCI_with_No_Plaques   \n",
       "424427              False                  False                    False   \n",
       "424428                NCI                  No AD      NCI_with_No_Plaques   \n",
       "424430                 AD                     AD          AD_with_Plaques   \n",
       "\n",
       "       train_test_clinical_and_pathological  \n",
       "0                                     train  \n",
       "1                                       NaN  \n",
       "2                                       NaN  \n",
       "3                                       NaN  \n",
       "4                                       NaN  \n",
       "...                                     ...  \n",
       "424425                                  NaN  \n",
       "424426                                train  \n",
       "424427                                  NaN  \n",
       "424428                                 test  \n",
       "424430                                train  \n",
       "\n",
       "[329699 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93f3357c-e0b1-4d27-ba16-1a906f1ad59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_metadata.to_csv('../../preprocessed_data/inhibitory_neuron/metadata_inhibitory_neurons.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef0ccb8b-aba3-46d7-9125-bddb36eca59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'LRIG2' in data.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50bcfcaa-813f-4090-b786-7922b75c73e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0        1\n",
      "0  ENSG00000210049    MT-TF\n",
      "1  ENSG00000211459  MT-RNR1\n",
      "2  ENSG00000210077    MT-TV\n",
      "3  ENSG00000210082  MT-RNR2\n",
      "4  ENSG00000209082   MT-TL1\n"
     ]
    }
   ],
   "source": [
    "from biomart import BiomartServer\n",
    "\n",
    "# Connect to the Ensembl Biomart server\n",
    "server = BiomartServer(\"http://www.ensembl.org/biomart\")\n",
    "\n",
    "# Access the Ensembl Genes dataset for Homo sapiens\n",
    "dataset = server.datasets['hsapiens_gene_ensembl']\n",
    "\n",
    "# Query the dataset for Ensembl IDs and gene names\n",
    "response = dataset.search({\n",
    "    'attributes': [\n",
    "        'ensembl_gene_id', \n",
    "        'external_gene_name'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Convert the response to a dataframe\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data_ensemble_gene = StringIO(response.text)\n",
    "\n",
    "df = pd.read_csv(data_ensemble_gene , sep=\"\\t\",header = None)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "# Nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a1aa0e0-2320-4e8c-8980-d17a92c5c796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70591</th>\n",
       "      <td>ENSG00000198799</td>\n",
       "      <td>LRIG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70592</th>\n",
       "      <td>ENSG00000237278</td>\n",
       "      <td>RLIMP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70593</th>\n",
       "      <td>ENSG00000233839</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70594</th>\n",
       "      <td>ENSG00000236887</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70595</th>\n",
       "      <td>ENSG00000238765</td>\n",
       "      <td>RNA5SP57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70596</th>\n",
       "      <td>ENSG00000224335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70597</th>\n",
       "      <td>ENSG00000227700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70598</th>\n",
       "      <td>ENSG00000199879</td>\n",
       "      <td>RNVU1-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70599</th>\n",
       "      <td>ENSG00000274020</td>\n",
       "      <td>LINC01138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70600</th>\n",
       "      <td>ENSG00000226716</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70601</th>\n",
       "      <td>ENSG00000293250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70602</th>\n",
       "      <td>ENSG00000236427</td>\n",
       "      <td>CCDST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70603</th>\n",
       "      <td>ENSG00000143631</td>\n",
       "      <td>FLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70604</th>\n",
       "      <td>ENSG00000143520</td>\n",
       "      <td>FLG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70605</th>\n",
       "      <td>ENSG00000143507</td>\n",
       "      <td>DUSP10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70606</th>\n",
       "      <td>ENSG00000232679</td>\n",
       "      <td>LINC01705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70607</th>\n",
       "      <td>ENSG00000200033</td>\n",
       "      <td>RNU6-403P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70608</th>\n",
       "      <td>ENSG00000228437</td>\n",
       "      <td>LINC02474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70609</th>\n",
       "      <td>ENSG00000229463</td>\n",
       "      <td>LYST-AS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70610</th>\n",
       "      <td>ENSG00000229291</td>\n",
       "      <td>LINC02768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0          1\n",
       "70591  ENSG00000198799      LRIG2\n",
       "70592  ENSG00000237278     RLIMP2\n",
       "70593  ENSG00000233839        NaN\n",
       "70594  ENSG00000236887        NaN\n",
       "70595  ENSG00000238765   RNA5SP57\n",
       "70596  ENSG00000224335        NaN\n",
       "70597  ENSG00000227700        NaN\n",
       "70598  ENSG00000199879   RNVU1-22\n",
       "70599  ENSG00000274020  LINC01138\n",
       "70600  ENSG00000226716        NaN\n",
       "70601  ENSG00000293250        NaN\n",
       "70602  ENSG00000236427      CCDST\n",
       "70603  ENSG00000143631        FLG\n",
       "70604  ENSG00000143520       FLG2\n",
       "70605  ENSG00000143507     DUSP10\n",
       "70606  ENSG00000232679  LINC01705\n",
       "70607  ENSG00000200033  RNU6-403P\n",
       "70608  ENSG00000228437  LINC02474\n",
       "70609  ENSG00000229463   LYST-AS1\n",
       "70610  ENSG00000229291  LINC02768"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ebf04e6b-aa1f-46f9-a183-d5ff36ef2b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>GCCGTGACACCGTGCA.11.9</th>\n",
       "      <th>ATGGGAGAGGCCCGTT.7.13</th>\n",
       "      <th>CACCGTTAGCTAGCCC.38.2</th>\n",
       "      <th>ACTTATCTCGAACGCC.8.10</th>\n",
       "      <th>ACTTCGCGTACTAACC.13.6</th>\n",
       "      <th>TGACAACAGGTACTCT.44.1</th>\n",
       "      <th>GGGACAATCTCTCCGA.21.11</th>\n",
       "      <th>TCGGGCAAGCGATGCA.20.2</th>\n",
       "      <th>ACTTCCGAGGTACATA.11.11</th>\n",
       "      <th>...</th>\n",
       "      <th>GCTACAAGTCAAGCCC.1.6</th>\n",
       "      <th>CCACTTGAGAGGTATT.24.8</th>\n",
       "      <th>ATTACCTAGAGCCGTA.7.13</th>\n",
       "      <th>TTTGGAGAGCATATGA.7.6</th>\n",
       "      <th>TTCTAACTCCGTAATG.22.9</th>\n",
       "      <th>TCCATCGCATCTGTTT.14.14</th>\n",
       "      <th>GTCAAGTAGTGGCCTC.21.2</th>\n",
       "      <th>CAGCCAGTCCGTAGGC.10.13</th>\n",
       "      <th>GGAAGTGGTATCCTCC.9.9</th>\n",
       "      <th>TTGCCTGGTGTATCCA.30.11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KRTCAP2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL713999.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRIM46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUC1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AC234582.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33533</th>\n",
       "      <td>AC233755.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33534</th>\n",
       "      <td>AC233755.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33535</th>\n",
       "      <td>AC240274.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33536</th>\n",
       "      <td>AC213203.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33537</th>\n",
       "      <td>FAM231C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33538 rows × 164850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  GCCGTGACACCGTGCA.11.9  ATGGGAGAGGCCCGTT.7.13  \\\n",
       "0         KRTCAP2                      0                      0   \n",
       "1      AL713999.1                      0                      0   \n",
       "2          TRIM46                      0                      0   \n",
       "3            MUC1                      0                      0   \n",
       "4      AC234582.1                      0                      0   \n",
       "...           ...                    ...                    ...   \n",
       "33533  AC233755.2                      0                      0   \n",
       "33534  AC233755.1                      0                      0   \n",
       "33535  AC240274.1                      0                      0   \n",
       "33536  AC213203.1                      0                      0   \n",
       "33537     FAM231C                      0                      0   \n",
       "\n",
       "       CACCGTTAGCTAGCCC.38.2  ACTTATCTCGAACGCC.8.10  ACTTCGCGTACTAACC.13.6  \\\n",
       "0                          0                      0                      0   \n",
       "1                          0                      0                      0   \n",
       "2                          0                      0                      0   \n",
       "3                          0                      0                      0   \n",
       "4                          0                      0                      0   \n",
       "...                      ...                    ...                    ...   \n",
       "33533                      0                      0                      0   \n",
       "33534                      0                      0                      0   \n",
       "33535                      0                      0                      0   \n",
       "33536                      0                      0                      0   \n",
       "33537                      0                      0                      0   \n",
       "\n",
       "       TGACAACAGGTACTCT.44.1  GGGACAATCTCTCCGA.21.11  TCGGGCAAGCGATGCA.20.2  \\\n",
       "0                          0                       0                      0   \n",
       "1                          0                       0                      0   \n",
       "2                          0                       0                      0   \n",
       "3                          0                       0                      0   \n",
       "4                          0                       0                      0   \n",
       "...                      ...                     ...                    ...   \n",
       "33533                      0                       0                      0   \n",
       "33534                      0                       0                      0   \n",
       "33535                      0                       0                      0   \n",
       "33536                      0                       0                      0   \n",
       "33537                      0                       0                      0   \n",
       "\n",
       "       ACTTCCGAGGTACATA.11.11  ...  GCTACAAGTCAAGCCC.1.6  \\\n",
       "0                           0  ...                     0   \n",
       "1                           0  ...                     0   \n",
       "2                           0  ...                     0   \n",
       "3                           0  ...                     0   \n",
       "4                           0  ...                     0   \n",
       "...                       ...  ...                   ...   \n",
       "33533                       0  ...                     0   \n",
       "33534                       0  ...                     0   \n",
       "33535                       0  ...                     0   \n",
       "33536                       0  ...                     0   \n",
       "33537                       0  ...                     0   \n",
       "\n",
       "       CCACTTGAGAGGTATT.24.8  ATTACCTAGAGCCGTA.7.13  TTTGGAGAGCATATGA.7.6  \\\n",
       "0                          0                      0                     0   \n",
       "1                          0                      0                     0   \n",
       "2                          1                      0                     0   \n",
       "3                          0                      0                     0   \n",
       "4                          0                      0                     0   \n",
       "...                      ...                    ...                   ...   \n",
       "33533                      0                      0                     0   \n",
       "33534                      0                      0                     0   \n",
       "33535                      0                      0                     1   \n",
       "33536                      0                      0                     0   \n",
       "33537                      0                      0                     0   \n",
       "\n",
       "       TTCTAACTCCGTAATG.22.9  TCCATCGCATCTGTTT.14.14  GTCAAGTAGTGGCCTC.21.2  \\\n",
       "0                          0                       0                      0   \n",
       "1                          0                       0                      0   \n",
       "2                          0                       0                      0   \n",
       "3                          0                       0                      0   \n",
       "4                          0                       0                      0   \n",
       "...                      ...                     ...                    ...   \n",
       "33533                      0                       0                      0   \n",
       "33534                      0                       0                      0   \n",
       "33535                      0                       1                      0   \n",
       "33536                      0                       0                      0   \n",
       "33537                      0                       0                      0   \n",
       "\n",
       "       CAGCCAGTCCGTAGGC.10.13  GGAAGTGGTATCCTCC.9.9  TTGCCTGGTGTATCCA.30.11  \n",
       "0                           0                     0                       0  \n",
       "1                           0                     0                       0  \n",
       "2                           1                     0                       0  \n",
       "3                           0                     0                       0  \n",
       "4                           0                     0                       0  \n",
       "...                       ...                   ...                     ...  \n",
       "33533                       0                     0                       0  \n",
       "33534                       0                     0                       0  \n",
       "33535                       0                     0                       0  \n",
       "33536                       0                     0                       0  \n",
       "33537                       0                     0                       0  \n",
       "\n",
       "[33538 rows x 164850 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9d33e76-889c-42b5-94a1-33ef7c0968ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data.index.tolist()).intersection(set(df[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eeafa4b5-59c4-4384-b48a-225bf2c84113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GCCGTGACACCGTGCA.11.9</th>\n",
       "      <th>ATGGGAGAGGCCCGTT.7.13</th>\n",
       "      <th>CACCGTTAGCTAGCCC.38.2</th>\n",
       "      <th>ACTTATCTCGAACGCC.8.10</th>\n",
       "      <th>ACTTCGCGTACTAACC.13.6</th>\n",
       "      <th>TGACAACAGGTACTCT.44.1</th>\n",
       "      <th>GGGACAATCTCTCCGA.21.11</th>\n",
       "      <th>TCGGGCAAGCGATGCA.20.2</th>\n",
       "      <th>ACTTCCGAGGTACATA.11.11</th>\n",
       "      <th>TCAGTTTCATGGTACT.15.4</th>\n",
       "      <th>...</th>\n",
       "      <th>GCTACAAGTCAAGCCC.1.6</th>\n",
       "      <th>CCACTTGAGAGGTATT.24.8</th>\n",
       "      <th>ATTACCTAGAGCCGTA.7.13</th>\n",
       "      <th>TTTGGAGAGCATATGA.7.6</th>\n",
       "      <th>TTCTAACTCCGTAATG.22.9</th>\n",
       "      <th>TCCATCGCATCTGTTT.14.14</th>\n",
       "      <th>GTCAAGTAGTGGCCTC.21.2</th>\n",
       "      <th>CAGCCAGTCCGTAGGC.10.13</th>\n",
       "      <th>GGAAGTGGTATCCTCC.9.9</th>\n",
       "      <th>TTGCCTGGTGTATCCA.30.11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KRTCAP2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL713999.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRIM46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUC1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC234582.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC233755.2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC233755.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC240274.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC213203.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAM231C</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33538 rows × 164849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GCCGTGACACCGTGCA.11.9  ATGGGAGAGGCCCGTT.7.13  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            CACCGTTAGCTAGCCC.38.2  ACTTATCTCGAACGCC.8.10  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            ACTTCGCGTACTAACC.13.6  TGACAACAGGTACTCT.44.1  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            GGGACAATCTCTCCGA.21.11  TCGGGCAAGCGATGCA.20.2  \\\n",
       "KRTCAP2                          0                      0   \n",
       "AL713999.1                       0                      0   \n",
       "TRIM46                           0                      0   \n",
       "MUC1                             0                      0   \n",
       "AC234582.1                       0                      0   \n",
       "...                            ...                    ...   \n",
       "AC233755.2                       0                      0   \n",
       "AC233755.1                       0                      0   \n",
       "AC240274.1                       0                      0   \n",
       "AC213203.1                       0                      0   \n",
       "FAM231C                          0                      0   \n",
       "\n",
       "            ACTTCCGAGGTACATA.11.11  TCAGTTTCATGGTACT.15.4  ...  \\\n",
       "KRTCAP2                          0                      0  ...   \n",
       "AL713999.1                       0                      0  ...   \n",
       "TRIM46                           0                      0  ...   \n",
       "MUC1                             0                      0  ...   \n",
       "AC234582.1                       0                      1  ...   \n",
       "...                            ...                    ...  ...   \n",
       "AC233755.2                       0                      0  ...   \n",
       "AC233755.1                       0                      0  ...   \n",
       "AC240274.1                       0                      0  ...   \n",
       "AC213203.1                       0                      0  ...   \n",
       "FAM231C                          0                      0  ...   \n",
       "\n",
       "            GCTACAAGTCAAGCCC.1.6  CCACTTGAGAGGTATT.24.8  \\\n",
       "KRTCAP2                        0                      0   \n",
       "AL713999.1                     0                      0   \n",
       "TRIM46                         0                      1   \n",
       "MUC1                           0                      0   \n",
       "AC234582.1                     0                      0   \n",
       "...                          ...                    ...   \n",
       "AC233755.2                     0                      0   \n",
       "AC233755.1                     0                      0   \n",
       "AC240274.1                     0                      0   \n",
       "AC213203.1                     0                      0   \n",
       "FAM231C                        0                      0   \n",
       "\n",
       "            ATTACCTAGAGCCGTA.7.13  TTTGGAGAGCATATGA.7.6  \\\n",
       "KRTCAP2                         0                     0   \n",
       "AL713999.1                      0                     0   \n",
       "TRIM46                          0                     0   \n",
       "MUC1                            0                     0   \n",
       "AC234582.1                      0                     0   \n",
       "...                           ...                   ...   \n",
       "AC233755.2                      0                     0   \n",
       "AC233755.1                      0                     0   \n",
       "AC240274.1                      0                     1   \n",
       "AC213203.1                      0                     0   \n",
       "FAM231C                         0                     0   \n",
       "\n",
       "            TTCTAACTCCGTAATG.22.9  TCCATCGCATCTGTTT.14.14  \\\n",
       "KRTCAP2                         0                       0   \n",
       "AL713999.1                      0                       0   \n",
       "TRIM46                          0                       0   \n",
       "MUC1                            0                       0   \n",
       "AC234582.1                      0                       0   \n",
       "...                           ...                     ...   \n",
       "AC233755.2                      0                       0   \n",
       "AC233755.1                      0                       0   \n",
       "AC240274.1                      0                       1   \n",
       "AC213203.1                      0                       0   \n",
       "FAM231C                         0                       0   \n",
       "\n",
       "            GTCAAGTAGTGGCCTC.21.2  CAGCCAGTCCGTAGGC.10.13  \\\n",
       "KRTCAP2                         0                       0   \n",
       "AL713999.1                      0                       0   \n",
       "TRIM46                          0                       1   \n",
       "MUC1                            0                       0   \n",
       "AC234582.1                      0                       0   \n",
       "...                           ...                     ...   \n",
       "AC233755.2                      0                       0   \n",
       "AC233755.1                      0                       0   \n",
       "AC240274.1                      0                       0   \n",
       "AC213203.1                      0                       0   \n",
       "FAM231C                         0                       0   \n",
       "\n",
       "            GGAAGTGGTATCCTCC.9.9  TTGCCTGGTGTATCCA.30.11  \n",
       "KRTCAP2                        0                       0  \n",
       "AL713999.1                     0                       0  \n",
       "TRIM46                         0                       0  \n",
       "MUC1                           0                       0  \n",
       "AC234582.1                     0                       0  \n",
       "...                          ...                     ...  \n",
       "AC233755.2                     0                       0  \n",
       "AC233755.1                     0                       0  \n",
       "AC240274.1                     0                       0  \n",
       "AC213203.1                     0                       0  \n",
       "FAM231C                        0                       0  \n",
       "\n",
       "[33538 rows x 164849 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c6396b9-2d6e-43c6-a11b-e8a21dfe28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def return_ensemble_id(x):\n",
    "    try:\n",
    "        return df[df[1]==x][0].values[0]\n",
    "    except: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "755eb6f2-6cff-44e7-8886-5fae7a44a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.reset_index()['index'].apply(return_ensemble_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9b3bc31-ae02-42d0-8484-7aa90d45792e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "ENSG00000274847    1\n",
       "ENSG00000163463    1\n",
       "ENSG00000163462    1\n",
       "ENSG00000185499    1\n",
       "ENSG00000275874    1\n",
       "                  ..\n",
       "ENSG00000263324    1\n",
       "ENSG00000262785    1\n",
       "ENSG00000160752    1\n",
       "ENSG00000225855    1\n",
       "ENSG00000160753    1\n",
       "Name: count, Length: 22500, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c265ebb0-253a-4696-8e5e-7fb7b74e568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ENSG00000163463\n",
       "1                    NaN\n",
       "2        ENSG00000163462\n",
       "3        ENSG00000185499\n",
       "4                    NaN\n",
       "              ...       \n",
       "33533                NaN\n",
       "33534                NaN\n",
       "33535                NaN\n",
       "33536                NaN\n",
       "33537                NaN\n",
       "Name: index, Length: 33538, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd79a473-2318-4844-be69-5bfa9b68bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ensemble_gene_name'] = x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1372f2f7-a463-407a-aa40-1ffe1e97642f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GCCGTGACACCGTGCA.11.9</th>\n",
       "      <th>ATGGGAGAGGCCCGTT.7.13</th>\n",
       "      <th>CACCGTTAGCTAGCCC.38.2</th>\n",
       "      <th>ACTTATCTCGAACGCC.8.10</th>\n",
       "      <th>ACTTCGCGTACTAACC.13.6</th>\n",
       "      <th>TGACAACAGGTACTCT.44.1</th>\n",
       "      <th>GGGACAATCTCTCCGA.21.11</th>\n",
       "      <th>TCGGGCAAGCGATGCA.20.2</th>\n",
       "      <th>ACTTCCGAGGTACATA.11.11</th>\n",
       "      <th>TCAGTTTCATGGTACT.15.4</th>\n",
       "      <th>...</th>\n",
       "      <th>CCACTTGAGAGGTATT.24.8</th>\n",
       "      <th>ATTACCTAGAGCCGTA.7.13</th>\n",
       "      <th>TTTGGAGAGCATATGA.7.6</th>\n",
       "      <th>TTCTAACTCCGTAATG.22.9</th>\n",
       "      <th>TCCATCGCATCTGTTT.14.14</th>\n",
       "      <th>GTCAAGTAGTGGCCTC.21.2</th>\n",
       "      <th>CAGCCAGTCCGTAGGC.10.13</th>\n",
       "      <th>GGAAGTGGTATCCTCC.9.9</th>\n",
       "      <th>TTGCCTGGTGTATCCA.30.11</th>\n",
       "      <th>ensemble_gene_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KRTCAP2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000163463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL713999.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRIM46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000163462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUC1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000185499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC234582.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC233755.2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC233755.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC240274.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC213203.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAM231C</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33538 rows × 164850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GCCGTGACACCGTGCA.11.9  ATGGGAGAGGCCCGTT.7.13  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            CACCGTTAGCTAGCCC.38.2  ACTTATCTCGAACGCC.8.10  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            ACTTCGCGTACTAACC.13.6  TGACAACAGGTACTCT.44.1  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          0                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            GGGACAATCTCTCCGA.21.11  TCGGGCAAGCGATGCA.20.2  \\\n",
       "KRTCAP2                          0                      0   \n",
       "AL713999.1                       0                      0   \n",
       "TRIM46                           0                      0   \n",
       "MUC1                             0                      0   \n",
       "AC234582.1                       0                      0   \n",
       "...                            ...                    ...   \n",
       "AC233755.2                       0                      0   \n",
       "AC233755.1                       0                      0   \n",
       "AC240274.1                       0                      0   \n",
       "AC213203.1                       0                      0   \n",
       "FAM231C                          0                      0   \n",
       "\n",
       "            ACTTCCGAGGTACATA.11.11  TCAGTTTCATGGTACT.15.4  ...  \\\n",
       "KRTCAP2                          0                      0  ...   \n",
       "AL713999.1                       0                      0  ...   \n",
       "TRIM46                           0                      0  ...   \n",
       "MUC1                             0                      0  ...   \n",
       "AC234582.1                       0                      1  ...   \n",
       "...                            ...                    ...  ...   \n",
       "AC233755.2                       0                      0  ...   \n",
       "AC233755.1                       0                      0  ...   \n",
       "AC240274.1                       0                      0  ...   \n",
       "AC213203.1                       0                      0  ...   \n",
       "FAM231C                          0                      0  ...   \n",
       "\n",
       "            CCACTTGAGAGGTATT.24.8  ATTACCTAGAGCCGTA.7.13  \\\n",
       "KRTCAP2                         0                      0   \n",
       "AL713999.1                      0                      0   \n",
       "TRIM46                          1                      0   \n",
       "MUC1                            0                      0   \n",
       "AC234582.1                      0                      0   \n",
       "...                           ...                    ...   \n",
       "AC233755.2                      0                      0   \n",
       "AC233755.1                      0                      0   \n",
       "AC240274.1                      0                      0   \n",
       "AC213203.1                      0                      0   \n",
       "FAM231C                         0                      0   \n",
       "\n",
       "            TTTGGAGAGCATATGA.7.6  TTCTAACTCCGTAATG.22.9  \\\n",
       "KRTCAP2                        0                      0   \n",
       "AL713999.1                     0                      0   \n",
       "TRIM46                         0                      0   \n",
       "MUC1                           0                      0   \n",
       "AC234582.1                     0                      0   \n",
       "...                          ...                    ...   \n",
       "AC233755.2                     0                      0   \n",
       "AC233755.1                     0                      0   \n",
       "AC240274.1                     1                      0   \n",
       "AC213203.1                     0                      0   \n",
       "FAM231C                        0                      0   \n",
       "\n",
       "            TCCATCGCATCTGTTT.14.14  GTCAAGTAGTGGCCTC.21.2  \\\n",
       "KRTCAP2                          0                      0   \n",
       "AL713999.1                       0                      0   \n",
       "TRIM46                           0                      0   \n",
       "MUC1                             0                      0   \n",
       "AC234582.1                       0                      0   \n",
       "...                            ...                    ...   \n",
       "AC233755.2                       0                      0   \n",
       "AC233755.1                       0                      0   \n",
       "AC240274.1                       1                      0   \n",
       "AC213203.1                       0                      0   \n",
       "FAM231C                          0                      0   \n",
       "\n",
       "            CAGCCAGTCCGTAGGC.10.13  GGAAGTGGTATCCTCC.9.9  \\\n",
       "KRTCAP2                          0                     0   \n",
       "AL713999.1                       0                     0   \n",
       "TRIM46                           1                     0   \n",
       "MUC1                             0                     0   \n",
       "AC234582.1                       0                     0   \n",
       "...                            ...                   ...   \n",
       "AC233755.2                       0                     0   \n",
       "AC233755.1                       0                     0   \n",
       "AC240274.1                       0                     0   \n",
       "AC213203.1                       0                     0   \n",
       "FAM231C                          0                     0   \n",
       "\n",
       "            TTGCCTGGTGTATCCA.30.11  ensemble_gene_name  \n",
       "KRTCAP2                          0     ENSG00000163463  \n",
       "AL713999.1                       0                 NaN  \n",
       "TRIM46                           0     ENSG00000163462  \n",
       "MUC1                             0     ENSG00000185499  \n",
       "AC234582.1                       0                 NaN  \n",
       "...                            ...                 ...  \n",
       "AC233755.2                       0                 NaN  \n",
       "AC233755.1                       0                 NaN  \n",
       "AC240274.1                       0                 NaN  \n",
       "AC213203.1                       0                 NaN  \n",
       "FAM231C                          0                 NaN  \n",
       "\n",
       "[33538 rows x 164850 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9612b8-d888-4012-95dc-899dceda8d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ebe36a96-ad1a-4540-b94f-13258c82a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GCCGTGACACCGTGCA.11.9</th>\n",
       "      <th>ATGGGAGAGGCCCGTT.7.13</th>\n",
       "      <th>CACCGTTAGCTAGCCC.38.2</th>\n",
       "      <th>ACTTATCTCGAACGCC.8.10</th>\n",
       "      <th>ACTTCGCGTACTAACC.13.6</th>\n",
       "      <th>TGACAACAGGTACTCT.44.1</th>\n",
       "      <th>GGGACAATCTCTCCGA.21.11</th>\n",
       "      <th>TCGGGCAAGCGATGCA.20.2</th>\n",
       "      <th>ACTTCCGAGGTACATA.11.11</th>\n",
       "      <th>TCAGTTTCATGGTACT.15.4</th>\n",
       "      <th>...</th>\n",
       "      <th>CCACTTGAGAGGTATT.24.8</th>\n",
       "      <th>ATTACCTAGAGCCGTA.7.13</th>\n",
       "      <th>TTTGGAGAGCATATGA.7.6</th>\n",
       "      <th>TTCTAACTCCGTAATG.22.9</th>\n",
       "      <th>TCCATCGCATCTGTTT.14.14</th>\n",
       "      <th>GTCAAGTAGTGGCCTC.21.2</th>\n",
       "      <th>CAGCCAGTCCGTAGGC.10.13</th>\n",
       "      <th>GGAAGTGGTATCCTCC.9.9</th>\n",
       "      <th>TTGCCTGGTGTATCCA.30.11</th>\n",
       "      <th>ensemble_gene_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KRTCAP2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000163463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRIM46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000163462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUC1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000185499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THBS3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000169231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTX1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT-ND4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>86</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>ENSG00000198886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT-ND5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000198786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT-ND6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000198695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT-CYB</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>78</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>ENSG00000198727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAFIP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000274847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22500 rows × 164850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GCCGTGACACCGTGCA.11.9  ATGGGAGAGGCCCGTT.7.13  CACCGTTAGCTAGCCC.38.2  \\\n",
       "KRTCAP2                      0                      0                      0   \n",
       "TRIM46                       0                      0                      0   \n",
       "MUC1                         0                      0                      0   \n",
       "THBS3                        0                      0                      0   \n",
       "MTX1                         0                      0                      0   \n",
       "...                        ...                    ...                    ...   \n",
       "MT-ND4                       6                      5                     11   \n",
       "MT-ND5                       2                      2                      0   \n",
       "MT-ND6                       0                      0                      0   \n",
       "MT-CYB                       8                      6                     25   \n",
       "MAFIP                        0                      0                      0   \n",
       "\n",
       "         ACTTATCTCGAACGCC.8.10  ACTTCGCGTACTAACC.13.6  TGACAACAGGTACTCT.44.1  \\\n",
       "KRTCAP2                      0                      0                      0   \n",
       "TRIM46                       0                      0                      0   \n",
       "MUC1                         0                      0                      0   \n",
       "THBS3                        0                      0                      2   \n",
       "MTX1                         0                      0                      0   \n",
       "...                        ...                    ...                    ...   \n",
       "MT-ND4                      86                     43                     23   \n",
       "MT-ND5                      26                      1                      4   \n",
       "MT-ND6                       1                      0                      0   \n",
       "MT-CYB                      78                     15                     25   \n",
       "MAFIP                        0                      0                      0   \n",
       "\n",
       "         GGGACAATCTCTCCGA.21.11  TCGGGCAAGCGATGCA.20.2  \\\n",
       "KRTCAP2                       0                      0   \n",
       "TRIM46                        0                      0   \n",
       "MUC1                          0                      0   \n",
       "THBS3                         0                      0   \n",
       "MTX1                          0                      0   \n",
       "...                         ...                    ...   \n",
       "MT-ND4                        9                      7   \n",
       "MT-ND5                        1                      0   \n",
       "MT-ND6                        0                      0   \n",
       "MT-CYB                       10                      3   \n",
       "MAFIP                         0                      0   \n",
       "\n",
       "         ACTTCCGAGGTACATA.11.11  TCAGTTTCATGGTACT.15.4  ...  \\\n",
       "KRTCAP2                       0                      0  ...   \n",
       "TRIM46                        0                      0  ...   \n",
       "MUC1                          0                      0  ...   \n",
       "THBS3                         0                      0  ...   \n",
       "MTX1                          0                      0  ...   \n",
       "...                         ...                    ...  ...   \n",
       "MT-ND4                       24                     12  ...   \n",
       "MT-ND5                        5                      6  ...   \n",
       "MT-ND6                        0                      1  ...   \n",
       "MT-CYB                       19                     37  ...   \n",
       "MAFIP                         0                      0  ...   \n",
       "\n",
       "         CCACTTGAGAGGTATT.24.8  ATTACCTAGAGCCGTA.7.13  TTTGGAGAGCATATGA.7.6  \\\n",
       "KRTCAP2                      0                      0                     0   \n",
       "TRIM46                       1                      0                     0   \n",
       "MUC1                         0                      0                     0   \n",
       "THBS3                        0                      0                     0   \n",
       "MTX1                         1                      0                     0   \n",
       "...                        ...                    ...                   ...   \n",
       "MT-ND4                      60                     20                    40   \n",
       "MT-ND5                      11                      3                     3   \n",
       "MT-ND6                       0                      0                     1   \n",
       "MT-CYB                      57                     14                    20   \n",
       "MAFIP                        0                      0                     0   \n",
       "\n",
       "         TTCTAACTCCGTAATG.22.9  TCCATCGCATCTGTTT.14.14  GTCAAGTAGTGGCCTC.21.2  \\\n",
       "KRTCAP2                      0                       0                      0   \n",
       "TRIM46                       0                       0                      0   \n",
       "MUC1                         0                       0                      0   \n",
       "THBS3                        0                       0                      0   \n",
       "MTX1                         0                       0                      0   \n",
       "...                        ...                     ...                    ...   \n",
       "MT-ND4                      16                      24                      5   \n",
       "MT-ND5                       3                       5                      1   \n",
       "MT-ND6                       0                       0                      0   \n",
       "MT-CYB                      23                      18                      6   \n",
       "MAFIP                        0                       0                      0   \n",
       "\n",
       "         CAGCCAGTCCGTAGGC.10.13  GGAAGTGGTATCCTCC.9.9  TTGCCTGGTGTATCCA.30.11  \\\n",
       "KRTCAP2                       0                     0                       0   \n",
       "TRIM46                        1                     0                       0   \n",
       "MUC1                          0                     0                       0   \n",
       "THBS3                         0                     0                       0   \n",
       "MTX1                          0                     0                       0   \n",
       "...                         ...                   ...                     ...   \n",
       "MT-ND4                       25                     0                       7   \n",
       "MT-ND5                        9                     2                       2   \n",
       "MT-ND6                        0                     0                       0   \n",
       "MT-CYB                       27                     2                       5   \n",
       "MAFIP                         0                     0                       0   \n",
       "\n",
       "         ensemble_gene_name  \n",
       "KRTCAP2     ENSG00000163463  \n",
       "TRIM46      ENSG00000163462  \n",
       "MUC1        ENSG00000185499  \n",
       "THBS3       ENSG00000169231  \n",
       "MTX1        ENSG00000261905  \n",
       "...                     ...  \n",
       "MT-ND4      ENSG00000198886  \n",
       "MT-ND5      ENSG00000198786  \n",
       "MT-ND6      ENSG00000198695  \n",
       "MT-CYB      ENSG00000198727  \n",
       "MAFIP       ENSG00000274847  \n",
       "\n",
       "[22500 rows x 164850 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af476e13-f267-4d29-a68c-d25071cb1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('ensemble_gene_name', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "faf747c9-8321-4d97-8774-287466802523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GCCGTGACACCGTGCA.11.9</th>\n",
       "      <th>ATGGGAGAGGCCCGTT.7.13</th>\n",
       "      <th>CACCGTTAGCTAGCCC.38.2</th>\n",
       "      <th>ACTTATCTCGAACGCC.8.10</th>\n",
       "      <th>ACTTCGCGTACTAACC.13.6</th>\n",
       "      <th>TGACAACAGGTACTCT.44.1</th>\n",
       "      <th>GGGACAATCTCTCCGA.21.11</th>\n",
       "      <th>TCGGGCAAGCGATGCA.20.2</th>\n",
       "      <th>ACTTCCGAGGTACATA.11.11</th>\n",
       "      <th>TCAGTTTCATGGTACT.15.4</th>\n",
       "      <th>...</th>\n",
       "      <th>GCTACAAGTCAAGCCC.1.6</th>\n",
       "      <th>CCACTTGAGAGGTATT.24.8</th>\n",
       "      <th>ATTACCTAGAGCCGTA.7.13</th>\n",
       "      <th>TTTGGAGAGCATATGA.7.6</th>\n",
       "      <th>TTCTAACTCCGTAATG.22.9</th>\n",
       "      <th>TCCATCGCATCTGTTT.14.14</th>\n",
       "      <th>GTCAAGTAGTGGCCTC.21.2</th>\n",
       "      <th>CAGCCAGTCCGTAGGC.10.13</th>\n",
       "      <th>GGAAGTGGTATCCTCC.9.9</th>\n",
       "      <th>TTGCCTGGTGTATCCA.30.11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_gene_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000163463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000163462</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000185499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000169231</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000261905</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198886</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>86</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198786</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198727</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>78</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000274847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22500 rows × 164849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GCCGTGACACCGTGCA.11.9  ATGGGAGAGGCCCGTT.7.13  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                         6                      5   \n",
       "ENSG00000198786                         2                      2   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                         8                      6   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    CACCGTTAGCTAGCCC.38.2  ACTTATCTCGAACGCC.8.10  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                        11                     86   \n",
       "ENSG00000198786                         0                     26   \n",
       "ENSG00000198695                         0                      1   \n",
       "ENSG00000198727                        25                     78   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    ACTTCGCGTACTAACC.13.6  TGACAACAGGTACTCT.44.1  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      2   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                        43                     23   \n",
       "ENSG00000198786                         1                      4   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                        15                     25   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    GGGACAATCTCTCCGA.21.11  TCGGGCAAGCGATGCA.20.2  \\\n",
       "ensemble_gene_name                                                  \n",
       "ENSG00000163463                          0                      0   \n",
       "ENSG00000163462                          0                      0   \n",
       "ENSG00000185499                          0                      0   \n",
       "ENSG00000169231                          0                      0   \n",
       "ENSG00000261905                          0                      0   \n",
       "...                                    ...                    ...   \n",
       "ENSG00000198886                          9                      7   \n",
       "ENSG00000198786                          1                      0   \n",
       "ENSG00000198695                          0                      0   \n",
       "ENSG00000198727                         10                      3   \n",
       "ENSG00000274847                          0                      0   \n",
       "\n",
       "                    ACTTCCGAGGTACATA.11.11  TCAGTTTCATGGTACT.15.4  ...  \\\n",
       "ensemble_gene_name                                                 ...   \n",
       "ENSG00000163463                          0                      0  ...   \n",
       "ENSG00000163462                          0                      0  ...   \n",
       "ENSG00000185499                          0                      0  ...   \n",
       "ENSG00000169231                          0                      0  ...   \n",
       "ENSG00000261905                          0                      0  ...   \n",
       "...                                    ...                    ...  ...   \n",
       "ENSG00000198886                         24                     12  ...   \n",
       "ENSG00000198786                          5                      6  ...   \n",
       "ENSG00000198695                          0                      1  ...   \n",
       "ENSG00000198727                         19                     37  ...   \n",
       "ENSG00000274847                          0                      0  ...   \n",
       "\n",
       "                    GCTACAAGTCAAGCCC.1.6  CCACTTGAGAGGTATT.24.8  \\\n",
       "ensemble_gene_name                                                \n",
       "ENSG00000163463                        0                      0   \n",
       "ENSG00000163462                        0                      1   \n",
       "ENSG00000185499                        0                      0   \n",
       "ENSG00000169231                        0                      0   \n",
       "ENSG00000261905                        0                      1   \n",
       "...                                  ...                    ...   \n",
       "ENSG00000198886                       26                     60   \n",
       "ENSG00000198786                        7                     11   \n",
       "ENSG00000198695                        0                      0   \n",
       "ENSG00000198727                       29                     57   \n",
       "ENSG00000274847                        0                      0   \n",
       "\n",
       "                    ATTACCTAGAGCCGTA.7.13  TTTGGAGAGCATATGA.7.6  \\\n",
       "ensemble_gene_name                                                \n",
       "ENSG00000163463                         0                     0   \n",
       "ENSG00000163462                         0                     0   \n",
       "ENSG00000185499                         0                     0   \n",
       "ENSG00000169231                         0                     0   \n",
       "ENSG00000261905                         0                     0   \n",
       "...                                   ...                   ...   \n",
       "ENSG00000198886                        20                    40   \n",
       "ENSG00000198786                         3                     3   \n",
       "ENSG00000198695                         0                     1   \n",
       "ENSG00000198727                        14                    20   \n",
       "ENSG00000274847                         0                     0   \n",
       "\n",
       "                    TTCTAACTCCGTAATG.22.9  TCCATCGCATCTGTTT.14.14  \\\n",
       "ensemble_gene_name                                                  \n",
       "ENSG00000163463                         0                       0   \n",
       "ENSG00000163462                         0                       0   \n",
       "ENSG00000185499                         0                       0   \n",
       "ENSG00000169231                         0                       0   \n",
       "ENSG00000261905                         0                       0   \n",
       "...                                   ...                     ...   \n",
       "ENSG00000198886                        16                      24   \n",
       "ENSG00000198786                         3                       5   \n",
       "ENSG00000198695                         0                       0   \n",
       "ENSG00000198727                        23                      18   \n",
       "ENSG00000274847                         0                       0   \n",
       "\n",
       "                    GTCAAGTAGTGGCCTC.21.2  CAGCCAGTCCGTAGGC.10.13  \\\n",
       "ensemble_gene_name                                                  \n",
       "ENSG00000163463                         0                       0   \n",
       "ENSG00000163462                         0                       1   \n",
       "ENSG00000185499                         0                       0   \n",
       "ENSG00000169231                         0                       0   \n",
       "ENSG00000261905                         0                       0   \n",
       "...                                   ...                     ...   \n",
       "ENSG00000198886                         5                      25   \n",
       "ENSG00000198786                         1                       9   \n",
       "ENSG00000198695                         0                       0   \n",
       "ENSG00000198727                         6                      27   \n",
       "ENSG00000274847                         0                       0   \n",
       "\n",
       "                    GGAAGTGGTATCCTCC.9.9  TTGCCTGGTGTATCCA.30.11  \n",
       "ensemble_gene_name                                                \n",
       "ENSG00000163463                        0                       0  \n",
       "ENSG00000163462                        0                       0  \n",
       "ENSG00000185499                        0                       0  \n",
       "ENSG00000169231                        0                       0  \n",
       "ENSG00000261905                        0                       0  \n",
       "...                                  ...                     ...  \n",
       "ENSG00000198886                        0                       7  \n",
       "ENSG00000198786                        2                       2  \n",
       "ENSG00000198695                        0                       0  \n",
       "ENSG00000198727                        2                       5  \n",
       "ENSG00000274847                        0                       0  \n",
       "\n",
       "[22500 rows x 164849 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c9bf186d-524f-4f76-be92-49e74e0c2a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENSG00000198786'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[1]=='MT-ND5'][0].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6ddd0256-7733-41a4-ba21-8e5406d989d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = '../../preprocessed_data/inhibitory_neuron/count_matrix_ensemble_id_inhibitory.pkl'\n",
    "data.to_pickle(pickle_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7c2f5f2-75f5-4925-9468-4a2059335209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38da5102-1ddb-4767-bf58-14a8a786c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_metadata = single_cell_metadata[single_cell_metadata.cell_id.isin(data.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e83faaa-021f-4b85-9192-979ec93ba3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGAACTGAT.10.12</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGAAGCGGG.31.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AAACCCAAGACTCTTG.2.4</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>19464</td>\n",
       "      <td>5267</td>\n",
       "      <td>0.709001</td>\n",
       "      <td>0.303124</td>\n",
       "      <td>0.867653</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-30479</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2398487</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AAACCCAAGAGGCGTT.1.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>5782</td>\n",
       "      <td>2943</td>\n",
       "      <td>0.830163</td>\n",
       "      <td>0.397786</td>\n",
       "      <td>0.922041</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-59604</td>\n",
       "      <td>no</td>\n",
       "      <td>R8799615</td>\n",
       "      <td>False</td>\n",
       "      <td>No AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424419</th>\n",
       "      <td>TTTGTTGTCTGGAAGG.44.2</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>8260</td>\n",
       "      <td>3331</td>\n",
       "      <td>8.789346</td>\n",
       "      <td>0.181598</td>\n",
       "      <td>0.899309</td>\n",
       "      <td>Inh L1 PAX6 CA4</td>\n",
       "      <td>ROSMAP-17199</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1617674</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424422</th>\n",
       "      <td>TTTGTTGTCTTACACT.27.3</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>40445</td>\n",
       "      <td>7315</td>\n",
       "      <td>0.487081</td>\n",
       "      <td>0.279392</td>\n",
       "      <td>0.838795</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-18464</td>\n",
       "      <td>yes</td>\n",
       "      <td>R5405023</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424426</th>\n",
       "      <td>TTTGTTGTCTTCCCGA.28.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424427</th>\n",
       "      <td>TTTGTTGTCTTCGACC.3.13</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>16770</td>\n",
       "      <td>5431</td>\n",
       "      <td>2.098986</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-53472</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424428</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164849 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "2       AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764   \n",
       "3        AAACCCAAGAAGCGGG.31.8     ROSMAP       11658          4377   \n",
       "13        AAACCCAAGACTCTTG.2.4     ROSMAP       19464          5267   \n",
       "14       AAACCCAAGAGGCGTT.1.11     ROSMAP        5782          2943   \n",
       "...                        ...        ...         ...           ...   \n",
       "424419   TTTGTTGTCTGGAAGG.44.2     ROSMAP        8260          3331   \n",
       "424422   TTTGTTGTCTTACACT.27.3     ROSMAP       40445          7315   \n",
       "424426   TTTGTTGTCTTCCCGA.28.6     ROSMAP       22844          5507   \n",
       "424427   TTTGTTGTCTTCGACC.3.13     ROSMAP       16770          5431   \n",
       "424428   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "2         4.809160    0.274809          0.901814            Inh LAMP5 RELN   \n",
       "3         5.738549    0.394579          0.895381            Inh VIP CLSTN2   \n",
       "13        0.709001    0.303124          0.867653            Inh PVALB HTR4   \n",
       "14        0.830163    0.397786          0.922041            Inh VIP CLSTN2   \n",
       "...            ...         ...               ...                       ...   \n",
       "424419    8.789346    0.181598          0.899309           Inh L1 PAX6 CA4   \n",
       "424422    0.487081    0.279392          0.838795            Inh PVALB HTR4   \n",
       "424426    0.153213    0.358956          0.858250           Inh PVALB SULF1   \n",
       "424427    2.098986    0.679785          0.884093             Inh CUX2 MSR1   \n",
       "424428    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD individualID  \\\n",
       "0       ROSMAP-65967                        yes     R3857147   \n",
       "2       ROSMAP-57958                        yes     R2347173   \n",
       "3       ROSMAP-40761                        yes     R1287407   \n",
       "13      ROSMAP-30479                        yes     R2398487   \n",
       "14      ROSMAP-59604                         no     R8799615   \n",
       "...              ...                        ...          ...   \n",
       "424419  ROSMAP-17199                        yes     R1617674   \n",
       "424422  ROSMAP-18464                        yes     R5405023   \n",
       "424426  ROSMAP-38931                         no     R6292415   \n",
       "424427  ROSMAP-53472                        yes     R3863249   \n",
       "424428  ROSMAP-44788                         no     R5221394   \n",
       "\n",
       "       clinical_diagnosis pathological_diagnosis clinical_pathological_AD  \\\n",
       "0                      AD                     AD          AD_with_Plaques   \n",
       "2                     NCI                     AD                    False   \n",
       "3                   False                     AD                    False   \n",
       "13                     AD                  False                    False   \n",
       "14                  False                  No AD                    False   \n",
       "...                   ...                    ...                      ...   \n",
       "424419                 AD                  False                    False   \n",
       "424422                 AD                     AD          AD_with_Plaques   \n",
       "424426                NCI                  No AD      NCI_with_No_Plaques   \n",
       "424427              False                  False                    False   \n",
       "424428                NCI                  No AD      NCI_with_No_Plaques   \n",
       "\n",
       "       train_test_clinical_and_pathological  \n",
       "0                                     train  \n",
       "2                                       NaN  \n",
       "3                                       NaN  \n",
       "13                                      NaN  \n",
       "14                                      NaN  \n",
       "...                                     ...  \n",
       "424419                                  NaN  \n",
       "424422                                train  \n",
       "424426                                train  \n",
       "424427                                  NaN  \n",
       "424428                                 test  \n",
       "\n",
       "[164849 rows x 15 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "713ead92-f161-4dee-9a9f-13714effd332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAACCCAAGAAATCCA.12.9',\n",
       " 'AAACCCAAGATTCGCT.20.4',\n",
       " 'AAACCCAAGCCATCCG.21.6',\n",
       " 'AAACCCAAGCCTATTG.18.6',\n",
       " 'AAACCCAAGCTAGATA.25.10',\n",
       " 'AAACCCAAGCTAGTTC.31.9',\n",
       " 'AAACCCAAGGCTATCT.18.7',\n",
       " 'AAACCCAAGGTGCTAG.19.10',\n",
       " 'AAACCCAAGGTTATAG.23.10',\n",
       " 'AAACCCAAGTCGCCCA.18.6']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = list(single_cell_metadata[single_cell_metadata.train_test_clinical_and_pathological == 'train'].cell_id)\n",
    "label_train = list(single_cell_metadata[single_cell_metadata.train_test_clinical_and_pathological == 'train'].clinical_pathological_AD)\n",
    "m[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "97772f3c-797c-48fb-bfda-a3ac71a05ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AD_with_Plaques',\n",
       " 'NCI_with_No_Plaques',\n",
       " 'AD_with_Plaques',\n",
       " 'AD_with_Plaques',\n",
       " 'AD_with_Plaques',\n",
       " 'NCI_with_No_Plaques',\n",
       " 'AD_with_Plaques',\n",
       " 'NCI_with_No_Plaques',\n",
       " 'AD_with_Plaques',\n",
       " 'AD_with_Plaques']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "693a68cc-d081-4f98-8a2a-3f0f20f820f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AD_with_Plaques\n",
       "Name: clinical_pathological_AD, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata[single_cell_metadata.cell_id == 'AAACCCAAGAAATCCA.12.9'].clinical_pathological_AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "150765f2-6815-4753-8c7f-e84c60fab094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <th>AAACCCAAGATTCGCT.20.4</th>\n",
       "      <th>AAACCCAAGCCATCCG.21.6</th>\n",
       "      <th>AAACCCAAGCCTATTG.18.6</th>\n",
       "      <th>AAACCCAAGCTAGATA.25.10</th>\n",
       "      <th>AAACCCAAGCTAGTTC.31.9</th>\n",
       "      <th>AAACCCAAGGCTATCT.18.7</th>\n",
       "      <th>AAACCCAAGGTGCTAG.19.10</th>\n",
       "      <th>AAACCCAAGGTTATAG.23.10</th>\n",
       "      <th>AAACCCAAGTCGCCCA.18.6</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTGTTGGTGGATCGA.32.3</th>\n",
       "      <th>TTTGTTGGTGTACATC.20.4</th>\n",
       "      <th>TTTGTTGGTTACGCCG.1.5</th>\n",
       "      <th>TTTGTTGTCAAATGAG.20.11</th>\n",
       "      <th>TTTGTTGTCAAATGCC.9.14</th>\n",
       "      <th>TTTGTTGTCACACCGG.11.9</th>\n",
       "      <th>TTTGTTGTCCGAAATC.9.14</th>\n",
       "      <th>TTTGTTGTCGAACCTA.5.2</th>\n",
       "      <th>TTTGTTGTCTTACACT.27.3</th>\n",
       "      <th>TTTGTTGTCTTCCCGA.28.6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_gene_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000163463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000163462</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000185499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000169231</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000261905</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198886</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198786</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198727</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>89</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000274847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22500 rows × 53519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AAACCCAAGAAATCCA.12.9  AAACCCAAGATTCGCT.20.4  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                         0                     12   \n",
       "ENSG00000198786                         3                      4   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                         4                     14   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    AAACCCAAGCCATCCG.21.6  AAACCCAAGCCTATTG.18.6  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                         3                     21   \n",
       "ENSG00000198786                         0                      2   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                         1                     18   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    AAACCCAAGCTAGATA.25.10  AAACCCAAGCTAGTTC.31.9  \\\n",
       "ensemble_gene_name                                                  \n",
       "ENSG00000163463                          0                      0   \n",
       "ENSG00000163462                          1                      0   \n",
       "ENSG00000185499                          0                      0   \n",
       "ENSG00000169231                          0                      0   \n",
       "ENSG00000261905                          0                      0   \n",
       "...                                    ...                    ...   \n",
       "ENSG00000198886                         32                     35   \n",
       "ENSG00000198786                         10                      2   \n",
       "ENSG00000198695                          0                      0   \n",
       "ENSG00000198727                         60                     25   \n",
       "ENSG00000274847                          0                      0   \n",
       "\n",
       "                    AAACCCAAGGCTATCT.18.7  AAACCCAAGGTGCTAG.19.10  \\\n",
       "ensemble_gene_name                                                  \n",
       "ENSG00000163463                         0                       0   \n",
       "ENSG00000163462                         0                       0   \n",
       "ENSG00000185499                         0                       0   \n",
       "ENSG00000169231                         0                       0   \n",
       "ENSG00000261905                         0                       0   \n",
       "...                                   ...                     ...   \n",
       "ENSG00000198886                        10                       1   \n",
       "ENSG00000198786                         4                       0   \n",
       "ENSG00000198695                         1                       0   \n",
       "ENSG00000198727                        10                       3   \n",
       "ENSG00000274847                         0                       0   \n",
       "\n",
       "                    AAACCCAAGGTTATAG.23.10  AAACCCAAGTCGCCCA.18.6  ...  \\\n",
       "ensemble_gene_name                                                 ...   \n",
       "ENSG00000163463                          0                      0  ...   \n",
       "ENSG00000163462                          0                      0  ...   \n",
       "ENSG00000185499                          0                      0  ...   \n",
       "ENSG00000169231                          0                      0  ...   \n",
       "ENSG00000261905                          0                      0  ...   \n",
       "...                                    ...                    ...  ...   \n",
       "ENSG00000198886                          9                      6  ...   \n",
       "ENSG00000198786                          1                      2  ...   \n",
       "ENSG00000198695                          0                      0  ...   \n",
       "ENSG00000198727                          7                      6  ...   \n",
       "ENSG00000274847                          0                      0  ...   \n",
       "\n",
       "                    TTTGTTGGTGGATCGA.32.3  TTTGTTGGTGTACATC.20.4  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         1                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                         3                     26   \n",
       "ENSG00000198786                         2                      6   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                         1                     35   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    TTTGTTGGTTACGCCG.1.5  TTTGTTGTCAAATGAG.20.11  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                        0                       0   \n",
       "ENSG00000163462                        1                       1   \n",
       "ENSG00000185499                        0                       0   \n",
       "ENSG00000169231                        0                       0   \n",
       "ENSG00000261905                        0                       0   \n",
       "...                                  ...                     ...   \n",
       "ENSG00000198886                       44                      19   \n",
       "ENSG00000198786                        7                       1   \n",
       "ENSG00000198695                        0                       0   \n",
       "ENSG00000198727                       89                      21   \n",
       "ENSG00000274847                        0                       0   \n",
       "\n",
       "                    TTTGTTGTCAAATGCC.9.14  TTTGTTGTCACACCGG.11.9  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                         0                      8   \n",
       "ENSG00000198786                         0                      6   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                         0                     19   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    TTTGTTGTCCGAAATC.9.14  TTTGTTGTCGAACCTA.5.2  \\\n",
       "ensemble_gene_name                                                \n",
       "ENSG00000163463                         0                     0   \n",
       "ENSG00000163462                         0                     0   \n",
       "ENSG00000185499                         0                     0   \n",
       "ENSG00000169231                         0                     0   \n",
       "ENSG00000261905                         0                     0   \n",
       "...                                   ...                   ...   \n",
       "ENSG00000198886                         4                     6   \n",
       "ENSG00000198786                         0                     2   \n",
       "ENSG00000198695                         0                     0   \n",
       "ENSG00000198727                         3                     5   \n",
       "ENSG00000274847                         0                     0   \n",
       "\n",
       "                    TTTGTTGTCTTACACT.27.3  TTTGTTGTCTTCCCGA.28.6  \n",
       "ensemble_gene_name                                                \n",
       "ENSG00000163463                         0                      0  \n",
       "ENSG00000163462                         0                      1  \n",
       "ENSG00000185499                         0                      0  \n",
       "ENSG00000169231                         0                      0  \n",
       "ENSG00000261905                         0                      0  \n",
       "...                                   ...                    ...  \n",
       "ENSG00000198886                         7                      1  \n",
       "ENSG00000198786                         4                      2  \n",
       "ENSG00000198695                         0                      0  \n",
       "ENSG00000198727                        25                      6  \n",
       "ENSG00000274847                         0                      0  \n",
       "\n",
       "[22500 rows x 53519 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_count_matrix = df_loaded[m]\n",
    "train_count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "453bdd44-edc4-4ba7-8f21-13df74600554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAACCCAAGGGCCCTT.21.11',\n",
       " 'AAACCCACAACGGCCT.32.11',\n",
       " 'AAACCCACACAAGCAG.42.2',\n",
       " 'AAACCCACAGTCACGC.40.2',\n",
       " 'AAACCCAGTGTACGCC.21.11',\n",
       " 'AAACCCATCAGACCCG.6.2',\n",
       " 'AAACCCATCGGTCATA.13.11',\n",
       " 'AAACCCATCTACTATC.32.11',\n",
       " 'AAACCTGAGTACGTAA.38.1',\n",
       " 'AAACCTGCACATCCAA.38.1']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = list(single_cell_metadata[single_cell_metadata.train_test_clinical_and_pathological == 'test'].cell_id)\n",
    "label_test = list(single_cell_metadata[single_cell_metadata.train_test_clinical_and_pathological == 'test'].clinical_pathological_AD)\n",
    "n[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71d188a4-10be-46da-b75c-c6d298f9361a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAACCCAAGGGCCCTT.21.11</th>\n",
       "      <th>AAACCCACAACGGCCT.32.11</th>\n",
       "      <th>AAACCCACACAAGCAG.42.2</th>\n",
       "      <th>AAACCCACAGTCACGC.40.2</th>\n",
       "      <th>AAACCCAGTGTACGCC.21.11</th>\n",
       "      <th>AAACCCATCAGACCCG.6.2</th>\n",
       "      <th>AAACCCATCGGTCATA.13.11</th>\n",
       "      <th>AAACCCATCTACTATC.32.11</th>\n",
       "      <th>AAACCTGAGTACGTAA.38.1</th>\n",
       "      <th>AAACCTGCACATCCAA.38.1</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTGGTTTCTGCAGCG.34.2</th>\n",
       "      <th>TTTGTCAGTCAGGACA.38.1</th>\n",
       "      <th>TTTGTTGCACAAGGTG.40.2</th>\n",
       "      <th>TTTGTTGCACTACCGG.8.11</th>\n",
       "      <th>TTTGTTGCAGGTCAAG.13.2</th>\n",
       "      <th>TTTGTTGCAGGTTTAC.13.2</th>\n",
       "      <th>TTTGTTGTCAAACTGC.8.11</th>\n",
       "      <th>TTTGTTGTCCTCCACA.13.2</th>\n",
       "      <th>TTTGTTGTCCTGTAAG.32.11</th>\n",
       "      <th>TTTGTTGTCTTGGTGA.8.11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_gene_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000163463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000163462</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000185499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000169231</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000261905</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198886</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198786</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198727</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000274847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22500 rows × 8683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AAACCCAAGGGCCCTT.21.11  AAACCCACAACGGCCT.32.11  \\\n",
       "ensemble_gene_name                                                   \n",
       "ENSG00000163463                          0                       0   \n",
       "ENSG00000163462                          0                       1   \n",
       "ENSG00000185499                          0                       0   \n",
       "ENSG00000169231                          0                       0   \n",
       "ENSG00000261905                          0                       0   \n",
       "...                                    ...                     ...   \n",
       "ENSG00000198886                          2                       0   \n",
       "ENSG00000198786                          4                       0   \n",
       "ENSG00000198695                          0                       0   \n",
       "ENSG00000198727                          4                       3   \n",
       "ENSG00000274847                          0                       0   \n",
       "\n",
       "                    AAACCCACACAAGCAG.42.2  AAACCCACAGTCACGC.40.2  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                        32                      0   \n",
       "ENSG00000198786                         6                      0   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                        38                      0   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    AAACCCAGTGTACGCC.21.11  AAACCCATCAGACCCG.6.2  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                          0                     0   \n",
       "ENSG00000163462                          0                     0   \n",
       "ENSG00000185499                          0                     0   \n",
       "ENSG00000169231                          1                     0   \n",
       "ENSG00000261905                          0                     0   \n",
       "...                                    ...                   ...   \n",
       "ENSG00000198886                         11                    17   \n",
       "ENSG00000198786                          1                     5   \n",
       "ENSG00000198695                          0                     0   \n",
       "ENSG00000198727                         10                     8   \n",
       "ENSG00000274847                          0                     0   \n",
       "\n",
       "                    AAACCCATCGGTCATA.13.11  AAACCCATCTACTATC.32.11  \\\n",
       "ensemble_gene_name                                                   \n",
       "ENSG00000163463                          0                       0   \n",
       "ENSG00000163462                          1                       0   \n",
       "ENSG00000185499                          0                       0   \n",
       "ENSG00000169231                          0                       0   \n",
       "ENSG00000261905                          0                       0   \n",
       "...                                    ...                     ...   \n",
       "ENSG00000198886                          8                       2   \n",
       "ENSG00000198786                          1                       1   \n",
       "ENSG00000198695                          0                       0   \n",
       "ENSG00000198727                          3                       0   \n",
       "ENSG00000274847                          0                       0   \n",
       "\n",
       "                    AAACCTGAGTACGTAA.38.1  AAACCTGCACATCCAA.38.1  ...  \\\n",
       "ensemble_gene_name                                                ...   \n",
       "ENSG00000163463                         0                      0  ...   \n",
       "ENSG00000163462                         0                      1  ...   \n",
       "ENSG00000185499                         0                      0  ...   \n",
       "ENSG00000169231                         0                      0  ...   \n",
       "ENSG00000261905                         0                      1  ...   \n",
       "...                                   ...                    ...  ...   \n",
       "ENSG00000198886                         5                     83  ...   \n",
       "ENSG00000198786                         1                      7  ...   \n",
       "ENSG00000198695                         0                      0  ...   \n",
       "ENSG00000198727                         0                     51  ...   \n",
       "ENSG00000274847                         0                      0  ...   \n",
       "\n",
       "                    TTTGGTTTCTGCAGCG.34.2  TTTGTCAGTCAGGACA.38.1  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                         2                      9   \n",
       "ENSG00000198786                         1                      1   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                         4                      8   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    TTTGTTGCACAAGGTG.40.2  TTTGTTGCACTACCGG.8.11  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                        19                      0   \n",
       "ENSG00000198786                         1                      0   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                        13                      0   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    TTTGTTGCAGGTCAAG.13.2  TTTGTTGCAGGTTTAC.13.2  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                        24                     25   \n",
       "ENSG00000198786                         6                      5   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                        23                     38   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    TTTGTTGTCAAACTGC.8.11  TTTGTTGTCCTCCACA.13.2  \\\n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                         0                      0   \n",
       "ENSG00000163462                         0                      0   \n",
       "ENSG00000185499                         0                      0   \n",
       "ENSG00000169231                         0                      0   \n",
       "ENSG00000261905                         0                      0   \n",
       "...                                   ...                    ...   \n",
       "ENSG00000198886                        24                     19   \n",
       "ENSG00000198786                         5                      6   \n",
       "ENSG00000198695                         0                      0   \n",
       "ENSG00000198727                        17                     15   \n",
       "ENSG00000274847                         0                      0   \n",
       "\n",
       "                    TTTGTTGTCCTGTAAG.32.11  TTTGTTGTCTTGGTGA.8.11  \n",
       "ensemble_gene_name                                                 \n",
       "ENSG00000163463                          0                      0  \n",
       "ENSG00000163462                          0                      0  \n",
       "ENSG00000185499                          0                      0  \n",
       "ENSG00000169231                          0                      0  \n",
       "ENSG00000261905                          0                      0  \n",
       "...                                    ...                    ...  \n",
       "ENSG00000198886                          4                      3  \n",
       "ENSG00000198786                          0                      0  \n",
       "ENSG00000198695                          0                      0  \n",
       "ENSG00000198727                          3                      1  \n",
       "ENSG00000274847                          0                      0  \n",
       "\n",
       "[22500 rows x 8683 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_count_matrix = df_loaded[n]\n",
    "test_count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "311f5a74-9976-40b6-99e8-f1371034d969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cell_id, orig.ident, nCount_RNA, nFeature_RNA, percent.mt, percent.rb, log10GenesPerUMI, cell_type_high_resolution, subject, Pathologic_diagnosis_of_AD, individualID, clinical_diagnosis, pathological_diagnosis, clinical_pathological_AD, train_test_clinical_and_pathological]\n",
       "Index: []"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata[single_cell_metadata.cell_id =='AAACCCACAGCACAGA.23.6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52a73bb5-a83c-4a08-8296-f47960022fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = pd.DataFrame(label_test,columns=['diagnosis'])\n",
    "train_label = pd.DataFrame(label_train,columns=['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bfad27bd-30cd-4d3d-85aa-cff368e67e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "NCI_with_No_Plaques    5241\n",
       "AD_with_Plaques        3442\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea04efc9-9bfd-40cb-a78b-acfb6ebdf594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "NCI_with_No_Plaques    29147\n",
       "AD_with_Plaques        24372\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "050cbac6-2c2c-48c2-a146-e202d1843e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/12tb_dsk1/usman/Single_Cell_Microglia_Project/preprocessed_data/train_test_set\n",
    "\n",
    "test_count_matrix.to_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/test_count_matrix.csv')\n",
    "train_count_matrix.to_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/train_count_matrix.csv')\n",
    "\n",
    "test_label.to_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/test_label.csv', index = False)\n",
    "train_label.to_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/train_label.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d634296-7d16-4492-a0ec-8053b0801466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have the train test sets here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6b561a-0a0d-4eed-bf40-7de61cb2df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = pd.read_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/train_count_matrix.csv')\n",
    "qdata = pd.read_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/test_count_matrix.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746d73a0-8ab9-4689-9311-2b7995381dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlabel = pd.read_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/train_label.csv')\n",
    "qlabel = pd.read_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a0a554-593f-4d3d-a6cd-fbbcd44fd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import SliceDict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "868ad77d-8b5e-49b0-ad46-140cefa1c95d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: torch.Size([53519, 22500]) torch.Size([53519, 1])\n",
      "Test set: torch.Size([8683, 22500]) torch.Size([8683, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "train_labels = pd.Series(rlabel['diagnosis'].values, index=rdata.columns[1:])\n",
    "test_labels = pd.Series(qlabel['diagnosis'].values, index=qdata.columns[1:]) \n",
    "\n",
    "\n",
    "label_mapping = {'AD_with_Plaques': 1, 'NCI_with_No_Plaques': 0}\n",
    "train_labels = train_labels.map(label_mapping)\n",
    "test_labels = test_labels.map(label_mapping)\n",
    "\n",
    "\n",
    "\n",
    "X_train = rdata.set_index('ensemble_gene_name').T\n",
    "X_test = qdata.set_index('ensemble_gene_name').T\n",
    "\n",
    "\n",
    "train_labels = train_labels.loc[X_train.index]\n",
    "test_labels = test_labels.loc[X_test.index]\n",
    "\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = train_labels.values\n",
    "X_test = X_test.values\n",
    "y_test = test_labels.values\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"Training set:\", X_train_tensor.shape, y_train_tensor.shape)\n",
    "print(\"Test set:\", X_test_tensor.shape, y_test_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b51d2a6b-fc48-40c2-a4e8-97cf543921d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "0    29147\n",
      "1    24372\n",
      "Name: count, dtype: int64\n",
      "Test set class distribution:\n",
      "0    5241\n",
      "1    3442\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of classes in the training set\n",
    "train_label_counts = pd.Series(y_train).value_counts()\n",
    "print(\"Training set class distribution:\")\n",
    "print(train_label_counts)\n",
    "\n",
    "# Check the distribution of classes in the test set\n",
    "test_label_counts = pd.Series(y_test).value_counts()\n",
    "print(\"Test set class distribution:\")\n",
    "print(test_label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "876baaf6-bff8-4e12-b4b6-7be78bfe684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from imbalanced-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "294ef529-4e23-4f3a-91fc-e5575f78a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden_dim = 128\n",
    "#learning_rate = 0.001\n",
    "#num_epochs = 50\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb11f68-5173-4d71-ab67-94e0330647c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.6201\n",
      "Epoch [2/50], Loss: 0.5109\n",
      "Epoch [3/50], Loss: 0.4588\n",
      "Epoch [4/50], Loss: 0.4092\n",
      "Epoch [5/50], Loss: 0.3717\n",
      "Epoch [6/50], Loss: 0.3510\n",
      "Epoch [7/50], Loss: 0.3278\n",
      "Epoch [8/50], Loss: 0.3080\n",
      "Epoch [9/50], Loss: 0.2913\n",
      "Epoch [10/50], Loss: 0.2799\n",
      "Epoch [11/50], Loss: 0.2686\n",
      "Epoch [12/50], Loss: 0.2537\n",
      "Epoch [13/50], Loss: 0.2508\n",
      "Epoch [14/50], Loss: 0.2466\n",
      "Epoch [15/50], Loss: 0.2428\n",
      "Epoch [16/50], Loss: 0.2279\n",
      "Epoch [17/50], Loss: 0.2284\n",
      "Epoch [18/50], Loss: 0.2203\n",
      "Epoch [19/50], Loss: 0.2082\n",
      "Epoch [20/50], Loss: 0.2296\n",
      "Epoch [21/50], Loss: 0.2060\n",
      "Epoch [22/50], Loss: 0.2540\n",
      "Epoch [23/50], Loss: 0.2100\n",
      "Epoch [24/50], Loss: 0.2140\n",
      "Epoch [25/50], Loss: 0.1911\n",
      "Epoch [26/50], Loss: 0.2808\n",
      "Epoch [27/50], Loss: 0.5004\n",
      "Epoch [28/50], Loss: 0.4774\n",
      "Epoch [29/50], Loss: 0.4587\n",
      "Epoch [30/50], Loss: 0.4795\n",
      "Epoch [31/50], Loss: 0.4559\n",
      "Epoch [32/50], Loss: 0.4116\n",
      "Epoch [33/50], Loss: 0.4002\n",
      "Epoch [34/50], Loss: 0.3999\n",
      "Epoch [35/50], Loss: 0.4030\n",
      "Epoch [36/50], Loss: 0.3714\n",
      "Epoch [37/50], Loss: 0.4052\n",
      "Epoch [38/50], Loss: 0.3889\n",
      "Epoch [39/50], Loss: 0.3830\n",
      "Epoch [40/50], Loss: 0.3682\n",
      "Epoch [41/50], Loss: 0.3727\n",
      "Epoch [42/50], Loss: 0.3542\n",
      "Epoch [43/50], Loss: 0.3513\n",
      "Epoch [44/50], Loss: 0.3724\n",
      "Epoch [45/50], Loss: 0.3534\n",
      "Epoch [46/50], Loss: 0.3568\n",
      "Epoch [47/50], Loss: 0.3392\n",
      "Epoch [48/50], Loss: 0.3325\n",
      "Epoch [49/50], Loss: 0.3327\n",
      "Epoch [50/50], Loss: 0.3240\n",
      "Finished Training\n",
      "Test Accuracy: 0.6509\n",
      "Test AUC: 0.6577\n",
      "Test F1 Score: 0.4646\n",
      "Test Recall: 0.3820\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, output_dim, activation_func):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        \n",
    "        for _ in range(n_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation_func = activation_func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.activation_func(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "hidden_dim = 512\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "n_layers = 5\n",
    "activation_func = F.relu\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "model = SimpleNN(input_dim, hidden_dim, n_layers, output_dim, activation_func)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0, 1], y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Modify the optimizer to use the class weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor).squeeze()\n",
    "    test_predictions = torch.round(torch.sigmoid(test_outputs))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_tensor, test_predictions)\n",
    "    auc = roc_auc_score(y_test_tensor, test_outputs)\n",
    "    f1 = f1_score(y_test_tensor, test_predictions)\n",
    "    recall = recall_score(y_test_tensor, test_predictions)\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test AUC: {auc:.4f}')\n",
    "    print(f'Test F1 Score: {f1:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cbce898-bc5d-4ae8-8742-66c3e1266733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6509\n",
      "Test AUC: 0.6577\n",
      "Test F1 Score: 0.4646\n",
      "Test Recall: 0.3820\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor).squeeze()\n",
    "    test_predictions = torch.round(torch.sigmoid(test_outputs))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_tensor, test_predictions)\n",
    "    auc = roc_auc_score(y_test_tensor, test_outputs)\n",
    "    f1 = f1_score(y_test_tensor, test_predictions)\n",
    "    recall = recall_score(y_test_tensor, test_predictions)\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test AUC: {auc:.4f}')\n",
    "    print(f'Test F1 Score: {f1:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c68f6bfa-278f-4d4e-9318-5574101d3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution after SMOTE:\n",
      "1    29147\n",
      "0    29147\n",
      "Name: count, dtype: int64\n",
      "Epoch [1/50], Loss: 0.6165\n",
      "Epoch [2/50], Loss: 0.5605\n",
      "Epoch [3/50], Loss: 0.5147\n",
      "Epoch [4/50], Loss: 0.5011\n",
      "Epoch [5/50], Loss: 0.4839\n",
      "Epoch [6/50], Loss: 0.4714\n",
      "Epoch [7/50], Loss: 0.4527\n",
      "Epoch [8/50], Loss: 0.4340\n",
      "Epoch [9/50], Loss: 0.4213\n",
      "Epoch [10/50], Loss: 0.4106\n",
      "Epoch [11/50], Loss: 0.4075\n",
      "Epoch [12/50], Loss: 0.4089\n",
      "Epoch [13/50], Loss: 0.3992\n",
      "Epoch [14/50], Loss: 0.3826\n",
      "Epoch [15/50], Loss: 0.3685\n",
      "Epoch [16/50], Loss: 0.3667\n",
      "Epoch [17/50], Loss: 0.3529\n",
      "Epoch [18/50], Loss: 0.3487\n",
      "Epoch [19/50], Loss: 0.3516\n",
      "Epoch [20/50], Loss: 0.3409\n",
      "Epoch [21/50], Loss: 0.3317\n",
      "Epoch [22/50], Loss: 0.3253\n",
      "Epoch [23/50], Loss: 0.3200\n",
      "Epoch [24/50], Loss: 0.3132\n",
      "Epoch [25/50], Loss: 0.3105\n",
      "Epoch [26/50], Loss: 0.3008\n",
      "Epoch [27/50], Loss: 0.3134\n",
      "Epoch [28/50], Loss: 0.3030\n",
      "Epoch [29/50], Loss: 0.2892\n",
      "Epoch [30/50], Loss: 0.2893\n",
      "Epoch [31/50], Loss: 0.2776\n",
      "Epoch [32/50], Loss: 0.2761\n",
      "Epoch [33/50], Loss: 0.2727\n",
      "Epoch [34/50], Loss: 0.2678\n",
      "Epoch [35/50], Loss: 0.2605\n",
      "Epoch [36/50], Loss: 0.2562\n",
      "Epoch [37/50], Loss: 0.2541\n",
      "Epoch [38/50], Loss: 0.2567\n",
      "Epoch [39/50], Loss: 0.2578\n",
      "Epoch [40/50], Loss: 0.2515\n",
      "Epoch [41/50], Loss: 0.2559\n",
      "Epoch [42/50], Loss: 0.2431\n",
      "Epoch [43/50], Loss: 0.2397\n",
      "Epoch [44/50], Loss: 0.2381\n",
      "Epoch [45/50], Loss: 0.2405\n",
      "Epoch [46/50], Loss: 0.2417\n",
      "Epoch [47/50], Loss: 0.2701\n",
      "Epoch [48/50], Loss: 0.2676\n",
      "Epoch [49/50], Loss: 0.2577\n",
      "Epoch [50/50], Loss: 0.2524\n",
      "Finished Training\n",
      "Test Accuracy: 0.6558\n",
      "Test AUC: 0.7085\n",
      "Test F1 Score: 0.5490\n",
      "Test Recall: 0.5285\n"
     ]
    }
   ],
   "source": [
    "train_labels = pd.Series(rlabel['diagnosis'].values, index=rdata.columns[1:])\n",
    "test_labels = pd.Series(qlabel['diagnosis'].values, index=qdata.columns[1:]) \n",
    "\n",
    "label_mapping = {'AD_with_Plaques': 1, 'NCI_with_No_Plaques': 0}\n",
    "train_labels = train_labels.map(label_mapping)\n",
    "test_labels = test_labels.map(label_mapping)\n",
    "\n",
    "X_train = rdata.set_index('ensemble_gene_name').T\n",
    "X_test = qdata.set_index('ensemble_gene_name').T\n",
    "\n",
    "train_labels = train_labels.loc[X_train.index]\n",
    "test_labels = test_labels.loc[X_test.index]\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = train_labels.values\n",
    "X_test = X_test.values\n",
    "y_test = test_labels.values\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the distribution after SMOTE\n",
    "print(\"Training set class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_res).value_counts())\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train_res, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_res, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# DataLoader for balanced dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, output_dim, activation_func, dropout_rate=0.5):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.batch_norm_layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.hidden_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        self.batch_norm_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        for _ in range(n_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.batch_norm_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation_func = activation_func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer, bn_layer in zip(self.hidden_layers, self.batch_norm_layers):\n",
    "            x = self.activation_func(layer(x))\n",
    "            x = bn_layer(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Update hyperparameters\n",
    "hidden_dim = 256\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "n_layers = 3\n",
    "activation_func = F.relu\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "model = SimpleNN(input_dim, hidden_dim, n_layers, output_dim, activation_func, dropout_rate)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels.view(-1, 1)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor).squeeze()\n",
    "    test_predictions = torch.round(torch.sigmoid(test_outputs))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_tensor, test_predictions)\n",
    "    auc = roc_auc_score(y_test_tensor, test_outputs)\n",
    "    f1 = f1_score(y_test_tensor, test_predictions)\n",
    "    recall = recall_score(y_test_tensor, test_predictions)\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test AUC: {auc:.4f}')\n",
    "    print(f'Test F1 Score: {f1:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1a1b1e1-c615-4086-b812-d910bab8e168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution after SMOTE:\n",
      "1    29147\n",
      "0    29147\n",
      "Name: count, dtype: int64\n",
      "Epoch [1/100], Loss: 0.6217\n",
      "Epoch [2/100], Loss: 0.5637\n",
      "Epoch [3/100], Loss: 0.5155\n",
      "Epoch [4/100], Loss: 0.5212\n",
      "Epoch [5/100], Loss: 0.4882\n",
      "Epoch [6/100], Loss: 0.4664\n",
      "Epoch [7/100], Loss: 0.4541\n",
      "Epoch [8/100], Loss: 0.4393\n",
      "Epoch [9/100], Loss: 0.4301\n",
      "Epoch [10/100], Loss: 0.4201\n",
      "Epoch [11/100], Loss: 0.3777\n",
      "Epoch [12/100], Loss: 0.3697\n",
      "Epoch [13/100], Loss: 0.3665\n",
      "Epoch [14/100], Loss: 0.3579\n",
      "Epoch [15/100], Loss: 0.3579\n",
      "Epoch [16/100], Loss: 0.3519\n",
      "Epoch [17/100], Loss: 0.3506\n",
      "Epoch [18/100], Loss: 0.3468\n",
      "Epoch [19/100], Loss: 0.3402\n",
      "Epoch [20/100], Loss: 0.3411\n",
      "Epoch [21/100], Loss: 0.3316\n",
      "Epoch [22/100], Loss: 0.3317\n",
      "Epoch [23/100], Loss: 0.3317\n",
      "Epoch [24/100], Loss: 0.3320\n",
      "Epoch [25/100], Loss: 0.3318\n",
      "Epoch [26/100], Loss: 0.3302\n",
      "Epoch [27/100], Loss: 0.3291\n",
      "Epoch [28/100], Loss: 0.3309\n",
      "Epoch [29/100], Loss: 0.3278\n",
      "Epoch [30/100], Loss: 0.3272\n",
      "Epoch [31/100], Loss: 0.3257\n",
      "Epoch [32/100], Loss: 0.3282\n",
      "Epoch [33/100], Loss: 0.3286\n",
      "Epoch [34/100], Loss: 0.3274\n",
      "Epoch [35/100], Loss: 0.3271\n",
      "Epoch [36/100], Loss: 0.3251\n",
      "Epoch [37/100], Loss: 0.3258\n",
      "Epoch [38/100], Loss: 0.3270\n",
      "Epoch [39/100], Loss: 0.3262\n",
      "Epoch [40/100], Loss: 0.3308\n",
      "Epoch [41/100], Loss: 0.3270\n",
      "Epoch [42/100], Loss: 0.3270\n",
      "Epoch [43/100], Loss: 0.3268\n",
      "Epoch [44/100], Loss: 0.3262\n",
      "Epoch [45/100], Loss: 0.3261\n",
      "Epoch [46/100], Loss: 0.3265\n",
      "Epoch [47/100], Loss: 0.3278\n",
      "Epoch [48/100], Loss: 0.3276\n",
      "Epoch [49/100], Loss: 0.3251\n",
      "Epoch [50/100], Loss: 0.3264\n",
      "Epoch [51/100], Loss: 0.3284\n",
      "Epoch [52/100], Loss: 0.3286\n",
      "Epoch [53/100], Loss: 0.3301\n",
      "Epoch [54/100], Loss: 0.3296\n",
      "Epoch [55/100], Loss: 0.3247\n",
      "Epoch [56/100], Loss: 0.3295\n",
      "Epoch [57/100], Loss: 0.3272\n",
      "Epoch [58/100], Loss: 0.3269\n",
      "Epoch [59/100], Loss: 0.3282\n",
      "Epoch [60/100], Loss: 0.3260\n",
      "Epoch [61/100], Loss: 0.3294\n",
      "Epoch [62/100], Loss: 0.3268\n",
      "Epoch [63/100], Loss: 0.3280\n",
      "Epoch [64/100], Loss: 0.3260\n",
      "Epoch [65/100], Loss: 0.3259\n",
      "Epoch [66/100], Loss: 0.3253\n",
      "Epoch [67/100], Loss: 0.3270\n",
      "Epoch [68/100], Loss: 0.3255\n",
      "Epoch [69/100], Loss: 0.3300\n",
      "Epoch [70/100], Loss: 0.3279\n",
      "Epoch [71/100], Loss: 0.3287\n",
      "Epoch [72/100], Loss: 0.3262\n",
      "Epoch [73/100], Loss: 0.3263\n",
      "Epoch [74/100], Loss: 0.3254\n",
      "Epoch [75/100], Loss: 0.3295\n",
      "Epoch [76/100], Loss: 0.3269\n",
      "Epoch [77/100], Loss: 0.3302\n",
      "Epoch [78/100], Loss: 0.3282\n",
      "Epoch [79/100], Loss: 0.3282\n",
      "Epoch [80/100], Loss: 0.3289\n",
      "Epoch [81/100], Loss: 0.3268\n",
      "Epoch [82/100], Loss: 0.3284\n",
      "Epoch [83/100], Loss: 0.3274\n",
      "Epoch [84/100], Loss: 0.3252\n",
      "Epoch [85/100], Loss: 0.3282\n",
      "Epoch [86/100], Loss: 0.3255\n",
      "Epoch [87/100], Loss: 0.3281\n",
      "Epoch [88/100], Loss: 0.3282\n",
      "Epoch [89/100], Loss: 0.3272\n",
      "Epoch [90/100], Loss: 0.3292\n",
      "Epoch [91/100], Loss: 0.3228\n",
      "Epoch [92/100], Loss: 0.3297\n",
      "Epoch [93/100], Loss: 0.3278\n",
      "Epoch [94/100], Loss: 0.3250\n",
      "Epoch [95/100], Loss: 0.3278\n",
      "Epoch [96/100], Loss: 0.3233\n",
      "Epoch [97/100], Loss: 0.3260\n",
      "Epoch [98/100], Loss: 0.3295\n",
      "Epoch [99/100], Loss: 0.3211\n",
      "Epoch [100/100], Loss: 0.3253\n",
      "Finished Training\n",
      "Test Accuracy: 0.6895\n",
      "Test AUC: 0.7527\n",
      "Test F1 Score: 0.6019\n",
      "Test Recall: 0.5921\n"
     ]
    }
   ],
   "source": [
    "train_labels = pd.Series(rlabel['diagnosis'].values, index=rdata.columns[1:])\n",
    "test_labels = pd.Series(qlabel['diagnosis'].values, index=qdata.columns[1:]) \n",
    "\n",
    "label_mapping = {'AD_with_Plaques': 1, 'NCI_with_No_Plaques': 0}\n",
    "train_labels = train_labels.map(label_mapping)\n",
    "test_labels = test_labels.map(label_mapping)\n",
    "\n",
    "X_train = rdata.set_index('ensemble_gene_name').T\n",
    "X_test = qdata.set_index('ensemble_gene_name').T\n",
    "\n",
    "train_labels = train_labels.loc[X_train.index]\n",
    "test_labels = test_labels.loc[X_test.index]\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = train_labels.values\n",
    "X_test = X_test.values\n",
    "y_test = test_labels.values\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the distribution after SMOTE\n",
    "print(\"Training set class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_res).value_counts())\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train_res, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_res, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# DataLoader for balanced dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the neural network with dropout and batch normalization\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, output_dim, activation_func, dropout_rate=0.5):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.batch_norm_layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.hidden_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        self.batch_norm_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        for _ in range(n_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.batch_norm_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation_func = activation_func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer, bn_layer in zip(self.hidden_layers, self.batch_norm_layers):\n",
    "            x = self.activation_func(layer(x))\n",
    "            x = bn_layer(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Update hyperparameters\n",
    "hidden_dim = 256\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "n_layers = 3\n",
    "activation_func = nn.ReLU()\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "model = SimpleNN(input_dim, hidden_dim, n_layers, output_dim, activation_func, dropout_rate)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels.view(-1, 1)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor).squeeze()\n",
    "    test_predictions = torch.round(torch.sigmoid(test_outputs))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_tensor, test_predictions)\n",
    "    auc = roc_auc_score(y_test_tensor, test_outputs)\n",
    "    f1 = f1_score(y_test_tensor, test_predictions)\n",
    "    recall = recall_score(y_test_tensor, test_predictions)\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test AUC: {auc:.4f}')\n",
    "    print(f'Test F1 Score: {f1:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14633878-02cd-4172-a9e5-e0e7e857119b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7748\u001b[0m  0.4128\n",
      "      2        \u001b[36m0.5977\u001b[0m  0.4123\n",
      "      3        \u001b[36m0.4798\u001b[0m  0.4121\n",
      "      4        \u001b[36m0.3810\u001b[0m  0.4127\n",
      "      5        \u001b[36m0.2968\u001b[0m  0.4126\n",
      "      6        \u001b[36m0.2178\u001b[0m  0.4109\n",
      "      7        \u001b[36m0.1832\u001b[0m  0.4097\n",
      "      8        \u001b[36m0.1819\u001b[0m  0.4112\n",
      "      9        \u001b[36m0.0956\u001b[0m  0.4103\n",
      "     10        \u001b[36m0.0672\u001b[0m  0.4113\n",
      "     11        \u001b[36m0.0520\u001b[0m  0.4107\n",
      "     12        \u001b[36m0.0344\u001b[0m  0.4099\n",
      "     13        \u001b[36m0.0244\u001b[0m  0.4100\n",
      "     14        \u001b[36m0.0178\u001b[0m  0.4107\n",
      "     15        \u001b[36m0.0134\u001b[0m  0.4111\n",
      "     16        \u001b[36m0.0104\u001b[0m  0.4100\n",
      "     17        \u001b[36m0.0092\u001b[0m  0.4118\n",
      "     18        \u001b[36m0.0065\u001b[0m  0.4106\n",
      "     19        \u001b[36m0.0053\u001b[0m  0.4114\n",
      "     20        \u001b[36m0.0044\u001b[0m  0.4117\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0239\u001b[0m  0.4158\n",
      "      2        \u001b[36m0.5898\u001b[0m  0.4128\n",
      "      3        \u001b[36m0.4847\u001b[0m  0.4114\n",
      "      4        \u001b[36m0.3899\u001b[0m  0.4107\n",
      "      5        \u001b[36m0.2872\u001b[0m  0.4095\n",
      "      6        \u001b[36m0.2390\u001b[0m  0.4110\n",
      "      7        \u001b[36m0.1715\u001b[0m  0.4118\n",
      "      8        \u001b[36m0.1173\u001b[0m  0.4115\n",
      "      9        \u001b[36m0.0886\u001b[0m  0.4110\n",
      "     10        0.2440  0.4099\n",
      "     11        \u001b[36m0.0765\u001b[0m  0.4104\n",
      "     12        \u001b[36m0.0504\u001b[0m  0.4086\n",
      "     13        \u001b[36m0.0394\u001b[0m  0.4118\n",
      "     14        \u001b[36m0.0313\u001b[0m  0.4116\n",
      "     15        \u001b[36m0.0252\u001b[0m  0.4114\n",
      "     16        \u001b[36m0.0204\u001b[0m  0.4116\n",
      "     17        \u001b[36m0.0168\u001b[0m  0.4116\n",
      "     18        \u001b[36m0.0139\u001b[0m  0.4104\n",
      "     19        \u001b[36m0.0116\u001b[0m  0.4100\n",
      "     20        \u001b[36m0.0097\u001b[0m  0.4109\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7569\u001b[0m  0.4119\n",
      "      2        \u001b[36m0.6713\u001b[0m  0.4133\n",
      "      3        \u001b[36m0.6388\u001b[0m  0.4123\n",
      "      4        \u001b[36m0.5831\u001b[0m  0.4136\n",
      "      5        \u001b[36m0.5091\u001b[0m  0.4129\n",
      "      6        \u001b[36m0.4411\u001b[0m  0.4141\n",
      "      7        \u001b[36m0.4069\u001b[0m  0.4207\n",
      "      8        \u001b[36m0.3334\u001b[0m  0.4191\n",
      "      9        \u001b[36m0.2962\u001b[0m  0.4201\n",
      "     10        \u001b[36m0.2675\u001b[0m  0.4204\n",
      "     11        \u001b[36m0.2343\u001b[0m  0.4206\n",
      "     12        0.2416  0.4214\n",
      "     13        \u001b[36m0.2216\u001b[0m  0.4226\n",
      "     14        \u001b[36m0.1933\u001b[0m  0.4210\n",
      "     15        \u001b[36m0.1632\u001b[0m  0.4219\n",
      "     16        \u001b[36m0.1475\u001b[0m  0.4221\n",
      "     17        \u001b[36m0.1355\u001b[0m  0.4217\n",
      "     18        0.1481  0.4216\n",
      "     19        0.1608  0.4224\n",
      "     20        \u001b[36m0.1157\u001b[0m  0.4226\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7031\u001b[0m  0.4376\n",
      "      2        \u001b[36m0.5938\u001b[0m  0.4347\n",
      "      3        \u001b[36m0.4537\u001b[0m  0.4340\n",
      "      4        \u001b[36m0.3348\u001b[0m  0.4344\n",
      "      5        \u001b[36m0.1707\u001b[0m  0.4343\n",
      "      6        0.2472  0.4331\n",
      "      7        \u001b[36m0.1556\u001b[0m  0.4330\n",
      "      8        \u001b[36m0.0479\u001b[0m  0.4340\n",
      "      9        \u001b[36m0.0167\u001b[0m  0.4324\n",
      "     10        \u001b[36m0.0075\u001b[0m  0.4331\n",
      "     11        \u001b[36m0.0041\u001b[0m  0.4345\n",
      "     12        \u001b[36m0.0025\u001b[0m  0.4335\n",
      "     13        \u001b[36m0.0018\u001b[0m  0.4329\n",
      "     14        \u001b[36m0.0013\u001b[0m  0.4331\n",
      "     15        \u001b[36m0.0010\u001b[0m  0.4341\n",
      "     16        \u001b[36m0.0008\u001b[0m  0.4318\n",
      "     17        \u001b[36m0.0007\u001b[0m  0.4323\n",
      "     18        \u001b[36m0.0005\u001b[0m  0.4322\n",
      "     19        \u001b[36m0.0005\u001b[0m  0.4315\n",
      "     20        \u001b[36m0.0004\u001b[0m  0.4331\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7002\u001b[0m  0.4347\n",
      "      2        \u001b[36m0.6099\u001b[0m  0.4322\n",
      "      3        \u001b[36m0.5012\u001b[0m  0.4337\n",
      "      4        \u001b[36m0.3760\u001b[0m  0.4327\n",
      "      5        \u001b[36m0.2191\u001b[0m  0.4330\n",
      "      6        \u001b[36m0.1663\u001b[0m  0.4337\n",
      "      7        \u001b[36m0.0808\u001b[0m  0.4325\n",
      "      8        0.3653  0.4319\n",
      "      9        0.1502  0.4338\n",
      "     10        \u001b[36m0.0578\u001b[0m  0.4332\n",
      "     11        \u001b[36m0.0296\u001b[0m  0.4326\n",
      "     12        0.3338  0.4348\n",
      "     13        0.0634  0.4334\n",
      "     14        \u001b[36m0.0224\u001b[0m  0.4339\n",
      "     15        \u001b[36m0.0163\u001b[0m  0.4333\n",
      "     16        \u001b[36m0.0116\u001b[0m  0.4340\n",
      "     17        \u001b[36m0.0087\u001b[0m  0.4333\n",
      "     18        \u001b[36m0.0065\u001b[0m  0.4332\n",
      "     19        \u001b[36m0.0049\u001b[0m  0.4338\n",
      "     20        \u001b[36m0.0038\u001b[0m  0.4334\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6950\u001b[0m  0.4365\n",
      "      2        \u001b[36m0.6079\u001b[0m  0.4329\n",
      "      3        \u001b[36m0.4717\u001b[0m  0.4326\n",
      "      4        \u001b[36m0.3478\u001b[0m  0.4332\n",
      "      5        \u001b[36m0.2239\u001b[0m  0.4337\n",
      "      6        \u001b[36m0.1177\u001b[0m  0.4331\n",
      "      7        0.2384  0.4346\n",
      "      8        0.1653  0.4343\n",
      "      9        \u001b[36m0.0402\u001b[0m  0.4337\n",
      "     10        0.1935  0.4334\n",
      "     11        0.2007  0.4337\n",
      "     12        \u001b[36m0.0251\u001b[0m  0.4329\n",
      "     13        \u001b[36m0.0166\u001b[0m  0.4331\n",
      "     14        \u001b[36m0.0122\u001b[0m  0.4335\n",
      "     15        \u001b[36m0.0094\u001b[0m  0.4318\n",
      "     16        \u001b[36m0.0075\u001b[0m  0.4336\n",
      "     17        \u001b[36m0.0060\u001b[0m  0.4338\n",
      "     18        \u001b[36m0.0050\u001b[0m  0.4319\n",
      "     19        \u001b[36m0.0041\u001b[0m  0.4329\n",
      "     20        \u001b[36m0.0035\u001b[0m  0.4341\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6954\u001b[0m  0.4485\n",
      "      2        \u001b[36m0.6277\u001b[0m  0.4486\n",
      "      3        \u001b[36m0.5551\u001b[0m  0.4469\n",
      "      4        \u001b[36m0.3742\u001b[0m  0.4457\n",
      "      5        \u001b[36m0.2268\u001b[0m  0.4462\n",
      "      6        \u001b[36m0.1998\u001b[0m  0.4470\n",
      "      7        \u001b[36m0.1207\u001b[0m  0.4459\n",
      "      8        \u001b[36m0.0612\u001b[0m  0.4465\n",
      "      9        0.0802  0.4474\n",
      "     10        0.0633  0.4465\n",
      "     11        \u001b[36m0.0249\u001b[0m  0.4478\n",
      "     12        0.0850  0.4460\n",
      "     13        \u001b[36m0.0155\u001b[0m  0.4462\n",
      "     14        0.0772  0.4464\n",
      "     15        0.0263  0.4462\n",
      "     16        \u001b[36m0.0074\u001b[0m  0.4459\n",
      "     17        \u001b[36m0.0014\u001b[0m  0.4468\n",
      "     18        \u001b[36m0.0010\u001b[0m  0.4470\n",
      "     19        \u001b[36m0.0007\u001b[0m  0.4474\n",
      "     20        \u001b[36m0.0006\u001b[0m  0.4473\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6965\u001b[0m  0.4441\n",
      "      2        \u001b[36m0.6328\u001b[0m  0.4442\n",
      "      3        \u001b[36m0.5180\u001b[0m  0.4450\n",
      "      4        \u001b[36m0.3633\u001b[0m  0.4448\n",
      "      5        \u001b[36m0.2381\u001b[0m  0.4446\n",
      "      6        \u001b[36m0.1292\u001b[0m  0.4441\n",
      "      7        0.1682  0.4440\n",
      "      8        \u001b[36m0.0801\u001b[0m  0.4434\n",
      "      9        0.1441  0.4440\n",
      "     10        0.1037  0.4443\n",
      "     11        \u001b[36m0.0412\u001b[0m  0.4441\n",
      "     12        0.0583  0.4447\n",
      "     13        \u001b[36m0.0060\u001b[0m  0.4449\n",
      "     14        \u001b[36m0.0011\u001b[0m  0.4425\n",
      "     15        \u001b[36m0.0006\u001b[0m  0.4450\n",
      "     16        \u001b[36m0.0004\u001b[0m  0.4438\n",
      "     17        \u001b[36m0.0003\u001b[0m  0.4438\n",
      "     18        \u001b[36m0.0003\u001b[0m  0.4447\n",
      "     19        \u001b[36m0.0002\u001b[0m  0.4437\n",
      "     20        \u001b[36m0.0002\u001b[0m  0.4431\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6984\u001b[0m  0.4469\n",
      "      2        \u001b[36m0.6616\u001b[0m  0.4459\n",
      "      3        \u001b[36m0.5847\u001b[0m  0.4449\n",
      "      4        \u001b[36m0.3882\u001b[0m  0.4452\n",
      "      5        \u001b[36m0.2502\u001b[0m  0.4446\n",
      "      6        \u001b[36m0.1338\u001b[0m  0.4449\n",
      "      7        \u001b[36m0.1278\u001b[0m  0.4451\n",
      "      8        \u001b[36m0.0873\u001b[0m  0.4446\n",
      "      9        0.1157  0.4447\n",
      "     10        \u001b[36m0.0534\u001b[0m  0.4450\n",
      "     11        \u001b[36m0.0089\u001b[0m  0.4449\n",
      "     12        \u001b[36m0.0039\u001b[0m  0.4451\n",
      "     13        \u001b[36m0.0022\u001b[0m  0.4453\n",
      "     14        \u001b[36m0.0014\u001b[0m  0.4456\n",
      "     15        \u001b[36m0.0009\u001b[0m  0.4465\n",
      "     16        \u001b[36m0.0007\u001b[0m  0.4461\n",
      "     17        \u001b[36m0.0005\u001b[0m  0.4448\n",
      "     18        \u001b[36m0.0004\u001b[0m  0.4448\n",
      "     19        \u001b[36m0.0003\u001b[0m  0.4449\n",
      "     20        \u001b[36m0.0002\u001b[0m  0.4449\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8166\u001b[0m  0.5225\n",
      "      2        \u001b[36m0.6872\u001b[0m  0.5215\n",
      "      3        \u001b[36m0.6778\u001b[0m  0.5165\n",
      "      4        \u001b[36m0.6305\u001b[0m  0.5197\n",
      "      5        \u001b[36m0.5131\u001b[0m  0.5168\n",
      "      6        \u001b[36m0.3824\u001b[0m  0.5180\n",
      "      7        \u001b[36m0.2684\u001b[0m  0.5173\n",
      "      8        \u001b[36m0.1949\u001b[0m  0.5177\n",
      "      9        \u001b[36m0.1206\u001b[0m  0.5159\n",
      "     10        \u001b[36m0.0777\u001b[0m  0.5196\n",
      "     11        \u001b[36m0.0528\u001b[0m  0.5169\n",
      "     12        \u001b[36m0.0369\u001b[0m  0.5174\n",
      "     13        \u001b[36m0.0273\u001b[0m  0.5164\n",
      "     14        0.0279  0.5171\n",
      "     15        0.0417  0.5173\n",
      "     16        0.0309  0.5173\n",
      "     17        \u001b[36m0.0136\u001b[0m  0.5180\n",
      "     18        \u001b[36m0.0101\u001b[0m  0.5194\n",
      "     19        \u001b[36m0.0083\u001b[0m  0.5174\n",
      "     20        \u001b[36m0.0071\u001b[0m  0.5171\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8371\u001b[0m  0.5229\n",
      "      2        \u001b[36m0.6958\u001b[0m  0.5261\n",
      "      3        \u001b[36m0.6920\u001b[0m  0.5262\n",
      "      4        \u001b[36m0.6908\u001b[0m  0.5251\n",
      "      5        \u001b[36m0.6900\u001b[0m  0.5256\n",
      "      6        \u001b[36m0.6895\u001b[0m  0.5244\n",
      "      7        \u001b[36m0.6890\u001b[0m  0.5236\n",
      "      8        \u001b[36m0.6887\u001b[0m  0.5258\n",
      "      9        \u001b[36m0.6883\u001b[0m  0.5262\n",
      "     10        0.6890  0.5263\n",
      "     11        0.6890  0.5248\n",
      "     12        0.6889  0.5252\n",
      "     13        0.6889  0.5256\n",
      "     14        0.6889  0.5275\n",
      "     15        0.6889  0.5274\n",
      "     16        0.6889  0.5263\n",
      "     17        0.6889  0.5266\n",
      "     18        0.6889  0.5294\n",
      "     19        0.6889  0.5262\n",
      "     20        0.6889  0.5267\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9226\u001b[0m  0.5211\n",
      "      2        \u001b[36m0.5829\u001b[0m  0.5244\n",
      "      3        \u001b[36m0.4604\u001b[0m  0.5255\n",
      "      4        \u001b[36m0.3283\u001b[0m  0.5235\n",
      "      5        \u001b[36m0.2585\u001b[0m  0.5245\n",
      "      6        \u001b[36m0.1706\u001b[0m  0.5238\n",
      "      7        \u001b[36m0.1112\u001b[0m  0.5240\n",
      "      8        \u001b[36m0.0793\u001b[0m  0.5217\n",
      "      9        0.1377  0.5223\n",
      "     10        0.1760  0.5237\n",
      "     11        0.0802  0.5240\n",
      "     12        \u001b[36m0.0393\u001b[0m  0.5248\n",
      "     13        0.1670  0.5238\n",
      "     14        \u001b[36m0.0325\u001b[0m  0.5234\n",
      "     15        \u001b[36m0.0201\u001b[0m  0.5224\n",
      "     16        \u001b[36m0.0155\u001b[0m  0.5207\n",
      "     17        \u001b[36m0.0126\u001b[0m  0.5240\n",
      "     18        \u001b[36m0.0105\u001b[0m  0.5238\n",
      "     19        \u001b[36m0.0088\u001b[0m  0.5239\n",
      "     20        \u001b[36m0.0075\u001b[0m  0.5237\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7327\u001b[0m  0.5415\n",
      "      2        \u001b[36m0.6054\u001b[0m  0.5425\n",
      "      3        \u001b[36m0.4773\u001b[0m  0.5400\n",
      "      4        \u001b[36m0.3073\u001b[0m  0.5377\n",
      "      5        0.3241  0.5408\n",
      "      6        \u001b[36m0.1903\u001b[0m  0.5387\n",
      "      7        \u001b[36m0.1366\u001b[0m  0.5402\n",
      "      8        0.1765  0.5400\n",
      "      9        \u001b[36m0.0496\u001b[0m  0.5394\n",
      "     10        0.0990  0.5392\n",
      "     11        \u001b[36m0.0365\u001b[0m  0.5388\n",
      "     12        0.0755  0.5392\n",
      "     13        \u001b[36m0.0188\u001b[0m  0.5373\n",
      "     14        \u001b[36m0.0060\u001b[0m  0.5422\n",
      "     15        \u001b[36m0.0038\u001b[0m  0.5415\n",
      "     16        \u001b[36m0.0027\u001b[0m  0.5395\n",
      "     17        \u001b[36m0.0021\u001b[0m  0.5429\n",
      "     18        \u001b[36m0.0017\u001b[0m  0.5435\n",
      "     19        \u001b[36m0.0013\u001b[0m  0.5372\n",
      "     20        \u001b[36m0.0011\u001b[0m  0.5393\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7193\u001b[0m  0.5406\n",
      "      2        \u001b[36m0.6406\u001b[0m  0.5429\n",
      "      3        \u001b[36m0.5190\u001b[0m  0.5442\n",
      "      4        \u001b[36m0.4484\u001b[0m  0.5397\n",
      "      5        \u001b[36m0.2583\u001b[0m  0.5379\n",
      "      6        \u001b[36m0.1349\u001b[0m  0.5407\n",
      "      7        0.1615  0.5410\n",
      "      8        \u001b[36m0.0582\u001b[0m  0.5413\n",
      "      9        \u001b[36m0.0318\u001b[0m  0.5399\n",
      "     10        \u001b[36m0.0234\u001b[0m  0.5376\n",
      "     11        0.1592  0.5386\n",
      "     12        0.0794  0.5383\n",
      "     13        \u001b[36m0.0118\u001b[0m  0.5364\n",
      "     14        \u001b[36m0.0079\u001b[0m  0.5409\n",
      "     15        \u001b[36m0.0057\u001b[0m  0.5401\n",
      "     16        \u001b[36m0.0044\u001b[0m  0.5397\n",
      "     17        \u001b[36m0.0035\u001b[0m  0.5389\n",
      "     18        \u001b[36m0.0028\u001b[0m  0.5404\n",
      "     19        \u001b[36m0.0023\u001b[0m  0.5430\n",
      "     20        \u001b[36m0.0019\u001b[0m  0.5438\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7244\u001b[0m  0.5404\n",
      "      2        \u001b[36m0.6120\u001b[0m  0.5410\n",
      "      3        \u001b[36m0.5172\u001b[0m  0.5407\n",
      "      4        \u001b[36m0.3784\u001b[0m  0.5407\n",
      "      5        \u001b[36m0.2286\u001b[0m  0.5409\n",
      "      6        \u001b[36m0.2011\u001b[0m  0.5402\n",
      "      7        \u001b[36m0.0894\u001b[0m  0.5405\n",
      "      8        \u001b[36m0.0363\u001b[0m  0.5425\n",
      "      9        \u001b[36m0.0183\u001b[0m  0.5425\n",
      "     10        \u001b[36m0.0103\u001b[0m  0.5393\n",
      "     11        \u001b[36m0.0063\u001b[0m  0.5417\n",
      "     12        \u001b[36m0.0043\u001b[0m  0.5406\n",
      "     13        \u001b[36m0.0031\u001b[0m  0.5383\n",
      "     14        \u001b[36m0.0023\u001b[0m  0.5417\n",
      "     15        \u001b[36m0.0018\u001b[0m  0.5398\n",
      "     16        \u001b[36m0.0014\u001b[0m  0.5419\n",
      "     17        \u001b[36m0.0011\u001b[0m  0.5415\n",
      "     18        \u001b[36m0.0009\u001b[0m  0.5406\n",
      "     19        \u001b[36m0.0008\u001b[0m  0.5412\n",
      "     20        \u001b[36m0.0007\u001b[0m  0.5415\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6915\u001b[0m  0.5583\n",
      "      2        \u001b[36m0.6101\u001b[0m  0.5547\n",
      "      3        \u001b[36m0.4433\u001b[0m  0.5546\n",
      "      4        \u001b[36m0.3247\u001b[0m  0.5577\n",
      "      5        \u001b[36m0.1859\u001b[0m  0.5571\n",
      "      6        0.1933  0.5579\n",
      "      7        \u001b[36m0.1256\u001b[0m  0.5545\n",
      "      8        \u001b[36m0.0679\u001b[0m  0.5546\n",
      "      9        0.0806  0.5555\n",
      "     10        0.0814  0.5567\n",
      "     11        \u001b[36m0.0162\u001b[0m  0.5578\n",
      "     12        \u001b[36m0.0026\u001b[0m  0.5590\n",
      "     13        \u001b[36m0.0012\u001b[0m  0.5579\n",
      "     14        \u001b[36m0.0008\u001b[0m  0.5538\n",
      "     15        \u001b[36m0.0006\u001b[0m  0.5561\n",
      "     16        \u001b[36m0.0004\u001b[0m  0.5543\n",
      "     17        \u001b[36m0.0003\u001b[0m  0.5532\n",
      "     18        \u001b[36m0.0003\u001b[0m  0.5540\n",
      "     19        \u001b[36m0.0002\u001b[0m  0.5532\n",
      "     20        \u001b[36m0.0001\u001b[0m  0.5525\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7063\u001b[0m  0.5558\n",
      "      2        \u001b[36m0.6616\u001b[0m  0.5568\n",
      "      3        \u001b[36m0.5892\u001b[0m  0.5527\n",
      "      4        \u001b[36m0.4601\u001b[0m  0.5448\n",
      "      5        \u001b[36m0.2718\u001b[0m  0.5548\n",
      "      6        0.3091  0.5557\n",
      "      7        \u001b[36m0.2169\u001b[0m  0.5520\n",
      "      8        \u001b[36m0.0895\u001b[0m  0.5543\n",
      "      9        \u001b[36m0.0582\u001b[0m  0.5550\n",
      "     10        0.0907  0.5546\n",
      "     11        \u001b[36m0.0099\u001b[0m  0.5546\n",
      "     12        \u001b[36m0.0028\u001b[0m  0.5545\n",
      "     13        \u001b[36m0.0015\u001b[0m  0.5541\n",
      "     14        \u001b[36m0.0010\u001b[0m  0.5556\n",
      "     15        \u001b[36m0.0007\u001b[0m  0.5532\n",
      "     16        \u001b[36m0.0005\u001b[0m  0.5551\n",
      "     17        \u001b[36m0.0004\u001b[0m  0.5544\n",
      "     18        \u001b[36m0.0003\u001b[0m  0.5545\n",
      "     19        \u001b[36m0.0003\u001b[0m  0.5595\n",
      "     20        \u001b[36m0.0002\u001b[0m  0.5581\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6976\u001b[0m  0.5589\n",
      "      2        \u001b[36m0.6065\u001b[0m  0.5533\n",
      "      3        \u001b[36m0.4946\u001b[0m  0.5518\n",
      "      4        \u001b[36m0.4199\u001b[0m  0.5511\n",
      "      5        \u001b[36m0.2240\u001b[0m  0.5542\n",
      "      6        \u001b[36m0.1375\u001b[0m  0.5512\n",
      "      7        \u001b[36m0.1175\u001b[0m  0.5520\n",
      "      8        0.1538  0.5513\n",
      "      9        0.1420  0.5544\n",
      "     10        0.1413  0.5541\n",
      "     11        \u001b[36m0.0191\u001b[0m  0.5533\n",
      "     12        \u001b[36m0.0029\u001b[0m  0.5543\n",
      "     13        \u001b[36m0.0016\u001b[0m  0.5542\n",
      "     14        \u001b[36m0.0010\u001b[0m  0.5546\n",
      "     15        \u001b[36m0.0007\u001b[0m  0.5548\n",
      "     16        \u001b[36m0.0005\u001b[0m  0.5544\n",
      "     17        \u001b[36m0.0004\u001b[0m  0.5538\n",
      "     18        \u001b[36m0.0003\u001b[0m  0.5541\n",
      "     19        \u001b[36m0.0002\u001b[0m  0.5546\n",
      "     20        \u001b[36m0.0002\u001b[0m  0.5546\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8991\u001b[0m  0.7987\n",
      "      2        \u001b[36m0.5442\u001b[0m  0.7997\n",
      "      3        \u001b[36m0.3953\u001b[0m  0.7991\n",
      "      4        \u001b[36m0.2766\u001b[0m  0.7998\n",
      "      5        \u001b[36m0.2419\u001b[0m  0.7988\n",
      "      6        \u001b[36m0.1928\u001b[0m  0.8000\n",
      "      7        \u001b[36m0.1534\u001b[0m  0.7986\n",
      "      8        \u001b[36m0.0682\u001b[0m  0.7990\n",
      "      9        \u001b[36m0.0408\u001b[0m  0.7980\n",
      "     10        \u001b[36m0.0276\u001b[0m  0.7992\n",
      "     11        \u001b[36m0.0193\u001b[0m  0.7981\n",
      "     12        \u001b[36m0.0141\u001b[0m  0.7984\n",
      "     13        \u001b[36m0.0105\u001b[0m  0.7994\n",
      "     14        \u001b[36m0.0081\u001b[0m  0.7991\n",
      "     15        \u001b[36m0.0065\u001b[0m  0.8001\n",
      "     16        \u001b[36m0.0052\u001b[0m  0.7977\n",
      "     17        \u001b[36m0.0042\u001b[0m  0.7983\n",
      "     18        \u001b[36m0.0035\u001b[0m  0.7985\n",
      "     19        \u001b[36m0.0030\u001b[0m  0.7989\n",
      "     20        \u001b[36m0.0025\u001b[0m  0.7994\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0102\u001b[0m  0.8010\n",
      "      2        \u001b[36m0.4799\u001b[0m  0.7988\n",
      "      3        \u001b[36m0.3219\u001b[0m  0.7993\n",
      "      4        \u001b[36m0.2702\u001b[0m  0.7994\n",
      "      5        \u001b[36m0.1782\u001b[0m  0.8009\n",
      "      6        0.1907  0.7993\n",
      "      7        \u001b[36m0.1558\u001b[0m  0.7997\n",
      "      8        \u001b[36m0.1221\u001b[0m  0.7993\n",
      "      9        0.2560  0.7986\n",
      "     10        \u001b[36m0.1042\u001b[0m  0.7987\n",
      "     11        0.1290  0.7988\n",
      "     12        \u001b[36m0.0427\u001b[0m  0.7987\n",
      "     13        \u001b[36m0.0209\u001b[0m  0.7998\n",
      "     14        \u001b[36m0.0194\u001b[0m  0.8040\n",
      "     15        0.2954  0.7989\n",
      "     16        0.0734  0.8035\n",
      "     17        0.0218  0.7992\n",
      "     18        \u001b[36m0.0142\u001b[0m  0.8004\n",
      "     19        \u001b[36m0.0107\u001b[0m  0.8001\n",
      "     20        \u001b[36m0.0084\u001b[0m  0.8040\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0045\u001b[0m  0.8047\n",
      "      2        \u001b[36m0.5934\u001b[0m  0.7999\n",
      "      3        \u001b[36m0.4819\u001b[0m  0.7948\n",
      "      4        \u001b[36m0.3549\u001b[0m  0.8001\n",
      "      5        0.3899  0.8005\n",
      "      6        \u001b[36m0.3101\u001b[0m  0.7944\n",
      "      7        \u001b[36m0.1499\u001b[0m  0.7993\n",
      "      8        \u001b[36m0.1010\u001b[0m  0.7988\n",
      "      9        \u001b[36m0.0763\u001b[0m  0.7997\n",
      "     10        \u001b[36m0.0549\u001b[0m  0.8009\n",
      "     11        \u001b[36m0.0349\u001b[0m  0.7991\n",
      "     12        \u001b[36m0.0234\u001b[0m  0.8099\n",
      "     13        \u001b[36m0.0164\u001b[0m  0.8004\n",
      "     14        \u001b[36m0.0120\u001b[0m  0.8000\n",
      "     15        \u001b[36m0.0090\u001b[0m  0.7998\n",
      "     16        \u001b[36m0.0069\u001b[0m  0.7994\n",
      "     17        \u001b[36m0.0053\u001b[0m  0.7999\n",
      "     18        \u001b[36m0.0040\u001b[0m  0.7994\n",
      "     19        \u001b[36m0.0031\u001b[0m  0.7995\n",
      "     20        \u001b[36m0.0024\u001b[0m  0.7997\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7284\u001b[0m  0.8325\n",
      "      2        \u001b[36m0.6304\u001b[0m  0.8300\n",
      "      3        \u001b[36m0.5166\u001b[0m  0.8305\n",
      "      4        \u001b[36m0.3184\u001b[0m  0.8303\n",
      "      5        \u001b[36m0.2067\u001b[0m  0.8313\n",
      "      6        0.2368  0.8303\n",
      "      7        \u001b[36m0.0727\u001b[0m  0.8302\n",
      "      8        \u001b[36m0.0462\u001b[0m  0.8299\n",
      "      9        0.1933  0.8303\n",
      "     10        \u001b[36m0.0413\u001b[0m  0.8310\n",
      "     11        0.0897  0.8299\n",
      "     12        \u001b[36m0.0136\u001b[0m  0.8300\n",
      "     13        \u001b[36m0.0070\u001b[0m  0.8295\n",
      "     14        \u001b[36m0.0046\u001b[0m  0.8304\n",
      "     15        \u001b[36m0.0033\u001b[0m  0.8309\n",
      "     16        \u001b[36m0.0025\u001b[0m  0.8290\n",
      "     17        \u001b[36m0.0019\u001b[0m  0.8306\n",
      "     18        \u001b[36m0.0015\u001b[0m  0.8313\n",
      "     19        \u001b[36m0.0012\u001b[0m  0.8298\n",
      "     20        \u001b[36m0.0010\u001b[0m  0.8306\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7450\u001b[0m  0.8300\n",
      "      2        \u001b[36m0.6236\u001b[0m  0.8258\n",
      "      3        \u001b[36m0.4730\u001b[0m  0.8241\n",
      "      4        \u001b[36m0.4534\u001b[0m  0.8238\n",
      "      5        \u001b[36m0.2468\u001b[0m  0.8237\n",
      "      6        \u001b[36m0.1179\u001b[0m  0.8222\n",
      "      7        0.1841  0.8227\n",
      "      8        \u001b[36m0.1141\u001b[0m  0.8222\n",
      "      9        \u001b[36m0.0785\u001b[0m  0.8225\n",
      "     10        \u001b[36m0.0152\u001b[0m  0.8235\n",
      "     11        \u001b[36m0.0067\u001b[0m  0.8216\n",
      "     12        \u001b[36m0.0039\u001b[0m  0.8222\n",
      "     13        \u001b[36m0.0025\u001b[0m  0.8227\n",
      "     14        \u001b[36m0.0017\u001b[0m  0.8222\n",
      "     15        \u001b[36m0.0010\u001b[0m  0.8227\n",
      "     16        \u001b[36m0.0005\u001b[0m  0.8227\n",
      "     17        \u001b[36m0.0002\u001b[0m  0.8227\n",
      "     18        \u001b[36m0.0002\u001b[0m  0.8230\n",
      "     19        \u001b[36m0.0001\u001b[0m  0.8222\n",
      "     20        \u001b[36m0.0001\u001b[0m  0.8217\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7510\u001b[0m  0.8261\n",
      "      2        \u001b[36m0.6230\u001b[0m  0.8238\n",
      "      3        \u001b[36m0.4526\u001b[0m  0.8226\n",
      "      4        \u001b[36m0.3073\u001b[0m  0.8209\n",
      "      5        \u001b[36m0.2333\u001b[0m  0.8195\n",
      "      6        \u001b[36m0.1124\u001b[0m  0.8197\n",
      "      7        0.1960  0.8194\n",
      "      8        \u001b[36m0.0879\u001b[0m  0.8197\n",
      "      9        \u001b[36m0.0243\u001b[0m  0.8247\n",
      "     10        \u001b[36m0.0154\u001b[0m  0.8195\n",
      "     11        0.0650  0.8198\n",
      "     12        0.1137  0.8229\n",
      "     13        \u001b[36m0.0089\u001b[0m  0.8196\n",
      "     14        0.0875  0.8199\n",
      "     15        0.0133  0.8202\n",
      "     16        \u001b[36m0.0017\u001b[0m  0.8219\n",
      "     17        \u001b[36m0.0010\u001b[0m  0.8189\n",
      "     18        \u001b[36m0.0007\u001b[0m  0.8199\n",
      "     19        \u001b[36m0.0005\u001b[0m  0.8195\n",
      "     20        \u001b[36m0.0004\u001b[0m  0.8203\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7122\u001b[0m  0.8502\n",
      "      2        \u001b[36m0.6527\u001b[0m  0.8460\n",
      "      3        \u001b[36m0.5250\u001b[0m  0.8452\n",
      "      4        \u001b[36m0.3045\u001b[0m  0.8423\n",
      "      5        \u001b[36m0.2411\u001b[0m  0.8432\n",
      "      6        \u001b[36m0.1542\u001b[0m  0.8438\n",
      "      7        \u001b[36m0.0480\u001b[0m  0.8436\n",
      "      8        \u001b[36m0.0259\u001b[0m  0.8423\n",
      "      9        \u001b[36m0.0111\u001b[0m  0.8425\n",
      "     10        0.0331  0.8417\n",
      "     11        0.0157  0.8418\n",
      "     12        0.0371  0.8428\n",
      "     13        0.0587  0.8423\n",
      "     14        \u001b[36m0.0026\u001b[0m  0.8421\n",
      "     15        \u001b[36m0.0007\u001b[0m  0.8433\n",
      "     16        \u001b[36m0.0004\u001b[0m  0.8418\n",
      "     17        \u001b[36m0.0003\u001b[0m  0.8417\n",
      "     18        \u001b[36m0.0002\u001b[0m  0.8424\n",
      "     19        \u001b[36m0.0002\u001b[0m  0.8423\n",
      "     20        \u001b[36m0.0001\u001b[0m  0.8433\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7158\u001b[0m  0.8513\n",
      "      2        \u001b[36m0.6317\u001b[0m  0.8471\n",
      "      3        \u001b[36m0.4993\u001b[0m  0.8455\n",
      "      4        \u001b[36m0.3244\u001b[0m  0.8450\n",
      "      5        \u001b[36m0.3176\u001b[0m  0.8448\n",
      "      6        \u001b[36m0.1436\u001b[0m  0.8465\n",
      "      7        \u001b[36m0.0836\u001b[0m  0.8453\n",
      "      8        \u001b[36m0.0509\u001b[0m  0.8451\n",
      "      9        \u001b[36m0.0284\u001b[0m  0.8453\n",
      "     10        \u001b[36m0.0126\u001b[0m  0.8454\n",
      "     11        0.1560  0.8471\n",
      "     12        0.1634  0.8459\n",
      "     13        0.0444  0.8463\n",
      "     14        \u001b[36m0.0038\u001b[0m  0.8462\n",
      "     15        \u001b[36m0.0008\u001b[0m  0.8466\n",
      "     16        \u001b[36m0.0005\u001b[0m  0.8455\n",
      "     17        \u001b[36m0.0003\u001b[0m  0.8443\n",
      "     18        \u001b[36m0.0002\u001b[0m  0.8462\n",
      "     19        \u001b[36m0.0001\u001b[0m  0.8456\n",
      "     20        \u001b[36m0.0001\u001b[0m  0.8462\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7203\u001b[0m  0.8530\n",
      "      2        \u001b[36m0.6457\u001b[0m  0.8455\n",
      "      3        \u001b[36m0.5135\u001b[0m  0.8470\n",
      "      4        \u001b[36m0.3800\u001b[0m  0.8448\n",
      "      5        \u001b[36m0.2386\u001b[0m  0.8451\n",
      "      6        \u001b[36m0.1936\u001b[0m  0.8437\n",
      "      7        \u001b[36m0.0592\u001b[0m  0.8451\n",
      "      8        \u001b[36m0.0543\u001b[0m  0.8451\n",
      "      9        \u001b[36m0.0424\u001b[0m  0.8453\n",
      "     10        0.0522  0.8438\n",
      "     11        \u001b[36m0.0155\u001b[0m  0.8436\n",
      "     12        \u001b[36m0.0056\u001b[0m  0.8450\n",
      "     13        0.0576  0.8440\n",
      "     14        0.0113  0.8447\n",
      "     15        \u001b[36m0.0008\u001b[0m  0.8450\n",
      "     16        \u001b[36m0.0005\u001b[0m  0.8442\n",
      "     17        \u001b[36m0.0004\u001b[0m  0.8482\n",
      "     18        \u001b[36m0.0003\u001b[0m  0.8447\n",
      "     19        \u001b[36m0.0002\u001b[0m  0.8444\n",
      "     20        \u001b[36m0.0002\u001b[0m  0.8489\n",
      "[CV] END lr=0.001, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6892\u001b[0m  0.4143\n",
      "      2        \u001b[36m0.6532\u001b[0m  0.4090\n",
      "      3        \u001b[36m0.6166\u001b[0m  0.4103\n",
      "      4        \u001b[36m0.5651\u001b[0m  0.4095\n",
      "      5        \u001b[36m0.5301\u001b[0m  0.4084\n",
      "      6        \u001b[36m0.4675\u001b[0m  0.4089\n",
      "      7        \u001b[36m0.4458\u001b[0m  0.4118\n",
      "      8        \u001b[36m0.4043\u001b[0m  0.4089\n",
      "      9        \u001b[36m0.3847\u001b[0m  0.4097\n",
      "     10        \u001b[36m0.3253\u001b[0m  0.4094\n",
      "     11        0.3309  0.4088\n",
      "     12        \u001b[36m0.2882\u001b[0m  0.4076\n",
      "     13        \u001b[36m0.2462\u001b[0m  0.4090\n",
      "     14        \u001b[36m0.2033\u001b[0m  0.4077\n",
      "     15        \u001b[36m0.1714\u001b[0m  0.4074\n",
      "     16        \u001b[36m0.1646\u001b[0m  0.4086\n",
      "     17        0.1680  0.4092\n",
      "     18        0.1810  0.4073\n",
      "     19        \u001b[36m0.1445\u001b[0m  0.4077\n",
      "     20        \u001b[36m0.1289\u001b[0m  0.4077\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6964\u001b[0m  0.4152\n",
      "      2        \u001b[36m0.6799\u001b[0m  0.4095\n",
      "      3        \u001b[36m0.6613\u001b[0m  0.4085\n",
      "      4        \u001b[36m0.6373\u001b[0m  0.4095\n",
      "      5        \u001b[36m0.6219\u001b[0m  0.4095\n",
      "      6        \u001b[36m0.5878\u001b[0m  0.4084\n",
      "      7        \u001b[36m0.5300\u001b[0m  0.4087\n",
      "      8        \u001b[36m0.5221\u001b[0m  0.4068\n",
      "      9        \u001b[36m0.4542\u001b[0m  0.4075\n",
      "     10        \u001b[36m0.4026\u001b[0m  0.4145\n",
      "     11        \u001b[36m0.3674\u001b[0m  0.4049\n",
      "     12        \u001b[36m0.3198\u001b[0m  0.4061\n",
      "     13        \u001b[36m0.2912\u001b[0m  0.4054\n",
      "     14        \u001b[36m0.2775\u001b[0m  0.4051\n",
      "     15        \u001b[36m0.2309\u001b[0m  0.4060\n",
      "     16        \u001b[36m0.2148\u001b[0m  0.4058\n",
      "     17        0.2225  0.4059\n",
      "     18        0.2151  0.4053\n",
      "     19        \u001b[36m0.1917\u001b[0m  0.4046\n",
      "     20        \u001b[36m0.1416\u001b[0m  0.4056\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7063\u001b[0m  0.4140\n",
      "      2        \u001b[36m0.6558\u001b[0m  0.4098\n",
      "      3        \u001b[36m0.6387\u001b[0m  0.4074\n",
      "      4        \u001b[36m0.5981\u001b[0m  0.4060\n",
      "      5        \u001b[36m0.5583\u001b[0m  0.4077\n",
      "      6        \u001b[36m0.5199\u001b[0m  0.4066\n",
      "      7        \u001b[36m0.4912\u001b[0m  0.4069\n",
      "      8        \u001b[36m0.4348\u001b[0m  0.4058\n",
      "      9        \u001b[36m0.3829\u001b[0m  0.4063\n",
      "     10        \u001b[36m0.3494\u001b[0m  0.4055\n",
      "     11        \u001b[36m0.2926\u001b[0m  0.4061\n",
      "     12        \u001b[36m0.2589\u001b[0m  0.4074\n",
      "     13        \u001b[36m0.2430\u001b[0m  0.4061\n",
      "     14        \u001b[36m0.2223\u001b[0m  0.4043\n",
      "     15        \u001b[36m0.1970\u001b[0m  0.4057\n",
      "     16        \u001b[36m0.1745\u001b[0m  0.4052\n",
      "     17        \u001b[36m0.1244\u001b[0m  0.4057\n",
      "     18        \u001b[36m0.1106\u001b[0m  0.4048\n",
      "     19        0.1373  0.4056\n",
      "     20        0.1192  0.4054\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6847\u001b[0m  0.4249\n",
      "      2        \u001b[36m0.6699\u001b[0m  0.4207\n",
      "      3        \u001b[36m0.6473\u001b[0m  0.4179\n",
      "      4        \u001b[36m0.6061\u001b[0m  0.4193\n",
      "      5        \u001b[36m0.5781\u001b[0m  0.4189\n",
      "      6        \u001b[36m0.5344\u001b[0m  0.4167\n",
      "      7        \u001b[36m0.4714\u001b[0m  0.4177\n",
      "      8        \u001b[36m0.4382\u001b[0m  0.4172\n",
      "      9        \u001b[36m0.3939\u001b[0m  0.4173\n",
      "     10        \u001b[36m0.3366\u001b[0m  0.4179\n",
      "     11        \u001b[36m0.3361\u001b[0m  0.4195\n",
      "     12        \u001b[36m0.2903\u001b[0m  0.4181\n",
      "     13        \u001b[36m0.2324\u001b[0m  0.4171\n",
      "     14        0.2432  0.4180\n",
      "     15        \u001b[36m0.2208\u001b[0m  0.4169\n",
      "     16        \u001b[36m0.1997\u001b[0m  0.4178\n",
      "     17        \u001b[36m0.1967\u001b[0m  0.4174\n",
      "     18        0.2369  0.4164\n",
      "     19        0.2457  0.4153\n",
      "     20        \u001b[36m0.1734\u001b[0m  0.4173\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6899\u001b[0m  0.4310\n",
      "      2        \u001b[36m0.6847\u001b[0m  0.4258\n",
      "      3        \u001b[36m0.6719\u001b[0m  0.4259\n",
      "      4        \u001b[36m0.6474\u001b[0m  0.4256\n",
      "      5        \u001b[36m0.6128\u001b[0m  0.4247\n",
      "      6        \u001b[36m0.5616\u001b[0m  0.4252\n",
      "      7        \u001b[36m0.5096\u001b[0m  0.4239\n",
      "      8        \u001b[36m0.5014\u001b[0m  0.4220\n",
      "      9        \u001b[36m0.4492\u001b[0m  0.4236\n",
      "     10        \u001b[36m0.4089\u001b[0m  0.4231\n",
      "     11        \u001b[36m0.3940\u001b[0m  0.4238\n",
      "     12        \u001b[36m0.3384\u001b[0m  0.4216\n",
      "     13        \u001b[36m0.3049\u001b[0m  0.4223\n",
      "     14        0.3240  0.4228\n",
      "     15        \u001b[36m0.2923\u001b[0m  0.4228\n",
      "     16        \u001b[36m0.2379\u001b[0m  0.4244\n",
      "     17        \u001b[36m0.2257\u001b[0m  0.4224\n",
      "     18        \u001b[36m0.1858\u001b[0m  0.4204\n",
      "     19        0.2187  0.4224\n",
      "     20        0.2355  0.4243\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6842\u001b[0m  0.4272\n",
      "      2        \u001b[36m0.6537\u001b[0m  0.4214\n",
      "      3        \u001b[36m0.6140\u001b[0m  0.4213\n",
      "      4        \u001b[36m0.5728\u001b[0m  0.4205\n",
      "      5        \u001b[36m0.5358\u001b[0m  0.4205\n",
      "      6        \u001b[36m0.4795\u001b[0m  0.4209\n",
      "      7        \u001b[36m0.4179\u001b[0m  0.4197\n",
      "      8        \u001b[36m0.3718\u001b[0m  0.4197\n",
      "      9        0.3845  0.4199\n",
      "     10        \u001b[36m0.3018\u001b[0m  0.4208\n",
      "     11        \u001b[36m0.2661\u001b[0m  0.4199\n",
      "     12        \u001b[36m0.2519\u001b[0m  0.4206\n",
      "     13        \u001b[36m0.2308\u001b[0m  0.4199\n",
      "     14        \u001b[36m0.2234\u001b[0m  0.4174\n",
      "     15        \u001b[36m0.1995\u001b[0m  0.4185\n",
      "     16        0.2406  0.4188\n",
      "     17        \u001b[36m0.1372\u001b[0m  0.4175\n",
      "     18        \u001b[36m0.1331\u001b[0m  0.4182\n",
      "     19        \u001b[36m0.1217\u001b[0m  0.4188\n",
      "     20        0.1431  0.4179\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6920\u001b[0m  0.4446\n",
      "      2        \u001b[36m0.6895\u001b[0m  0.4407\n",
      "      3        \u001b[36m0.6839\u001b[0m  0.4374\n",
      "      4        \u001b[36m0.6663\u001b[0m  0.4374\n",
      "      5        \u001b[36m0.6353\u001b[0m  0.4363\n",
      "      6        \u001b[36m0.5828\u001b[0m  0.4370\n",
      "      7        0.5830  0.4354\n",
      "      8        \u001b[36m0.5538\u001b[0m  0.4349\n",
      "      9        \u001b[36m0.5315\u001b[0m  0.4359\n",
      "     10        \u001b[36m0.5001\u001b[0m  0.4349\n",
      "     11        0.5280  0.4335\n",
      "     12        \u001b[36m0.4831\u001b[0m  0.4339\n",
      "     13        \u001b[36m0.4482\u001b[0m  0.4370\n",
      "     14        \u001b[36m0.4444\u001b[0m  0.4375\n",
      "     15        0.5173  0.4336\n",
      "     16        \u001b[36m0.4023\u001b[0m  0.4336\n",
      "     17        0.4150  0.4342\n",
      "     18        \u001b[36m0.3783\u001b[0m  0.4345\n",
      "     19        \u001b[36m0.3671\u001b[0m  0.4345\n",
      "     20        \u001b[36m0.3333\u001b[0m  0.4353\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6898\u001b[0m  0.4397\n",
      "      2        \u001b[36m0.6889\u001b[0m  0.4339\n",
      "      3        \u001b[36m0.6770\u001b[0m  0.4340\n",
      "      4        \u001b[36m0.6416\u001b[0m  0.4323\n",
      "      5        \u001b[36m0.6101\u001b[0m  0.4324\n",
      "      6        \u001b[36m0.5771\u001b[0m  0.4317\n",
      "      7        \u001b[36m0.5435\u001b[0m  0.4314\n",
      "      8        \u001b[36m0.5009\u001b[0m  0.4315\n",
      "      9        \u001b[36m0.4752\u001b[0m  0.4319\n",
      "     10        \u001b[36m0.4172\u001b[0m  0.4303\n",
      "     11        \u001b[36m0.3842\u001b[0m  0.4306\n",
      "     12        0.4580  0.4319\n",
      "     13        0.3922  0.4305\n",
      "     14        \u001b[36m0.3522\u001b[0m  0.4304\n",
      "     15        \u001b[36m0.3402\u001b[0m  0.4308\n",
      "     16        0.6118  0.4314\n",
      "     17        0.5919  0.4322\n",
      "     18        0.3586  0.4315\n",
      "     19        \u001b[36m0.2934\u001b[0m  0.4307\n",
      "     20        \u001b[36m0.2678\u001b[0m  0.4298\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6928\u001b[0m  0.4441\n",
      "      2        \u001b[36m0.6904\u001b[0m  0.4375\n",
      "      3        \u001b[36m0.6875\u001b[0m  0.4382\n",
      "      4        \u001b[36m0.6680\u001b[0m  0.4388\n",
      "      5        \u001b[36m0.6323\u001b[0m  0.4374\n",
      "      6        \u001b[36m0.6034\u001b[0m  0.4381\n",
      "      7        \u001b[36m0.5571\u001b[0m  0.4368\n",
      "      8        \u001b[36m0.5325\u001b[0m  0.4365\n",
      "      9        0.5798  0.4351\n",
      "     10        \u001b[36m0.4809\u001b[0m  0.4358\n",
      "     11        \u001b[36m0.4336\u001b[0m  0.4364\n",
      "     12        \u001b[36m0.3951\u001b[0m  0.4349\n",
      "     13        \u001b[36m0.3836\u001b[0m  0.4359\n",
      "     14        \u001b[36m0.3584\u001b[0m  0.4355\n",
      "     15        \u001b[36m0.3183\u001b[0m  0.4365\n",
      "     16        0.3623  0.4365\n",
      "     17        0.3451  0.4358\n",
      "     18        \u001b[36m0.2756\u001b[0m  0.4350\n",
      "     19        0.3094  0.4364\n",
      "     20        0.3081  0.4376\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6913\u001b[0m  0.5103\n",
      "      2        \u001b[36m0.6533\u001b[0m  0.5068\n",
      "      3        \u001b[36m0.6187\u001b[0m  0.5066\n",
      "      4        \u001b[36m0.5799\u001b[0m  0.5087\n",
      "      5        \u001b[36m0.5591\u001b[0m  0.5061\n",
      "      6        \u001b[36m0.5119\u001b[0m  0.5047\n",
      "      7        \u001b[36m0.4715\u001b[0m  0.5079\n",
      "      8        \u001b[36m0.4304\u001b[0m  0.5082\n",
      "      9        \u001b[36m0.3965\u001b[0m  0.5095\n",
      "     10        \u001b[36m0.3348\u001b[0m  0.5076\n",
      "     11        \u001b[36m0.2956\u001b[0m  0.5051\n",
      "     12        \u001b[36m0.2727\u001b[0m  0.5057\n",
      "     13        \u001b[36m0.2411\u001b[0m  0.5046\n",
      "     14        \u001b[36m0.2106\u001b[0m  0.5029\n",
      "     15        \u001b[36m0.1829\u001b[0m  0.5028\n",
      "     16        \u001b[36m0.1781\u001b[0m  0.5010\n",
      "     17        \u001b[36m0.1439\u001b[0m  0.4989\n",
      "     18        \u001b[36m0.1350\u001b[0m  0.4993\n",
      "     19        \u001b[36m0.1183\u001b[0m  0.5015\n",
      "     20        \u001b[36m0.0966\u001b[0m  0.5031\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6872\u001b[0m  0.5076\n",
      "      2        \u001b[36m0.6586\u001b[0m  0.5034\n",
      "      3        \u001b[36m0.6362\u001b[0m  0.5026\n",
      "      4        \u001b[36m0.5962\u001b[0m  0.5008\n",
      "      5        \u001b[36m0.5714\u001b[0m  0.5005\n",
      "      6        \u001b[36m0.5360\u001b[0m  0.5007\n",
      "      7        \u001b[36m0.4892\u001b[0m  0.4998\n",
      "      8        \u001b[36m0.4719\u001b[0m  0.4998\n",
      "      9        \u001b[36m0.4227\u001b[0m  0.4980\n",
      "     10        \u001b[36m0.3817\u001b[0m  0.4970\n",
      "     11        \u001b[36m0.3437\u001b[0m  0.4989\n",
      "     12        \u001b[36m0.2968\u001b[0m  0.4973\n",
      "     13        \u001b[36m0.2702\u001b[0m  0.4973\n",
      "     14        0.2722  0.4972\n",
      "     15        \u001b[36m0.2050\u001b[0m  0.4974\n",
      "     16        \u001b[36m0.1923\u001b[0m  0.4977\n",
      "     17        \u001b[36m0.1667\u001b[0m  0.4973\n",
      "     18        \u001b[36m0.1574\u001b[0m  0.4971\n",
      "     19        \u001b[36m0.1281\u001b[0m  0.4971\n",
      "     20        \u001b[36m0.1166\u001b[0m  0.4984\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6832\u001b[0m  0.5079\n",
      "      2        \u001b[36m0.6440\u001b[0m  0.5032\n",
      "      3        \u001b[36m0.6103\u001b[0m  0.5047\n",
      "      4        \u001b[36m0.5748\u001b[0m  0.5046\n",
      "      5        \u001b[36m0.5412\u001b[0m  0.5017\n",
      "      6        \u001b[36m0.5127\u001b[0m  0.5043\n",
      "      7        \u001b[36m0.4476\u001b[0m  0.5052\n",
      "      8        \u001b[36m0.4346\u001b[0m  0.5006\n",
      "      9        \u001b[36m0.3717\u001b[0m  0.4999\n",
      "     10        0.3901  0.5015\n",
      "     11        \u001b[36m0.3342\u001b[0m  0.5014\n",
      "     12        \u001b[36m0.2967\u001b[0m  0.5021\n",
      "     13        \u001b[36m0.2611\u001b[0m  0.4955\n",
      "     14        \u001b[36m0.2274\u001b[0m  0.4955\n",
      "     15        \u001b[36m0.2256\u001b[0m  0.4950\n",
      "     16        \u001b[36m0.2080\u001b[0m  0.4955\n",
      "     17        \u001b[36m0.2002\u001b[0m  0.4989\n",
      "     18        \u001b[36m0.1626\u001b[0m  0.4977\n",
      "     19        0.1830  0.4975\n",
      "     20        0.1637  0.4945\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6881\u001b[0m  0.5257\n",
      "      2        \u001b[36m0.6608\u001b[0m  0.5221\n",
      "      3        \u001b[36m0.6215\u001b[0m  0.5202\n",
      "      4        \u001b[36m0.6020\u001b[0m  0.5197\n",
      "      5        \u001b[36m0.5497\u001b[0m  0.5210\n",
      "      6        \u001b[36m0.5367\u001b[0m  0.5140\n",
      "      7        \u001b[36m0.5001\u001b[0m  0.5056\n",
      "      8        0.5121  0.5152\n",
      "      9        \u001b[36m0.4408\u001b[0m  0.5168\n",
      "     10        0.4426  0.5175\n",
      "     11        \u001b[36m0.4100\u001b[0m  0.5194\n",
      "     12        \u001b[36m0.3709\u001b[0m  0.5199\n",
      "     13        \u001b[36m0.3503\u001b[0m  0.5155\n",
      "     14        \u001b[36m0.3168\u001b[0m  0.5152\n",
      "     15        \u001b[36m0.2801\u001b[0m  0.5160\n",
      "     16        \u001b[36m0.2597\u001b[0m  0.5212\n",
      "     17        0.2781  0.5186\n",
      "     18        \u001b[36m0.2387\u001b[0m  0.5166\n",
      "     19        \u001b[36m0.1957\u001b[0m  0.5196\n",
      "     20        0.2251  0.5187\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  10.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6812\u001b[0m  0.5289\n",
      "      2        \u001b[36m0.6564\u001b[0m  0.5229\n",
      "      3        \u001b[36m0.6428\u001b[0m  0.5204\n",
      "      4        \u001b[36m0.6065\u001b[0m  0.5204\n",
      "      5        \u001b[36m0.5581\u001b[0m  0.5178\n",
      "      6        \u001b[36m0.5412\u001b[0m  0.5139\n",
      "      7        \u001b[36m0.4702\u001b[0m  0.5180\n",
      "      8        \u001b[36m0.4456\u001b[0m  0.5188\n",
      "      9        0.4686  0.5192\n",
      "     10        \u001b[36m0.3289\u001b[0m  0.5189\n",
      "     11        0.3373  0.5182\n",
      "     12        \u001b[36m0.2910\u001b[0m  0.5156\n",
      "     13        \u001b[36m0.2743\u001b[0m  0.5054\n",
      "     14        0.2967  0.5171\n",
      "     15        \u001b[36m0.2398\u001b[0m  0.5173\n",
      "     16        \u001b[36m0.2102\u001b[0m  0.5186\n",
      "     17        \u001b[36m0.2005\u001b[0m  0.5158\n",
      "     18        \u001b[36m0.1955\u001b[0m  0.5166\n",
      "     19        \u001b[36m0.1880\u001b[0m  0.5164\n",
      "     20        \u001b[36m0.1372\u001b[0m  0.5161\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  10.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6828\u001b[0m  0.5296\n",
      "      2        \u001b[36m0.6444\u001b[0m  0.5197\n",
      "      3        \u001b[36m0.6091\u001b[0m  0.5172\n",
      "      4        \u001b[36m0.5747\u001b[0m  0.5166\n",
      "      5        \u001b[36m0.5468\u001b[0m  0.5158\n",
      "      6        \u001b[36m0.5138\u001b[0m  0.5153\n",
      "      7        \u001b[36m0.5101\u001b[0m  0.5149\n",
      "      8        \u001b[36m0.4489\u001b[0m  0.5178\n",
      "      9        \u001b[36m0.4379\u001b[0m  0.5147\n",
      "     10        \u001b[36m0.3881\u001b[0m  0.5144\n",
      "     11        \u001b[36m0.3684\u001b[0m  0.5142\n",
      "     12        0.3812  0.5148\n",
      "     13        \u001b[36m0.3167\u001b[0m  0.5140\n",
      "     14        \u001b[36m0.2981\u001b[0m  0.5150\n",
      "     15        0.3354  0.5144\n",
      "     16        \u001b[36m0.2632\u001b[0m  0.5157\n",
      "     17        \u001b[36m0.2044\u001b[0m  0.5151\n",
      "     18        0.2368  0.5156\n",
      "     19        \u001b[36m0.1530\u001b[0m  0.5147\n",
      "     20        0.1943  0.5170\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  10.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6957\u001b[0m  0.5595\n",
      "      2        \u001b[36m0.6909\u001b[0m  0.5509\n",
      "      3        \u001b[36m0.6889\u001b[0m  0.5476\n",
      "      4        \u001b[36m0.6778\u001b[0m  0.5461\n",
      "      5        \u001b[36m0.6453\u001b[0m  0.5446\n",
      "      6        \u001b[36m0.6132\u001b[0m  0.5419\n",
      "      7        \u001b[36m0.5562\u001b[0m  0.5426\n",
      "      8        \u001b[36m0.5548\u001b[0m  0.5382\n",
      "      9        \u001b[36m0.5349\u001b[0m  0.5397\n",
      "     10        \u001b[36m0.4780\u001b[0m  0.5375\n",
      "     11        0.4916  0.5397\n",
      "     12        \u001b[36m0.4117\u001b[0m  0.5338\n",
      "     13        \u001b[36m0.3948\u001b[0m  0.5397\n",
      "     14        0.4523  0.5394\n",
      "     15        \u001b[36m0.3849\u001b[0m  0.5393\n",
      "     16        \u001b[36m0.3457\u001b[0m  0.5394\n",
      "     17        \u001b[36m0.3124\u001b[0m  0.5394\n",
      "     18        \u001b[36m0.3092\u001b[0m  0.5414\n",
      "     19        \u001b[36m0.2921\u001b[0m  0.5391\n",
      "     20        \u001b[36m0.2322\u001b[0m  0.5394\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6932\u001b[0m  0.5492\n",
      "      2        \u001b[36m0.6881\u001b[0m  0.5451\n",
      "      3        \u001b[36m0.6601\u001b[0m  0.5399\n",
      "      4        \u001b[36m0.6256\u001b[0m  0.5347\n",
      "      5        \u001b[36m0.5670\u001b[0m  0.5384\n",
      "      6        \u001b[36m0.5099\u001b[0m  0.5386\n",
      "      7        \u001b[36m0.4642\u001b[0m  0.5406\n",
      "      8        0.4767  0.5427\n",
      "      9        \u001b[36m0.4168\u001b[0m  0.5408\n",
      "     10        0.4846  0.5431\n",
      "     11        \u001b[36m0.3925\u001b[0m  0.5402\n",
      "     12        \u001b[36m0.3596\u001b[0m  0.5390\n",
      "     13        \u001b[36m0.3279\u001b[0m  0.5391\n",
      "     14        0.3404  0.5396\n",
      "     15        \u001b[36m0.2797\u001b[0m  0.5388\n",
      "     16        \u001b[36m0.2729\u001b[0m  0.5374\n",
      "     17        \u001b[36m0.2271\u001b[0m  0.5392\n",
      "     18        0.2340  0.5389\n",
      "     19        0.2290  0.5394\n",
      "     20        \u001b[36m0.1992\u001b[0m  0.5391\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6911\u001b[0m  0.5464\n",
      "      2        \u001b[36m0.6767\u001b[0m  0.5430\n",
      "      3        \u001b[36m0.6387\u001b[0m  0.5424\n",
      "      4        \u001b[36m0.6032\u001b[0m  0.5424\n",
      "      5        \u001b[36m0.5672\u001b[0m  0.5405\n",
      "      6        \u001b[36m0.5607\u001b[0m  0.5401\n",
      "      7        \u001b[36m0.5138\u001b[0m  0.5382\n",
      "      8        \u001b[36m0.4927\u001b[0m  0.5408\n",
      "      9        \u001b[36m0.4381\u001b[0m  0.5346\n",
      "     10        \u001b[36m0.3888\u001b[0m  0.5349\n",
      "     11        0.3907  0.5350\n",
      "     12        \u001b[36m0.3543\u001b[0m  0.5368\n",
      "     13        0.4366  0.5389\n",
      "     14        0.4096  0.5380\n",
      "     15        \u001b[36m0.3013\u001b[0m  0.5396\n",
      "     16        \u001b[36m0.2454\u001b[0m  0.5407\n",
      "     17        \u001b[36m0.2332\u001b[0m  0.5425\n",
      "     18        0.2394  0.5398\n",
      "     19        \u001b[36m0.1927\u001b[0m  0.5381\n",
      "     20        0.1992  0.5402\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7262\u001b[0m  0.7722\n",
      "      2        \u001b[36m0.6683\u001b[0m  0.7645\n",
      "      3        \u001b[36m0.6373\u001b[0m  0.7621\n",
      "      4        \u001b[36m0.6086\u001b[0m  0.7613\n",
      "      5        \u001b[36m0.5860\u001b[0m  0.7619\n",
      "      6        \u001b[36m0.5483\u001b[0m  0.7605\n",
      "      7        \u001b[36m0.5173\u001b[0m  0.7622\n",
      "      8        \u001b[36m0.4751\u001b[0m  0.7607\n",
      "      9        \u001b[36m0.4468\u001b[0m  0.7599\n",
      "     10        \u001b[36m0.3744\u001b[0m  0.7600\n",
      "     11        \u001b[36m0.3510\u001b[0m  0.7587\n",
      "     12        \u001b[36m0.3387\u001b[0m  0.7589\n",
      "     13        \u001b[36m0.2826\u001b[0m  0.7591\n",
      "     14        \u001b[36m0.2800\u001b[0m  0.7588\n",
      "     15        \u001b[36m0.2377\u001b[0m  0.7586\n",
      "     16        \u001b[36m0.2149\u001b[0m  0.7570\n",
      "     17        \u001b[36m0.1841\u001b[0m  0.7576\n",
      "     18        \u001b[36m0.1695\u001b[0m  0.7581\n",
      "     19        \u001b[36m0.1365\u001b[0m  0.7509\n",
      "     20        0.1430  0.7502\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  15.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7428\u001b[0m  0.7798\n",
      "      2        \u001b[36m0.6802\u001b[0m  0.7710\n",
      "      3        \u001b[36m0.6641\u001b[0m  0.7726\n",
      "      4        \u001b[36m0.6374\u001b[0m  0.7707\n",
      "      5        \u001b[36m0.6023\u001b[0m  0.7683\n",
      "      6        \u001b[36m0.5718\u001b[0m  0.7654\n",
      "      7        \u001b[36m0.5389\u001b[0m  0.7637\n",
      "      8        \u001b[36m0.4970\u001b[0m  0.7619\n",
      "      9        \u001b[36m0.4564\u001b[0m  0.7601\n",
      "     10        \u001b[36m0.4406\u001b[0m  0.7608\n",
      "     11        \u001b[36m0.3773\u001b[0m  0.7602\n",
      "     12        \u001b[36m0.3286\u001b[0m  0.7577\n",
      "     13        \u001b[36m0.2900\u001b[0m  0.7566\n",
      "     14        \u001b[36m0.2836\u001b[0m  0.7572\n",
      "     15        \u001b[36m0.2275\u001b[0m  0.7565\n",
      "     16        0.2435  0.7563\n",
      "     17        \u001b[36m0.1998\u001b[0m  0.7567\n",
      "     18        \u001b[36m0.1837\u001b[0m  0.7493\n",
      "     19        \u001b[36m0.1558\u001b[0m  0.7504\n",
      "     20        \u001b[36m0.1442\u001b[0m  0.7495\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  15.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7813\u001b[0m  0.7850\n",
      "      2        \u001b[36m0.6752\u001b[0m  0.7755\n",
      "      3        \u001b[36m0.6467\u001b[0m  0.7736\n",
      "      4        \u001b[36m0.6131\u001b[0m  0.7724\n",
      "      5        \u001b[36m0.5805\u001b[0m  0.7702\n",
      "      6        \u001b[36m0.5317\u001b[0m  0.7672\n",
      "      7        \u001b[36m0.5111\u001b[0m  0.7655\n",
      "      8        \u001b[36m0.4318\u001b[0m  0.7637\n",
      "      9        \u001b[36m0.4083\u001b[0m  0.7644\n",
      "     10        \u001b[36m0.3856\u001b[0m  0.7619\n",
      "     11        \u001b[36m0.3338\u001b[0m  0.7605\n",
      "     12        \u001b[36m0.2944\u001b[0m  0.7608\n",
      "     13        \u001b[36m0.2612\u001b[0m  0.7598\n",
      "     14        \u001b[36m0.2204\u001b[0m  0.7591\n",
      "     15        \u001b[36m0.2137\u001b[0m  0.7573\n",
      "     16        \u001b[36m0.2044\u001b[0m  0.7576\n",
      "     17        \u001b[36m0.2021\u001b[0m  0.7572\n",
      "     18        \u001b[36m0.1656\u001b[0m  0.7581\n",
      "     19        \u001b[36m0.1424\u001b[0m  0.7596\n",
      "     20        0.1432  0.7574\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  15.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6868\u001b[0m  0.8086\n",
      "      2        \u001b[36m0.6431\u001b[0m  0.7899\n",
      "      3        \u001b[36m0.5874\u001b[0m  0.7873\n",
      "      4        \u001b[36m0.5481\u001b[0m  0.7836\n",
      "      5        \u001b[36m0.4756\u001b[0m  0.7870\n",
      "      6        \u001b[36m0.4107\u001b[0m  0.7820\n",
      "      7        \u001b[36m0.3972\u001b[0m  0.7814\n",
      "      8        \u001b[36m0.3908\u001b[0m  0.7802\n",
      "      9        0.4184  0.7854\n",
      "     10        \u001b[36m0.3563\u001b[0m  0.7809\n",
      "     11        \u001b[36m0.3169\u001b[0m  0.7817\n",
      "     12        \u001b[36m0.2628\u001b[0m  0.7822\n",
      "     13        \u001b[36m0.2346\u001b[0m  0.7804\n",
      "     14        \u001b[36m0.1968\u001b[0m  0.7742\n",
      "     15        \u001b[36m0.1721\u001b[0m  0.7742\n",
      "     16        0.1858  0.7767\n",
      "     17        0.3104  0.7760\n",
      "     18        \u001b[36m0.1524\u001b[0m  0.7760\n",
      "     19        \u001b[36m0.1325\u001b[0m  0.7759\n",
      "     20        0.1387  0.7762\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  15.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6928\u001b[0m  0.8009\n",
      "      2        \u001b[36m0.6587\u001b[0m  0.7923\n",
      "      3        \u001b[36m0.6167\u001b[0m  0.7822\n",
      "      4        \u001b[36m0.5883\u001b[0m  0.7792\n",
      "      5        \u001b[36m0.5503\u001b[0m  0.7839\n",
      "      6        \u001b[36m0.5034\u001b[0m  0.7832\n",
      "      7        0.5333  0.7824\n",
      "      8        \u001b[36m0.4908\u001b[0m  0.7834\n",
      "      9        \u001b[36m0.4597\u001b[0m  0.7838\n",
      "     10        \u001b[36m0.4273\u001b[0m  0.7810\n",
      "     11        0.4295  0.7821\n",
      "     12        \u001b[36m0.3834\u001b[0m  0.7816\n",
      "     13        \u001b[36m0.3295\u001b[0m  0.7821\n",
      "     14        0.3301  0.7813\n",
      "     15        \u001b[36m0.3152\u001b[0m  0.7816\n",
      "     16        \u001b[36m0.2944\u001b[0m  0.7747\n",
      "     17        \u001b[36m0.2608\u001b[0m  0.7760\n",
      "     18        \u001b[36m0.2431\u001b[0m  0.7753\n",
      "     19        0.2452  0.7758\n",
      "     20        0.2494  0.7759\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  15.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6925\u001b[0m  0.8124\n",
      "      2        \u001b[36m0.6630\u001b[0m  0.7919\n",
      "      3        \u001b[36m0.6212\u001b[0m  0.7909\n",
      "      4        \u001b[36m0.5750\u001b[0m  0.7928\n",
      "      5        \u001b[36m0.5361\u001b[0m  0.7858\n",
      "      6        \u001b[36m0.5077\u001b[0m  0.7852\n",
      "      7        \u001b[36m0.4686\u001b[0m  0.7852\n",
      "      8        \u001b[36m0.4141\u001b[0m  0.7841\n",
      "      9        0.4522  0.7846\n",
      "     10        0.5441  0.7850\n",
      "     11        0.4790  0.7846\n",
      "     12        0.4665  0.7837\n",
      "     13        0.4550  0.7781\n",
      "     14        \u001b[36m0.3449\u001b[0m  0.7776\n",
      "     15        \u001b[36m0.3091\u001b[0m  0.7778\n",
      "     16        0.3232  0.7782\n",
      "     17        \u001b[36m0.2647\u001b[0m  0.7789\n",
      "     18        \u001b[36m0.2255\u001b[0m  0.7783\n",
      "     19        \u001b[36m0.1874\u001b[0m  0.7786\n",
      "     20        \u001b[36m0.1697\u001b[0m  0.7796\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  15.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6938\u001b[0m  0.8400\n",
      "      2        \u001b[36m0.6807\u001b[0m  0.8227\n",
      "      3        \u001b[36m0.6467\u001b[0m  0.8152\n",
      "      4        \u001b[36m0.6004\u001b[0m  0.8115\n",
      "      5        \u001b[36m0.5805\u001b[0m  0.8043\n",
      "      6        \u001b[36m0.5636\u001b[0m  0.8035\n",
      "      7        \u001b[36m0.5520\u001b[0m  0.8052\n",
      "      8        \u001b[36m0.5337\u001b[0m  0.8055\n",
      "      9        \u001b[36m0.5017\u001b[0m  0.8047\n",
      "     10        \u001b[36m0.4930\u001b[0m  0.8045\n",
      "     11        \u001b[36m0.4317\u001b[0m  0.8040\n",
      "     12        0.4323  0.8045\n",
      "     13        \u001b[36m0.3933\u001b[0m  0.8049\n",
      "     14        0.4015  0.8049\n",
      "     15        \u001b[36m0.3595\u001b[0m  0.8053\n",
      "     16        \u001b[36m0.3193\u001b[0m  0.8039\n",
      "     17        0.3409  0.8080\n",
      "     18        \u001b[36m0.3019\u001b[0m  0.8050\n",
      "     19        \u001b[36m0.2808\u001b[0m  0.8045\n",
      "     20        \u001b[36m0.2725\u001b[0m  0.8057\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  16.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6954\u001b[0m  0.8345\n",
      "      2        \u001b[36m0.6731\u001b[0m  0.8136\n",
      "      3        \u001b[36m0.6415\u001b[0m  0.8100\n",
      "      4        \u001b[36m0.6098\u001b[0m  0.8067\n",
      "      5        \u001b[36m0.5845\u001b[0m  0.8093\n",
      "      6        \u001b[36m0.5302\u001b[0m  0.8068\n",
      "      7        \u001b[36m0.4958\u001b[0m  0.8069\n",
      "      8        \u001b[36m0.4509\u001b[0m  0.8070\n",
      "      9        \u001b[36m0.4366\u001b[0m  0.8065\n",
      "     10        0.4704  0.8050\n",
      "     11        0.4497  0.8057\n",
      "     12        \u001b[36m0.3968\u001b[0m  0.8061\n",
      "     13        \u001b[36m0.3528\u001b[0m  0.8053\n",
      "     14        \u001b[36m0.3202\u001b[0m  0.8051\n",
      "     15        \u001b[36m0.2741\u001b[0m  0.8056\n",
      "     16        0.3202  0.8045\n",
      "     17        0.2963  0.8032\n",
      "     18        \u001b[36m0.2420\u001b[0m  0.8043\n",
      "     19        \u001b[36m0.2209\u001b[0m  0.8038\n",
      "     20        \u001b[36m0.2074\u001b[0m  0.8029\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  16.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6957\u001b[0m  0.8308\n",
      "      2        \u001b[36m0.6791\u001b[0m  0.8136\n",
      "      3        \u001b[36m0.6319\u001b[0m  0.8094\n",
      "      4        \u001b[36m0.5985\u001b[0m  0.8064\n",
      "      5        \u001b[36m0.5582\u001b[0m  0.8085\n",
      "      6        \u001b[36m0.5470\u001b[0m  0.8075\n",
      "      7        \u001b[36m0.5390\u001b[0m  0.8070\n",
      "      8        \u001b[36m0.5078\u001b[0m  0.8056\n",
      "      9        \u001b[36m0.4770\u001b[0m  0.8057\n",
      "     10        \u001b[36m0.4693\u001b[0m  0.8056\n",
      "     11        \u001b[36m0.4358\u001b[0m  0.8048\n",
      "     12        0.5436  0.8054\n",
      "     13        0.5728  0.8054\n",
      "     14        \u001b[36m0.4180\u001b[0m  0.8046\n",
      "     15        \u001b[36m0.4000\u001b[0m  0.8041\n",
      "     16        \u001b[36m0.3572\u001b[0m  0.8041\n",
      "     17        0.3833  0.8037\n",
      "     18        \u001b[36m0.2937\u001b[0m  0.8055\n",
      "     19        \u001b[36m0.2751\u001b[0m  0.8053\n",
      "     20        0.3775  0.8041\n",
      "[CV] END lr=0.001, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  16.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6887\u001b[0m  0.4146\n",
      "      2        \u001b[36m0.6614\u001b[0m  0.4138\n",
      "      3        \u001b[36m0.6582\u001b[0m  0.4132\n",
      "      4        0.6597  0.4125\n",
      "      5        0.6638  0.4122\n",
      "      6        0.6643  0.4131\n",
      "      7        0.6626  0.4116\n",
      "      8        \u001b[36m0.6467\u001b[0m  0.4121\n",
      "      9        \u001b[36m0.6147\u001b[0m  0.4124\n",
      "     10        \u001b[36m0.5932\u001b[0m  0.4129\n",
      "     11        \u001b[36m0.5715\u001b[0m  0.4113\n",
      "     12        0.5789  0.4123\n",
      "     13        0.5738  0.4120\n",
      "     14        \u001b[36m0.5342\u001b[0m  0.4117\n",
      "     15        \u001b[36m0.4934\u001b[0m  0.4111\n",
      "     16        0.5652  0.4119\n",
      "     17        0.5946  0.4097\n",
      "     18        0.5366  0.4109\n",
      "     19        0.5204  0.4134\n",
      "     20        \u001b[36m0.4616\u001b[0m  0.4108\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6812\u001b[0m  0.4165\n",
      "      2        \u001b[36m0.6725\u001b[0m  0.4123\n",
      "      3        \u001b[36m0.6689\u001b[0m  0.4103\n",
      "      4        \u001b[36m0.6607\u001b[0m  0.4107\n",
      "      5        0.6609  0.4095\n",
      "      6        \u001b[36m0.6567\u001b[0m  0.4104\n",
      "      7        \u001b[36m0.6161\u001b[0m  0.4085\n",
      "      8        0.6270  0.4094\n",
      "      9        \u001b[36m0.5949\u001b[0m  0.4100\n",
      "     10        0.6236  0.4097\n",
      "     11        \u001b[36m0.5873\u001b[0m  0.4091\n",
      "     12        \u001b[36m0.5633\u001b[0m  0.4076\n",
      "     13        \u001b[36m0.5418\u001b[0m  0.4067\n",
      "     14        \u001b[36m0.5046\u001b[0m  0.4072\n",
      "     15        \u001b[36m0.4903\u001b[0m  0.4079\n",
      "     16        \u001b[36m0.4603\u001b[0m  0.4090\n",
      "     17        \u001b[36m0.4492\u001b[0m  0.4082\n",
      "     18        0.4800  0.4092\n",
      "     19        \u001b[36m0.4128\u001b[0m  0.4062\n",
      "     20        \u001b[36m0.4088\u001b[0m  0.4078\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6825\u001b[0m  0.4177\n",
      "      2        \u001b[36m0.6627\u001b[0m  0.4115\n",
      "      3        \u001b[36m0.6507\u001b[0m  0.4098\n",
      "      4        \u001b[36m0.6411\u001b[0m  0.4103\n",
      "      5        \u001b[36m0.6226\u001b[0m  0.4085\n",
      "      6        \u001b[36m0.5896\u001b[0m  0.4085\n",
      "      7        \u001b[36m0.5672\u001b[0m  0.4074\n",
      "      8        \u001b[36m0.5435\u001b[0m  0.4063\n",
      "      9        0.5523  0.4078\n",
      "     10        \u001b[36m0.5062\u001b[0m  0.4069\n",
      "     11        \u001b[36m0.4856\u001b[0m  0.4064\n",
      "     12        \u001b[36m0.4276\u001b[0m  0.4070\n",
      "     13        \u001b[36m0.4044\u001b[0m  0.4060\n",
      "     14        0.4369  0.4077\n",
      "     15        \u001b[36m0.3781\u001b[0m  0.4073\n",
      "     16        0.3828  0.4072\n",
      "     17        \u001b[36m0.3549\u001b[0m  0.4087\n",
      "     18        \u001b[36m0.3175\u001b[0m  0.4072\n",
      "     19        0.3713  0.4077\n",
      "     20        0.3497  0.4072\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7018\u001b[0m  0.4336\n",
      "      2        \u001b[36m0.6935\u001b[0m  0.4303\n",
      "      3        \u001b[36m0.6881\u001b[0m  0.4295\n",
      "      4        0.6887  0.4303\n",
      "      5        \u001b[36m0.6640\u001b[0m  0.4291\n",
      "      6        0.6677  0.4292\n",
      "      7        0.6801  0.4294\n",
      "      8        \u001b[36m0.6538\u001b[0m  0.4277\n",
      "      9        \u001b[36m0.6457\u001b[0m  0.4266\n",
      "     10        \u001b[36m0.6214\u001b[0m  0.4260\n",
      "     11        0.6256  0.4253\n",
      "     12        \u001b[36m0.6050\u001b[0m  0.4245\n",
      "     13        0.6370  0.4256\n",
      "     14        0.6659  0.4255\n",
      "     15        0.6324  0.4278\n",
      "     16        0.6248  0.4261\n",
      "     17        0.6336  0.4258\n",
      "     18        0.6168  0.4238\n",
      "     19        \u001b[36m0.5758\u001b[0m  0.4233\n",
      "     20        \u001b[36m0.5486\u001b[0m  0.4223\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6932\u001b[0m  0.4332\n",
      "      2        \u001b[36m0.6833\u001b[0m  0.4294\n",
      "      3        \u001b[36m0.6787\u001b[0m  0.4263\n",
      "      4        \u001b[36m0.6674\u001b[0m  0.4249\n",
      "      5        0.6745  0.4267\n",
      "      6        \u001b[36m0.6657\u001b[0m  0.4260\n",
      "      7        0.6665  0.4246\n",
      "      8        0.6731  0.4243\n",
      "      9        \u001b[36m0.6647\u001b[0m  0.4238\n",
      "     10        \u001b[36m0.6420\u001b[0m  0.4242\n",
      "     11        \u001b[36m0.6394\u001b[0m  0.4256\n",
      "     12        \u001b[36m0.6159\u001b[0m  0.4238\n",
      "     13        0.6684  0.4238\n",
      "     14        0.6466  0.4242\n",
      "     15        0.6425  0.4242\n",
      "     16        0.6470  0.4221\n",
      "     17        0.6245  0.4228\n",
      "     18        0.6192  0.4214\n",
      "     19        \u001b[36m0.6127\u001b[0m  0.4219\n",
      "     20        \u001b[36m0.5773\u001b[0m  0.4231\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6846\u001b[0m  0.4316\n",
      "      2        \u001b[36m0.6618\u001b[0m  0.4270\n",
      "      3        \u001b[36m0.6569\u001b[0m  0.4256\n",
      "      4        \u001b[36m0.6339\u001b[0m  0.4263\n",
      "      5        \u001b[36m0.6299\u001b[0m  0.4240\n",
      "      6        \u001b[36m0.5981\u001b[0m  0.4240\n",
      "      7        \u001b[36m0.5779\u001b[0m  0.4227\n",
      "      8        \u001b[36m0.5495\u001b[0m  0.4238\n",
      "      9        \u001b[36m0.5429\u001b[0m  0.4223\n",
      "     10        \u001b[36m0.5262\u001b[0m  0.4236\n",
      "     11        \u001b[36m0.4802\u001b[0m  0.4222\n",
      "     12        \u001b[36m0.4598\u001b[0m  0.4217\n",
      "     13        \u001b[36m0.4351\u001b[0m  0.4240\n",
      "     14        \u001b[36m0.4020\u001b[0m  0.4239\n",
      "     15        0.4136  0.4251\n",
      "     16        0.4246  0.4238\n",
      "     17        0.4112  0.4219\n",
      "     18        \u001b[36m0.3952\u001b[0m  0.4193\n",
      "     19        \u001b[36m0.3814\u001b[0m  0.4210\n",
      "     20        0.4215  0.4205\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6896\u001b[0m  0.4416\n",
      "      2        \u001b[36m0.6826\u001b[0m  0.4402\n",
      "      3        \u001b[36m0.6765\u001b[0m  0.4411\n",
      "      4        0.6804  0.4396\n",
      "      5        \u001b[36m0.6694\u001b[0m  0.4388\n",
      "      6        \u001b[36m0.6537\u001b[0m  0.4392\n",
      "      7        \u001b[36m0.6225\u001b[0m  0.4379\n",
      "      8        0.6526  0.4380\n",
      "      9        0.6733  0.4385\n",
      "     10        0.6714  0.4379\n",
      "     11        0.6719  0.4388\n",
      "     12        0.6603  0.4389\n",
      "     13        0.6797  0.4362\n",
      "     14        0.6766  0.4366\n",
      "     15        0.6724  0.4376\n",
      "     16        0.6530  0.4352\n",
      "     17        0.6675  0.4431\n",
      "     18        0.6513  0.4394\n",
      "     19        0.6405  0.4361\n",
      "     20        0.6245  0.4386\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6853\u001b[0m  0.4420\n",
      "      2        \u001b[36m0.6713\u001b[0m  0.4390\n",
      "      3        \u001b[36m0.6660\u001b[0m  0.4371\n",
      "      4        \u001b[36m0.6405\u001b[0m  0.4377\n",
      "      5        0.6504  0.4365\n",
      "      6        0.6665  0.4366\n",
      "      7        0.6780  0.4369\n",
      "      8        0.6594  0.4355\n",
      "      9        0.6475  0.4363\n",
      "     10        0.6690  0.4369\n",
      "     11        0.6652  0.4346\n",
      "     12        0.6531  0.4362\n",
      "     13        0.6518  0.4341\n",
      "     14        0.6494  0.4339\n",
      "     15        0.6530  0.4335\n",
      "     16        \u001b[36m0.6289\u001b[0m  0.4350\n",
      "     17        0.6573  0.4339\n",
      "     18        0.6412  0.4346\n",
      "     19        0.6332  0.4349\n",
      "     20        0.6350  0.4341\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6877\u001b[0m  0.4451\n",
      "      2        \u001b[36m0.6826\u001b[0m  0.4407\n",
      "      3        \u001b[36m0.6652\u001b[0m  0.4393\n",
      "      4        \u001b[36m0.6558\u001b[0m  0.4409\n",
      "      5        0.6643  0.4390\n",
      "      6        0.6618  0.4372\n",
      "      7        \u001b[36m0.6455\u001b[0m  0.4373\n",
      "      8        \u001b[36m0.6308\u001b[0m  0.4392\n",
      "      9        0.6470  0.4363\n",
      "     10        \u001b[36m0.6255\u001b[0m  0.4351\n",
      "     11        \u001b[36m0.5922\u001b[0m  0.4355\n",
      "     12        0.6415  0.4354\n",
      "     13        0.6131  0.4344\n",
      "     14        0.6437  0.4359\n",
      "     15        0.6259  0.4369\n",
      "     16        \u001b[36m0.5844\u001b[0m  0.4347\n",
      "     17        0.5856  0.4347\n",
      "     18        0.6058  0.4352\n",
      "     19        \u001b[36m0.5752\u001b[0m  0.4338\n",
      "     20        \u001b[36m0.5570\u001b[0m  0.4347\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8001\u001b[0m  0.5158\n",
      "      2        \u001b[36m0.6863\u001b[0m  0.5171\n",
      "      3        \u001b[36m0.6858\u001b[0m  0.5141\n",
      "      4        \u001b[36m0.6753\u001b[0m  0.5140\n",
      "      5        \u001b[36m0.6739\u001b[0m  0.5124\n",
      "      6        \u001b[36m0.6603\u001b[0m  0.5096\n",
      "      7        \u001b[36m0.6384\u001b[0m  0.5094\n",
      "      8        \u001b[36m0.6297\u001b[0m  0.5088\n",
      "      9        \u001b[36m0.6295\u001b[0m  0.5070\n",
      "     10        \u001b[36m0.6207\u001b[0m  0.5037\n",
      "     11        \u001b[36m0.6144\u001b[0m  0.5039\n",
      "     12        \u001b[36m0.5867\u001b[0m  0.5035\n",
      "     13        \u001b[36m0.5860\u001b[0m  0.5025\n",
      "     14        0.6209  0.5009\n",
      "     15        0.6067  0.5029\n",
      "     16        \u001b[36m0.5737\u001b[0m  0.5052\n",
      "     17        \u001b[36m0.5639\u001b[0m  0.5041\n",
      "     18        0.5673  0.5043\n",
      "     19        \u001b[36m0.5609\u001b[0m  0.5033\n",
      "     20        \u001b[36m0.5332\u001b[0m  0.5030\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6896\u001b[0m  0.5143\n",
      "      2        \u001b[36m0.6706\u001b[0m  0.5077\n",
      "      3        0.6744  0.5089\n",
      "      4        \u001b[36m0.6538\u001b[0m  0.5077\n",
      "      5        \u001b[36m0.6412\u001b[0m  0.5066\n",
      "      6        0.6577  0.5113\n",
      "      7        \u001b[36m0.6374\u001b[0m  0.5047\n",
      "      8        \u001b[36m0.6372\u001b[0m  0.5039\n",
      "      9        \u001b[36m0.6149\u001b[0m  0.5029\n",
      "     10        0.6227  0.5013\n",
      "     11        \u001b[36m0.6113\u001b[0m  0.5118\n",
      "     12        0.6130  0.5025\n",
      "     13        \u001b[36m0.5952\u001b[0m  0.5011\n",
      "     14        \u001b[36m0.5807\u001b[0m  0.5016\n",
      "     15        \u001b[36m0.5482\u001b[0m  0.5014\n",
      "     16        0.5550  0.5016\n",
      "     17        \u001b[36m0.5170\u001b[0m  0.5014\n",
      "     18        0.5196  0.5004\n",
      "     19        \u001b[36m0.4939\u001b[0m  0.5009\n",
      "     20        0.5042  0.5002\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6861\u001b[0m  0.5147\n",
      "      2        \u001b[36m0.6699\u001b[0m  0.5067\n",
      "      3        \u001b[36m0.6515\u001b[0m  0.5077\n",
      "      4        \u001b[36m0.6436\u001b[0m  0.5095\n",
      "      5        \u001b[36m0.6227\u001b[0m  0.5121\n",
      "      6        \u001b[36m0.6171\u001b[0m  0.5090\n",
      "      7        \u001b[36m0.5899\u001b[0m  0.5086\n",
      "      8        \u001b[36m0.5835\u001b[0m  0.5069\n",
      "      9        0.6152  0.5071\n",
      "     10        \u001b[36m0.5424\u001b[0m  0.5061\n",
      "     11        0.5538  0.5058\n",
      "     12        0.5572  0.5053\n",
      "     13        \u001b[36m0.5289\u001b[0m  0.5053\n",
      "     14        0.5438  0.5032\n",
      "     15        \u001b[36m0.5016\u001b[0m  0.5029\n",
      "     16        \u001b[36m0.4212\u001b[0m  0.4995\n",
      "     17        0.4245  0.4998\n",
      "     18        \u001b[36m0.4134\u001b[0m  0.4969\n",
      "     19        \u001b[36m0.4032\u001b[0m  0.5008\n",
      "     20        0.4086  0.5001\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7011\u001b[0m  0.5310\n",
      "      2        \u001b[36m0.6911\u001b[0m  0.5260\n",
      "      3        \u001b[36m0.6902\u001b[0m  0.5271\n",
      "      4        \u001b[36m0.6895\u001b[0m  0.5264\n",
      "      5        \u001b[36m0.6806\u001b[0m  0.5243\n",
      "      6        \u001b[36m0.6654\u001b[0m  0.5224\n",
      "      7        \u001b[36m0.6621\u001b[0m  0.5205\n",
      "      8        \u001b[36m0.6576\u001b[0m  0.5192\n",
      "      9        0.6590  0.5179\n",
      "     10        \u001b[36m0.6525\u001b[0m  0.5173\n",
      "     11        0.6626  0.5161\n",
      "     12        0.6558  0.5163\n",
      "     13        \u001b[36m0.6514\u001b[0m  0.5163\n",
      "     14        0.6682  0.5158\n",
      "     15        \u001b[36m0.6342\u001b[0m  0.5151\n",
      "     16        \u001b[36m0.6247\u001b[0m  0.5168\n",
      "     17        0.6386  0.5162\n",
      "     18        0.6348  0.5172\n",
      "     19        0.6269  0.5170\n",
      "     20        \u001b[36m0.6107\u001b[0m  0.5174\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6916\u001b[0m  0.5312\n",
      "      2        \u001b[36m0.6884\u001b[0m  0.5260\n",
      "      3        \u001b[36m0.6800\u001b[0m  0.5295\n",
      "      4        \u001b[36m0.6654\u001b[0m  0.5257\n",
      "      5        \u001b[36m0.6587\u001b[0m  0.5278\n",
      "      6        \u001b[36m0.6445\u001b[0m  0.5234\n",
      "      7        0.6545  0.5223\n",
      "      8        0.6458  0.5209\n",
      "      9        \u001b[36m0.6191\u001b[0m  0.5192\n",
      "     10        0.6459  0.5213\n",
      "     11        0.6436  0.5211\n",
      "     12        \u001b[36m0.6041\u001b[0m  0.5219\n",
      "     13        0.6408  0.5182\n",
      "     14        0.6755  0.5183\n",
      "     15        0.6625  0.5202\n",
      "     16        0.6489  0.5203\n",
      "     17        \u001b[36m0.5827\u001b[0m  0.5213\n",
      "     18        0.5943  0.5199\n",
      "     19        0.5966  0.5163\n",
      "     20        \u001b[36m0.5505\u001b[0m  0.5163\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6966\u001b[0m  0.5301\n",
      "      2        \u001b[36m0.6829\u001b[0m  0.5263\n",
      "      3        \u001b[36m0.6749\u001b[0m  0.5262\n",
      "      4        \u001b[36m0.6633\u001b[0m  0.5239\n",
      "      5        \u001b[36m0.6618\u001b[0m  0.5238\n",
      "      6        \u001b[36m0.6519\u001b[0m  0.5221\n",
      "      7        \u001b[36m0.6440\u001b[0m  0.5211\n",
      "      8        \u001b[36m0.6082\u001b[0m  0.5201\n",
      "      9        \u001b[36m0.5800\u001b[0m  0.5227\n",
      "     10        0.6238  0.5185\n",
      "     11        0.5806  0.5176\n",
      "     12        \u001b[36m0.5573\u001b[0m  0.5176\n",
      "     13        \u001b[36m0.5311\u001b[0m  0.5176\n",
      "     14        0.5414  0.5173\n",
      "     15        \u001b[36m0.5144\u001b[0m  0.5164\n",
      "     16        \u001b[36m0.4673\u001b[0m  0.5161\n",
      "     17        0.4673  0.5161\n",
      "     18        0.5016  0.5160\n",
      "     19        \u001b[36m0.4558\u001b[0m  0.5153\n",
      "     20        \u001b[36m0.4370\u001b[0m  0.5154\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6936\u001b[0m  0.5518\n",
      "      2        \u001b[36m0.6898\u001b[0m  0.5477\n",
      "      3        \u001b[36m0.6819\u001b[0m  0.5459\n",
      "      4        0.6867  0.5485\n",
      "      5        \u001b[36m0.6723\u001b[0m  0.5472\n",
      "      6        0.6731  0.5474\n",
      "      7        \u001b[36m0.6628\u001b[0m  0.5427\n",
      "      8        \u001b[36m0.6427\u001b[0m  0.5408\n",
      "      9        0.6434  0.5415\n",
      "     10        0.6693  0.5396\n",
      "     11        0.6606  0.5411\n",
      "     12        \u001b[36m0.6362\u001b[0m  0.5387\n",
      "     13        \u001b[36m0.6278\u001b[0m  0.5373\n",
      "     14        0.6490  0.5407\n",
      "     15        \u001b[36m0.6048\u001b[0m  0.5411\n",
      "     16        \u001b[36m0.5925\u001b[0m  0.5405\n",
      "     17        \u001b[36m0.5908\u001b[0m  0.5391\n",
      "     18        \u001b[36m0.5653\u001b[0m  0.5370\n",
      "     19        \u001b[36m0.5390\u001b[0m  0.5375\n",
      "     20        \u001b[36m0.5328\u001b[0m  0.5368\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6908\u001b[0m  0.5514\n",
      "      2        \u001b[36m0.6828\u001b[0m  0.5470\n",
      "      3        0.6913  0.5469\n",
      "      4        \u001b[36m0.6791\u001b[0m  0.5435\n",
      "      5        \u001b[36m0.6651\u001b[0m  0.5457\n",
      "      6        \u001b[36m0.6629\u001b[0m  0.5415\n",
      "      7        \u001b[36m0.6455\u001b[0m  0.5407\n",
      "      8        0.6598  0.5397\n",
      "      9        0.6635  0.5381\n",
      "     10        0.6499  0.5365\n",
      "     11        0.6609  0.5375\n",
      "     12        0.6525  0.5365\n",
      "     13        0.6458  0.5387\n",
      "     14        \u001b[36m0.6318\u001b[0m  0.5364\n",
      "     15        \u001b[36m0.6118\u001b[0m  0.5408\n",
      "     16        \u001b[36m0.6093\u001b[0m  0.5393\n",
      "     17        \u001b[36m0.5985\u001b[0m  0.5374\n",
      "     18        \u001b[36m0.5611\u001b[0m  0.5370\n",
      "     19        0.5650  0.5349\n",
      "     20        0.6007  0.5366\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6930\u001b[0m  0.5511\n",
      "      2        \u001b[36m0.6705\u001b[0m  0.5446\n",
      "      3        \u001b[36m0.6626\u001b[0m  0.5437\n",
      "      4        \u001b[36m0.6568\u001b[0m  0.5435\n",
      "      5        \u001b[36m0.6218\u001b[0m  0.5430\n",
      "      6        \u001b[36m0.6164\u001b[0m  0.5412\n",
      "      7        0.6193  0.5399\n",
      "      8        0.6241  0.5402\n",
      "      9        0.6802  0.5404\n",
      "     10        0.6719  0.5344\n",
      "     11        0.6679  0.5387\n",
      "     12        0.6578  0.5377\n",
      "     13        0.6685  0.5394\n",
      "     14        0.6527  0.5378\n",
      "     15        0.6559  0.5372\n",
      "     16        0.6564  0.5374\n",
      "     17        0.6413  0.5385\n",
      "     18        0.6569  0.5373\n",
      "     19        0.6287  0.5375\n",
      "     20        0.6356  0.5368\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7701\u001b[0m  0.7860\n",
      "      2        \u001b[36m0.6786\u001b[0m  0.7760\n",
      "      3        \u001b[36m0.6729\u001b[0m  0.7752\n",
      "      4        \u001b[36m0.6571\u001b[0m  0.7736\n",
      "      5        \u001b[36m0.6231\u001b[0m  0.7709\n",
      "      6        \u001b[36m0.6119\u001b[0m  0.7667\n",
      "      7        \u001b[36m0.6031\u001b[0m  0.7652\n",
      "      8        \u001b[36m0.5701\u001b[0m  0.7731\n",
      "      9        \u001b[36m0.5531\u001b[0m  0.7616\n",
      "     10        \u001b[36m0.5468\u001b[0m  0.7619\n",
      "     11        0.5576  0.7625\n",
      "     12        \u001b[36m0.5245\u001b[0m  0.7610\n",
      "     13        \u001b[36m0.4892\u001b[0m  0.7604\n",
      "     14        \u001b[36m0.4748\u001b[0m  0.7608\n",
      "     15        \u001b[36m0.4586\u001b[0m  0.7598\n",
      "     16        0.4740  0.7601\n",
      "     17        \u001b[36m0.4225\u001b[0m  0.7599\n",
      "     18        \u001b[36m0.4123\u001b[0m  0.7597\n",
      "     19        0.4436  0.7598\n",
      "     20        \u001b[36m0.3687\u001b[0m  0.7631\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  15.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6935\u001b[0m  0.7824\n",
      "      2        \u001b[36m0.6635\u001b[0m  0.7724\n",
      "      3        \u001b[36m0.6401\u001b[0m  0.7697\n",
      "      4        \u001b[36m0.6323\u001b[0m  0.7722\n",
      "      5        \u001b[36m0.6097\u001b[0m  0.7655\n",
      "      6        \u001b[36m0.6086\u001b[0m  0.7625\n",
      "      7        \u001b[36m0.5731\u001b[0m  0.7614\n",
      "      8        \u001b[36m0.5340\u001b[0m  0.7639\n",
      "      9        \u001b[36m0.5180\u001b[0m  0.7593\n",
      "     10        \u001b[36m0.5051\u001b[0m  0.7582\n",
      "     11        \u001b[36m0.4652\u001b[0m  0.7580\n",
      "     12        0.4735  0.7570\n",
      "     13        0.4770  0.7566\n",
      "     14        0.4833  0.7569\n",
      "     15        \u001b[36m0.4538\u001b[0m  0.7581\n",
      "     16        \u001b[36m0.4050\u001b[0m  0.7564\n",
      "     17        0.4271  0.7567\n",
      "     18        \u001b[36m0.3730\u001b[0m  0.7556\n",
      "     19        \u001b[36m0.3567\u001b[0m  0.7557\n",
      "     20        0.3728  0.7558\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  15.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6995\u001b[0m  0.7829\n",
      "      2        \u001b[36m0.6727\u001b[0m  0.7744\n",
      "      3        \u001b[36m0.6594\u001b[0m  0.7712\n",
      "      4        \u001b[36m0.6416\u001b[0m  0.7693\n",
      "      5        \u001b[36m0.6182\u001b[0m  0.7679\n",
      "      6        \u001b[36m0.6046\u001b[0m  0.7652\n",
      "      7        \u001b[36m0.5984\u001b[0m  0.7632\n",
      "      8        \u001b[36m0.5805\u001b[0m  0.7639\n",
      "      9        \u001b[36m0.5593\u001b[0m  0.7633\n",
      "     10        \u001b[36m0.5482\u001b[0m  0.7626\n",
      "     11        0.5674  0.7611\n",
      "     12        \u001b[36m0.5037\u001b[0m  0.7610\n",
      "     13        \u001b[36m0.4859\u001b[0m  0.7546\n",
      "     14        \u001b[36m0.4464\u001b[0m  0.7538\n",
      "     15        0.4915  0.7543\n",
      "     16        0.4596  0.7535\n",
      "     17        \u001b[36m0.4459\u001b[0m  0.7597\n",
      "     18        \u001b[36m0.4110\u001b[0m  0.7579\n",
      "     19        0.4617  0.7515\n",
      "     20        \u001b[36m0.3928\u001b[0m  0.7572\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  15.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6972\u001b[0m  0.8116\n",
      "      2        0.6983  0.8004\n",
      "      3        \u001b[36m0.6781\u001b[0m  0.7980\n",
      "      4        0.6823  0.7955\n",
      "      5        \u001b[36m0.6676\u001b[0m  0.7946\n",
      "      6        \u001b[36m0.6565\u001b[0m  0.7915\n",
      "      7        0.6643  0.7899\n",
      "      8        0.6578  0.7874\n",
      "      9        \u001b[36m0.6446\u001b[0m  0.7857\n",
      "     10        0.6644  0.7854\n",
      "     11        0.6606  0.7852\n",
      "     12        0.6566  0.7858\n",
      "     13        \u001b[36m0.6322\u001b[0m  0.7855\n",
      "     14        \u001b[36m0.6155\u001b[0m  0.7856\n",
      "     15        0.6292  0.7848\n",
      "     16        \u001b[36m0.5999\u001b[0m  0.7858\n",
      "     17        0.6195  0.7841\n",
      "     18        \u001b[36m0.5910\u001b[0m  0.7838\n",
      "     19        \u001b[36m0.5745\u001b[0m  0.7849\n",
      "     20        \u001b[36m0.5744\u001b[0m  0.7836\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6997\u001b[0m  0.8125\n",
      "      2        \u001b[36m0.6889\u001b[0m  0.7999\n",
      "      3        \u001b[36m0.6762\u001b[0m  0.7989\n",
      "      4        \u001b[36m0.6595\u001b[0m  0.7976\n",
      "      5        0.6729  0.7945\n",
      "      6        0.6629  0.7927\n",
      "      7        0.6601  0.7907\n",
      "      8        \u001b[36m0.6438\u001b[0m  0.7893\n",
      "      9        0.6628  0.7876\n",
      "     10        \u001b[36m0.6384\u001b[0m  0.7862\n",
      "     11        \u001b[36m0.6280\u001b[0m  0.7857\n",
      "     12        0.6355  0.7845\n",
      "     13        \u001b[36m0.6005\u001b[0m  0.7848\n",
      "     14        0.6400  0.7848\n",
      "     15        0.6509  0.7854\n",
      "     16        0.6262  0.7841\n",
      "     17        0.6087  0.7842\n",
      "     18        \u001b[36m0.5823\u001b[0m  0.7879\n",
      "     19        \u001b[36m0.5754\u001b[0m  0.7836\n",
      "     20        0.6270  0.7845\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7096\u001b[0m  0.8132\n",
      "      2        \u001b[36m0.6767\u001b[0m  0.8054\n",
      "      3        \u001b[36m0.6695\u001b[0m  0.7985\n",
      "      4        \u001b[36m0.6618\u001b[0m  0.7968\n",
      "      5        0.6677  0.7950\n",
      "      6        \u001b[36m0.6467\u001b[0m  0.7953\n",
      "      7        \u001b[36m0.6446\u001b[0m  0.7911\n",
      "      8        \u001b[36m0.6249\u001b[0m  0.7893\n",
      "      9        0.6396  0.7881\n",
      "     10        \u001b[36m0.6081\u001b[0m  0.7874\n",
      "     11        \u001b[36m0.6073\u001b[0m  0.7863\n",
      "     12        0.6172  0.7854\n",
      "     13        \u001b[36m0.5661\u001b[0m  0.7866\n",
      "     14        0.6164  0.7859\n",
      "     15        0.5906  0.7860\n",
      "     16        0.5880  0.7839\n",
      "     17        \u001b[36m0.5466\u001b[0m  0.7847\n",
      "     18        \u001b[36m0.5114\u001b[0m  0.7853\n",
      "     19        \u001b[36m0.4915\u001b[0m  0.7841\n",
      "     20        \u001b[36m0.4837\u001b[0m  0.7850\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7010\u001b[0m  0.8427\n",
      "      2        \u001b[36m0.7001\u001b[0m  0.8331\n",
      "      3        \u001b[36m0.6898\u001b[0m  0.8342\n",
      "      4        0.6916  0.8327\n",
      "      5        0.6903  0.8316\n",
      "      6        \u001b[36m0.6805\u001b[0m  0.8298\n",
      "      7        \u001b[36m0.6804\u001b[0m  0.8295\n",
      "      8        0.6846  0.8234\n",
      "      9        0.6805  0.8218\n",
      "     10        \u001b[36m0.6784\u001b[0m  0.8208\n",
      "     11        0.6888  0.8194\n",
      "     12        0.6876  0.8193\n",
      "     13        0.6827  0.8179\n",
      "     14        0.6786  0.8175\n",
      "     15        \u001b[36m0.6674\u001b[0m  0.8156\n",
      "     16        \u001b[36m0.6626\u001b[0m  0.8140\n",
      "     17        \u001b[36m0.6525\u001b[0m  0.8145\n",
      "     18        \u001b[36m0.6435\u001b[0m  0.8143\n",
      "     19        0.6544  0.8142\n",
      "     20        0.6493  0.8087\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  16.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6966\u001b[0m  0.8370\n",
      "      2        \u001b[36m0.6747\u001b[0m  0.8288\n",
      "      3        \u001b[36m0.6682\u001b[0m  0.8271\n",
      "      4        0.6693  0.8262\n",
      "      5        \u001b[36m0.6635\u001b[0m  0.8243\n",
      "      6        \u001b[36m0.6481\u001b[0m  0.8204\n",
      "      7        \u001b[36m0.6324\u001b[0m  0.8181\n",
      "      8        0.6563  0.8171\n",
      "      9        0.6384  0.8157\n",
      "     10        0.6337  0.8147\n",
      "     11        0.6345  0.8149\n",
      "     12        \u001b[36m0.6314\u001b[0m  0.8134\n",
      "     13        \u001b[36m0.6138\u001b[0m  0.8134\n",
      "     14        \u001b[36m0.5951\u001b[0m  0.8142\n",
      "     15        \u001b[36m0.5799\u001b[0m  0.8137\n",
      "     16        \u001b[36m0.5599\u001b[0m  0.8115\n",
      "     17        0.5707  0.8112\n",
      "     18        0.5973  0.8114\n",
      "     19        0.5804  0.8110\n",
      "     20        0.5682  0.8103\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  16.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6942\u001b[0m  0.8373\n",
      "      2        \u001b[36m0.6729\u001b[0m  0.8256\n",
      "      3        \u001b[36m0.6726\u001b[0m  0.8289\n",
      "      4        \u001b[36m0.6679\u001b[0m  0.8200\n",
      "      5        \u001b[36m0.6657\u001b[0m  0.8149\n",
      "      6        0.6796  0.8128\n",
      "      7        0.6775  0.8126\n",
      "      8        0.6751  0.8116\n",
      "      9        0.6716  0.8101\n",
      "     10        \u001b[36m0.6652\u001b[0m  0.8090\n",
      "     11        0.6762  0.8080\n",
      "     12        \u001b[36m0.6501\u001b[0m  0.8085\n",
      "     13        0.6578  0.8084\n",
      "     14        0.6514  0.8069\n",
      "     15        0.6543  0.8077\n",
      "     16        \u001b[36m0.6435\u001b[0m  0.8103\n",
      "     17        0.6785  0.8057\n",
      "     18        0.6627  0.8068\n",
      "     19        \u001b[36m0.6395\u001b[0m  0.8061\n",
      "     20        \u001b[36m0.6328\u001b[0m  0.8100\n",
      "[CV] END lr=0.001, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  16.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8581\u001b[0m  0.4233\n",
      "      2        \u001b[36m0.6783\u001b[0m  0.4224\n",
      "      3        \u001b[36m0.6661\u001b[0m  0.4225\n",
      "      4        0.6882  0.4224\n",
      "      5        0.6734  0.4227\n",
      "      6        0.6678  0.4246\n",
      "      7        0.6889  0.4229\n",
      "      8        0.6889  0.4214\n",
      "      9        0.6890  0.4224\n",
      "     10        0.6889  0.4225\n",
      "     11        0.6888  0.4215\n",
      "     12        0.6889  0.4226\n",
      "     13        0.6889  0.4229\n",
      "     14        0.6890  0.4223\n",
      "     15        0.6890  0.4221\n",
      "     16        0.6890  0.4234\n",
      "     17        0.6888  0.4220\n",
      "     18        0.6889  0.4220\n",
      "     19        0.6889  0.4227\n",
      "     20        0.6890  0.4226\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.9084\u001b[0m  0.4236\n",
      "      2        \u001b[36m0.5337\u001b[0m  0.4212\n",
      "      3        \u001b[36m0.4318\u001b[0m  0.4205\n",
      "      4        \u001b[36m0.2876\u001b[0m  0.4218\n",
      "      5        0.2932  0.4216\n",
      "      6        \u001b[36m0.2545\u001b[0m  0.4208\n",
      "      7        \u001b[36m0.1492\u001b[0m  0.4225\n",
      "      8        \u001b[36m0.1427\u001b[0m  0.4221\n",
      "      9        0.3800  0.4217\n",
      "     10        0.1527  0.4198\n",
      "     11        0.1560  0.4214\n",
      "     12        0.2986  0.4214\n",
      "     13        0.8520  0.4203\n",
      "     14        0.6912  0.4221\n",
      "     15        0.6840  0.4213\n",
      "     16        0.6820  0.4215\n",
      "     17        0.6773  0.4209\n",
      "     18        0.6794  0.4215\n",
      "     19        0.6774  0.4215\n",
      "     20        0.6780  0.4220\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6517\u001b[0m  0.4253\n",
      "      2        \u001b[36m0.5848\u001b[0m  0.4209\n",
      "      3        \u001b[36m0.4666\u001b[0m  0.4216\n",
      "      4        \u001b[36m0.4076\u001b[0m  0.4218\n",
      "      5        0.4081  0.4209\n",
      "      6        \u001b[36m0.2161\u001b[0m  0.4218\n",
      "      7        \u001b[36m0.1703\u001b[0m  0.4226\n",
      "      8        0.2284  0.4214\n",
      "      9        0.1747  0.4226\n",
      "     10        \u001b[36m0.0532\u001b[0m  0.4224\n",
      "     11        \u001b[36m0.0164\u001b[0m  0.4223\n",
      "     12        \u001b[36m0.0099\u001b[0m  0.4211\n",
      "     13        \u001b[36m0.0065\u001b[0m  0.4225\n",
      "     14        \u001b[36m0.0047\u001b[0m  0.4219\n",
      "     15        \u001b[36m0.0036\u001b[0m  0.4212\n",
      "     16        \u001b[36m0.0029\u001b[0m  0.4226\n",
      "     17        \u001b[36m0.0024\u001b[0m  0.4226\n",
      "     18        \u001b[36m0.0020\u001b[0m  0.4222\n",
      "     19        \u001b[36m0.0018\u001b[0m  0.4216\n",
      "     20        \u001b[36m0.0016\u001b[0m  0.4231\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1881\u001b[0m  0.4335\n",
      "      2        \u001b[36m0.6253\u001b[0m  0.4334\n",
      "      3        0.6443  0.4333\n",
      "      4        0.6933  0.4322\n",
      "      5        0.6885  0.4346\n",
      "      6        0.6338  0.4333\n",
      "      7        0.6894  0.4328\n",
      "      8        0.6890  0.4337\n",
      "      9        0.6900  0.4328\n",
      "     10        0.6899  0.4335\n",
      "     11        0.6897  0.4328\n",
      "     12        0.6894  0.4337\n",
      "     13        0.6893  0.4327\n",
      "     14        0.6894  0.4333\n",
      "     15        0.6897  0.4338\n",
      "     16        0.6895  0.4324\n",
      "     17        0.6890  0.4335\n",
      "     18        0.6288  0.4331\n",
      "     19        0.6954  0.4309\n",
      "     20        0.6353  0.4324\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.7137\u001b[0m  0.4365\n",
      "      2        \u001b[36m0.6830\u001b[0m  0.4354\n",
      "      3        \u001b[36m0.6591\u001b[0m  0.4365\n",
      "      4        0.6805  0.4367\n",
      "      5        0.6899  0.4358\n",
      "      6        0.6894  0.4359\n",
      "      7        0.6897  0.4364\n",
      "      8        0.6895  0.4355\n",
      "      9        0.6898  0.4360\n",
      "     10        0.6893  0.4367\n",
      "     11        0.6886  0.4356\n",
      "     12        0.6903  0.4362\n",
      "     13        0.6894  0.4364\n",
      "     14        0.6895  0.4361\n",
      "     15        0.6893  0.4367\n",
      "     16        0.6893  0.4363\n",
      "     17        0.6892  0.4361\n",
      "     18        0.6911  0.4347\n",
      "     19        0.6893  0.4350\n",
      "     20        0.6896  0.4365\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2701\u001b[0m  0.4355\n",
      "      2        \u001b[36m0.6951\u001b[0m  0.4351\n",
      "      3        \u001b[36m0.6899\u001b[0m  0.4326\n",
      "      4        \u001b[36m0.6895\u001b[0m  0.4343\n",
      "      5        \u001b[36m0.6893\u001b[0m  0.4335\n",
      "      6        0.6899  0.4339\n",
      "      7        0.6897  0.4326\n",
      "      8        0.6897  0.4336\n",
      "      9        \u001b[36m0.6893\u001b[0m  0.4338\n",
      "     10        0.6897  0.4325\n",
      "     11        0.6894  0.4346\n",
      "     12        0.6896  0.4343\n",
      "     13        0.6896  0.4321\n",
      "     14        0.6897  0.4341\n",
      "     15        0.6895  0.4340\n",
      "     16        0.6896  0.4330\n",
      "     17        0.6894  0.4343\n",
      "     18        0.6897  0.4339\n",
      "     19        0.6895  0.4335\n",
      "     20        0.6893  0.4341\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9327\u001b[0m  0.4466\n",
      "      2        \u001b[36m0.6790\u001b[0m  0.4461\n",
      "      3        \u001b[36m0.6688\u001b[0m  0.4471\n",
      "      4        \u001b[36m0.6081\u001b[0m  0.4475\n",
      "      5        \u001b[36m0.5667\u001b[0m  0.4457\n",
      "      6        0.6622  0.4466\n",
      "      7        0.6682  0.4460\n",
      "      8        0.6881  0.4461\n",
      "      9        0.6888  0.4455\n",
      "     10        0.6898  0.4468\n",
      "     11        0.6895  0.4456\n",
      "     12        0.6898  0.4468\n",
      "     13        0.6892  0.4466\n",
      "     14        0.6900  0.4461\n",
      "     15        0.6893  0.4464\n",
      "     16        0.6891  0.4472\n",
      "     17        0.6894  0.4461\n",
      "     18        0.6895  0.4476\n",
      "     19        0.6893  0.4470\n",
      "     20        0.6897  0.4463\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9561\u001b[0m  0.4482\n",
      "      2        \u001b[36m0.6776\u001b[0m  0.4461\n",
      "      3        0.6897  0.4466\n",
      "      4        0.6894  0.4474\n",
      "      5        0.6895  0.4471\n",
      "      6        0.6893  0.4474\n",
      "      7        0.6898  0.4469\n",
      "      8        0.6894  0.4465\n",
      "      9        0.6892  0.4469\n",
      "     10        0.6894  0.4477\n",
      "     11        0.6897  0.4479\n",
      "     12        0.6893  0.4487\n",
      "     13        0.6895  0.4476\n",
      "     14        0.6895  0.4479\n",
      "     15        0.6893  0.4480\n",
      "     16        0.6894  0.4474\n",
      "     17        0.6894  0.4472\n",
      "     18        0.6895  0.4478\n",
      "     19        0.6891  0.4475\n",
      "     20        0.6891  0.4466\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9953\u001b[0m  0.4492\n",
      "      2        \u001b[36m0.6685\u001b[0m  0.4468\n",
      "      3        \u001b[36m0.6332\u001b[0m  0.4452\n",
      "      4        \u001b[36m0.5960\u001b[0m  0.4461\n",
      "      5        0.6176  0.4473\n",
      "      6        \u001b[36m0.5705\u001b[0m  0.4463\n",
      "      7        \u001b[36m0.5553\u001b[0m  0.4494\n",
      "      8        \u001b[36m0.4559\u001b[0m  0.4468\n",
      "      9        \u001b[36m0.4406\u001b[0m  0.4464\n",
      "     10        0.5635  0.4472\n",
      "     11        0.4982  0.4463\n",
      "     12        \u001b[36m0.4027\u001b[0m  0.4464\n",
      "     13        0.4570  0.4469\n",
      "     14        0.4093  0.4468\n",
      "     15        0.4077  0.4461\n",
      "     16        0.4036  0.4467\n",
      "     17        \u001b[36m0.3839\u001b[0m  0.4456\n",
      "     18        \u001b[36m0.2447\u001b[0m  0.4454\n",
      "     19        0.2653  0.4465\n",
      "     20        0.2493  0.4467\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.1384\u001b[0m  0.5219\n",
      "      2        \u001b[36m0.6673\u001b[0m  0.5218\n",
      "      3        \u001b[36m0.6422\u001b[0m  0.5256\n",
      "      4        \u001b[36m0.6065\u001b[0m  0.5267\n",
      "      5        0.6326  0.5255\n",
      "      6        0.6091  0.5253\n",
      "      7        0.6853  0.5245\n",
      "      8        \u001b[36m0.5749\u001b[0m  0.5218\n",
      "      9        \u001b[36m0.5254\u001b[0m  0.5228\n",
      "     10        \u001b[36m0.4609\u001b[0m  0.5208\n",
      "     11        0.4759  0.5223\n",
      "     12        0.5307  0.5256\n",
      "     13        \u001b[36m0.4088\u001b[0m  0.5260\n",
      "     14        \u001b[36m0.3734\u001b[0m  0.5257\n",
      "     15        0.5451  0.5223\n",
      "     16        \u001b[36m0.3491\u001b[0m  0.5215\n",
      "     17        \u001b[36m0.2760\u001b[0m  0.5248\n",
      "     18        0.2981  0.5258\n",
      "     19        \u001b[36m0.2531\u001b[0m  0.5261\n",
      "     20        0.2711  0.5259\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.1839\u001b[0m  0.5301\n",
      "      2        \u001b[36m0.5762\u001b[0m  0.5228\n",
      "      3        \u001b[36m0.4557\u001b[0m  0.5208\n",
      "      4        \u001b[36m0.2711\u001b[0m  0.5229\n",
      "      5        0.2882  0.5260\n",
      "      6        \u001b[36m0.2380\u001b[0m  0.5248\n",
      "      7        0.3893  0.5225\n",
      "      8        0.3752  0.5232\n",
      "      9        0.7019  0.5210\n",
      "     10        0.6891  0.5241\n",
      "     11        0.6889  0.5212\n",
      "     12        0.6886  0.5242\n",
      "     13        0.6879  0.5246\n",
      "     14        0.5989  0.5244\n",
      "     15        0.5563  0.5255\n",
      "     16        0.4523  0.5240\n",
      "     17        0.3088  0.5257\n",
      "     18        \u001b[36m0.2117\u001b[0m  0.5257\n",
      "     19        0.6448  0.5240\n",
      "     20        0.4334  0.5249\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3912\u001b[0m  0.5219\n",
      "      2        \u001b[36m0.5049\u001b[0m  0.5223\n",
      "      3        \u001b[36m0.4256\u001b[0m  0.5217\n",
      "      4        \u001b[36m0.2482\u001b[0m  0.5231\n",
      "      5        0.3226  0.5251\n",
      "      6        0.2902  0.5201\n",
      "      7        0.2687  0.5214\n",
      "      8        0.2575  0.5206\n",
      "      9        \u001b[36m0.1411\u001b[0m  0.5220\n",
      "     10        \u001b[36m0.0889\u001b[0m  0.5273\n",
      "     11        0.1232  0.5225\n",
      "     12        0.1847  0.5201\n",
      "     13        0.2031  0.5221\n",
      "     14        0.1896  0.5230\n",
      "     15        0.2207  0.5239\n",
      "     16        0.1208  0.5225\n",
      "     17        0.1923  0.5214\n",
      "     18        \u001b[36m0.0531\u001b[0m  0.5225\n",
      "     19        \u001b[36m0.0139\u001b[0m  0.5231\n",
      "     20        \u001b[36m0.0079\u001b[0m  0.5211\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1306\u001b[0m  0.5421\n",
      "      2        \u001b[36m0.7116\u001b[0m  0.5393\n",
      "      3        \u001b[36m0.6953\u001b[0m  0.5385\n",
      "      4        \u001b[36m0.6919\u001b[0m  0.5403\n",
      "      5        \u001b[36m0.6901\u001b[0m  0.5433\n",
      "      6        \u001b[36m0.6893\u001b[0m  0.5412\n",
      "      7        \u001b[36m0.6892\u001b[0m  0.5383\n",
      "      8        0.6895  0.5383\n",
      "      9        \u001b[36m0.6892\u001b[0m  0.5388\n",
      "     10        0.6892  0.5405\n",
      "     11        0.6893  0.5406\n",
      "     12        0.6892  0.5404\n",
      "     13        \u001b[36m0.6891\u001b[0m  0.5380\n",
      "     14        \u001b[36m0.6891\u001b[0m  0.5381\n",
      "     15        0.6891  0.5385\n",
      "     16        0.6895  0.5380\n",
      "     17        \u001b[36m0.6890\u001b[0m  0.5435\n",
      "     18        0.6894  0.5439\n",
      "     19        0.6891  0.5432\n",
      "     20        0.6892  0.5419\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2243\u001b[0m  0.5429\n",
      "      2        \u001b[36m0.7133\u001b[0m  0.5435\n",
      "      3        \u001b[36m0.6893\u001b[0m  0.5442\n",
      "      4        0.6897  0.5422\n",
      "      5        0.6895  0.5441\n",
      "      6        0.6893  0.5406\n",
      "      7        \u001b[36m0.6892\u001b[0m  0.5441\n",
      "      8        0.6892  0.5445\n",
      "      9        0.6892  0.5421\n",
      "     10        0.6892  0.5436\n",
      "     11        \u001b[36m0.6891\u001b[0m  0.5446\n",
      "     12        0.6894  0.5418\n",
      "     13        0.6895  0.5426\n",
      "     14        \u001b[36m0.6890\u001b[0m  0.5437\n",
      "     15        \u001b[36m0.6889\u001b[0m  0.5411\n",
      "     16        0.6893  0.5415\n",
      "     17        0.6893  0.5435\n",
      "     18        0.6890  0.5407\n",
      "     19        0.6891  0.5413\n",
      "     20        0.6890  0.5447\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5157\u001b[0m  0.5400\n",
      "      2        \u001b[36m0.6896\u001b[0m  0.5400\n",
      "      3        0.6902  0.5401\n",
      "      4        \u001b[36m0.6892\u001b[0m  0.5406\n",
      "      5        0.6893  0.5385\n",
      "      6        \u001b[36m0.6892\u001b[0m  0.5392\n",
      "      7        \u001b[36m0.6892\u001b[0m  0.5396\n",
      "      8        0.6894  0.5397\n",
      "      9        \u001b[36m0.6891\u001b[0m  0.5397\n",
      "     10        0.6896  0.5390\n",
      "     11        \u001b[36m0.6891\u001b[0m  0.5400\n",
      "     12        \u001b[36m0.6890\u001b[0m  0.5392\n",
      "     13        0.6890  0.5346\n",
      "     14        0.6894  0.5361\n",
      "     15        0.6892  0.5371\n",
      "     16        0.6891  0.5386\n",
      "     17        0.6891  0.5407\n",
      "     18        0.6892  0.5355\n",
      "     19        0.6895  0.5366\n",
      "     20        0.6893  0.5373\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  10.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5008\u001b[0m  0.5575\n",
      "      2        \u001b[36m0.7021\u001b[0m  0.5539\n",
      "      3        \u001b[36m0.6896\u001b[0m  0.5544\n",
      "      4        0.6898  0.5540\n",
      "      5        \u001b[36m0.6894\u001b[0m  0.5539\n",
      "      6        0.6896  0.5534\n",
      "      7        0.6898  0.5541\n",
      "      8        0.6895  0.5540\n",
      "      9        0.6895  0.5557\n",
      "     10        0.6898  0.5539\n",
      "     11        \u001b[36m0.6894\u001b[0m  0.5547\n",
      "     12        0.6897  0.5542\n",
      "     13        0.6895  0.5544\n",
      "     14        0.6899  0.5540\n",
      "     15        0.6897  0.5536\n",
      "     16        0.6896  0.5541\n",
      "     17        0.6894  0.5540\n",
      "     18        0.6895  0.5536\n",
      "     19        0.6895  0.5538\n",
      "     20        0.6895  0.5552\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0492\u001b[0m  0.5645\n",
      "      2        \u001b[36m0.7019\u001b[0m  0.5613\n",
      "      3        \u001b[36m0.6896\u001b[0m  0.5624\n",
      "      4        \u001b[36m0.6893\u001b[0m  0.5603\n",
      "      5        0.6895  0.5614\n",
      "      6        0.6896  0.5607\n",
      "      7        \u001b[36m0.6892\u001b[0m  0.5615\n",
      "      8        0.6895  0.5612\n",
      "      9        0.6923  0.5609\n",
      "     10        0.6894  0.5604\n",
      "     11        0.6896  0.5619\n",
      "     12        0.6894  0.5631\n",
      "     13        0.6895  0.5626\n",
      "     14        0.6897  0.5622\n",
      "     15        0.6894  0.5629\n",
      "     16        0.6895  0.5602\n",
      "     17        0.6894  0.5626\n",
      "     18        0.6895  0.5607\n",
      "     19        0.6893  0.5613\n",
      "     20        0.6894  0.5602\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3119\u001b[0m  0.5591\n",
      "      2        \u001b[36m0.6767\u001b[0m  0.5583\n",
      "      3        0.6894  0.5594\n",
      "      4        0.6899  0.5596\n",
      "      5        0.6893  0.5586\n",
      "      6        0.6892  0.5598\n",
      "      7        0.6893  0.5584\n",
      "      8        0.6893  0.5590\n",
      "      9        0.6893  0.5593\n",
      "     10        0.6891  0.5583\n",
      "     11        0.6894  0.5582\n",
      "     12        0.6891  0.5588\n",
      "     13        0.6895  0.5589\n",
      "     14        0.6894  0.5589\n",
      "     15        0.6893  0.5581\n",
      "     16        0.6893  0.5591\n",
      "     17        0.6899  0.5597\n",
      "     18        0.6893  0.5589\n",
      "     19        0.6898  0.5575\n",
      "     20        0.6896  0.5578\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.0282\u001b[0m  0.7977\n",
      "      2        \u001b[36m0.6887\u001b[0m  0.7943\n",
      "      3        \u001b[36m0.5422\u001b[0m  0.7943\n",
      "      4        \u001b[36m0.4987\u001b[0m  0.7950\n",
      "      5        \u001b[36m0.3935\u001b[0m  0.7946\n",
      "      6        0.6391  0.7942\n",
      "      7        0.6913  0.7952\n",
      "      8        0.6752  0.7945\n",
      "      9        0.6873  0.7956\n",
      "     10        0.6881  0.7945\n",
      "     11        0.6824  0.7953\n",
      "     12        0.6887  0.7958\n",
      "     13        0.6888  0.8011\n",
      "     14        0.6889  0.7949\n",
      "     15        0.6888  0.7954\n",
      "     16        0.6888  0.7977\n",
      "     17        0.6888  0.7976\n",
      "     18        0.6886  0.7961\n",
      "     19        0.6888  0.7965\n",
      "     20        0.6887  0.7992\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.7642\u001b[0m  0.8002\n",
      "      2        \u001b[36m0.6965\u001b[0m  0.7989\n",
      "      3        \u001b[36m0.6893\u001b[0m  0.7993\n",
      "      4        \u001b[36m0.6892\u001b[0m  0.8000\n",
      "      5        0.6893  0.7975\n",
      "      6        0.6893  0.7975\n",
      "      7        0.6892  0.7991\n",
      "      8        0.6894  0.7987\n",
      "      9        0.6892  0.7994\n",
      "     10        0.6893  0.7985\n",
      "     11        0.6892  0.7983\n",
      "     12        0.6892  0.7987\n",
      "     13        \u001b[36m0.6891\u001b[0m  0.7995\n",
      "     14        \u001b[36m0.6891\u001b[0m  0.7992\n",
      "     15        0.6892  0.7992\n",
      "     16        0.6894  0.7981\n",
      "     17        0.6893  0.7991\n",
      "     18        0.6891  0.7974\n",
      "     19        \u001b[36m0.6890\u001b[0m  0.7982\n",
      "     20        0.6895  0.7985\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.9137\u001b[0m  0.8043\n",
      "      2        \u001b[36m0.6061\u001b[0m  0.8020\n",
      "      3        \u001b[36m0.5101\u001b[0m  0.8017\n",
      "      4        \u001b[36m0.3694\u001b[0m  0.8008\n",
      "      5        0.3836  0.8010\n",
      "      6        0.4311  0.8015\n",
      "      7        \u001b[36m0.1886\u001b[0m  0.8011\n",
      "      8        0.3333  0.8018\n",
      "      9        0.2178  0.8020\n",
      "     10        \u001b[36m0.0941\u001b[0m  0.8018\n",
      "     11        0.1709  0.8023\n",
      "     12        0.1360  0.8014\n",
      "     13        0.0945  0.8017\n",
      "     14        \u001b[36m0.0222\u001b[0m  0.8018\n",
      "     15        \u001b[36m0.0125\u001b[0m  0.8021\n",
      "     16        \u001b[36m0.0080\u001b[0m  0.8024\n",
      "     17        \u001b[36m0.0059\u001b[0m  0.8023\n",
      "     18        \u001b[36m0.0045\u001b[0m  0.8017\n",
      "     19        \u001b[36m0.0036\u001b[0m  0.8015\n",
      "     20        \u001b[36m0.0030\u001b[0m  0.8066\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6550\u001b[0m  0.8312\n",
      "      2        \u001b[36m0.7217\u001b[0m  0.8284\n",
      "      3        \u001b[36m0.6915\u001b[0m  0.8266\n",
      "      4        \u001b[36m0.6896\u001b[0m  0.8278\n",
      "      5        \u001b[36m0.6890\u001b[0m  0.8278\n",
      "      6        \u001b[36m0.6890\u001b[0m  0.8268\n",
      "      7        0.6894  0.8270\n",
      "      8        \u001b[36m0.6884\u001b[0m  0.8282\n",
      "      9        0.6903  0.8279\n",
      "     10        0.6889  0.8278\n",
      "     11        0.6891  0.8291\n",
      "     12        0.6890  0.8270\n",
      "     13        0.6889  0.8283\n",
      "     14        0.6889  0.8282\n",
      "     15        0.6889  0.8282\n",
      "     16        0.6886  0.8280\n",
      "     17        0.6892  0.8272\n",
      "     18        0.6892  0.8277\n",
      "     19        0.6891  0.8288\n",
      "     20        0.6888  0.8274\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.3259\u001b[0m  0.8272\n",
      "      2        \u001b[36m0.6841\u001b[0m  0.8259\n",
      "      3        0.6882  0.8250\n",
      "      4        0.6895  0.8263\n",
      "      5        0.6896  0.8257\n",
      "      6        0.6894  0.8226\n",
      "      7        0.6896  0.8242\n",
      "      8        0.6898  0.8312\n",
      "      9        0.6895  0.8204\n",
      "     10        0.6894  0.8207\n",
      "     11        0.6893  0.8210\n",
      "     12        0.6894  0.8228\n",
      "     13        0.6893  0.8210\n",
      "     14        0.6897  0.8197\n",
      "     15        0.6897  0.8201\n",
      "     16        0.6893  0.8205\n",
      "     17        0.6893  0.8203\n",
      "     18        0.6894  0.8196\n",
      "     19        0.6895  0.8204\n",
      "     20        0.6893  0.8191\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.7711\u001b[0m  0.8214\n",
      "      2        \u001b[36m0.7002\u001b[0m  0.8196\n",
      "      3        0.7104  0.8183\n",
      "      4        \u001b[36m0.6955\u001b[0m  0.8188\n",
      "      5        \u001b[36m0.6866\u001b[0m  0.8189\n",
      "      6        0.6873  0.8183\n",
      "      7        \u001b[36m0.6852\u001b[0m  0.8180\n",
      "      8        0.6885  0.8180\n",
      "      9        0.6887  0.8180\n",
      "     10        \u001b[36m0.6790\u001b[0m  0.8180\n",
      "     11        0.6890  0.8169\n",
      "     12        0.6892  0.8180\n",
      "     13        0.6891  0.8177\n",
      "     14        0.6891  0.8186\n",
      "     15        0.6896  0.8193\n",
      "     16        0.6889  0.8180\n",
      "     17        0.6889  0.8179\n",
      "     18        0.6889  0.8179\n",
      "     19        0.6890  0.8176\n",
      "     20        0.6896  0.8184\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4331\u001b[0m  0.8518\n",
      "      2        \u001b[36m0.6904\u001b[0m  0.8491\n",
      "      3        \u001b[36m0.6837\u001b[0m  0.8493\n",
      "      4        \u001b[36m0.6690\u001b[0m  0.8493\n",
      "      5        \u001b[36m0.6425\u001b[0m  0.8492\n",
      "      6        0.6779  0.8474\n",
      "      7        0.6900  0.8501\n",
      "      8        0.6897  0.8489\n",
      "      9        0.6894  0.8487\n",
      "     10        0.6896  0.8489\n",
      "     11        0.6895  0.8487\n",
      "     12        0.6896  0.8487\n",
      "     13        0.6893  0.8487\n",
      "     14        0.6899  0.8482\n",
      "     15        0.6894  0.8480\n",
      "     16        0.6896  0.8480\n",
      "     17        0.6894  0.8485\n",
      "     18        0.6894  0.8493\n",
      "     19        0.6895  0.8493\n",
      "     20        0.6892  0.8492\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8355\u001b[0m  0.8649\n",
      "      2        \u001b[36m0.6999\u001b[0m  0.8606\n",
      "      3        \u001b[36m0.6897\u001b[0m  0.8606\n",
      "      4        \u001b[36m0.6890\u001b[0m  0.8599\n",
      "      5        \u001b[36m0.6890\u001b[0m  0.8598\n",
      "      6        0.6890  0.8611\n",
      "      7        0.6892  0.8610\n",
      "      8        0.6892  0.8600\n",
      "      9        \u001b[36m0.6889\u001b[0m  0.8607\n",
      "     10        0.6891  0.8608\n",
      "     11        0.6892  0.8613\n",
      "     12        0.6892  0.8608\n",
      "     13        0.6890  0.8607\n",
      "     14        0.6890  0.8609\n",
      "     15        0.6891  0.8629\n",
      "     16        0.6895  0.8600\n",
      "     17        0.6891  0.8608\n",
      "     18        0.6892  0.8638\n",
      "     19        0.6891  0.8593\n",
      "     20        \u001b[36m0.6889\u001b[0m  0.8604\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.8303\u001b[0m  0.8485\n",
      "      2        \u001b[36m0.7082\u001b[0m  0.8509\n",
      "      3        \u001b[36m0.6840\u001b[0m  0.8461\n",
      "      4        \u001b[36m0.6543\u001b[0m  0.8459\n",
      "      5        \u001b[36m0.5956\u001b[0m  0.8450\n",
      "      6        0.6111  0.8538\n",
      "      7        \u001b[36m0.5326\u001b[0m  0.8488\n",
      "      8        0.6878  0.8495\n",
      "      9        0.6968  0.8490\n",
      "     10        0.6893  0.8486\n",
      "     11        0.6903  0.8476\n",
      "     12        0.6892  0.8490\n",
      "     13        0.6897  0.8537\n",
      "     14        0.6894  0.8500\n",
      "     15        0.6883  0.8503\n",
      "     16        0.6893  0.8503\n",
      "     17        0.6893  0.8506\n",
      "     18        0.6895  0.8489\n",
      "     19        0.6893  0.8502\n",
      "     20        0.6890  0.8502\n",
      "[CV] END lr=0.01, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7004\u001b[0m  0.4236\n",
      "      2        \u001b[36m0.6925\u001b[0m  0.4237\n",
      "      3        0.7008  0.4246\n",
      "      4        0.6976  0.4246\n",
      "      5        0.6933  0.4246\n",
      "      6        0.6962  0.4250\n",
      "      7        \u001b[36m0.6913\u001b[0m  0.4242\n",
      "      8        0.6921  0.4248\n",
      "      9        0.6939  0.4257\n",
      "     10        0.6917  0.4248\n",
      "     11        0.6957  0.4255\n",
      "     12        0.6929  0.4256\n",
      "     13        0.6946  0.4238\n",
      "     14        \u001b[36m0.6906\u001b[0m  0.4246\n",
      "     15        0.6920  0.4252\n",
      "     16        0.6981  0.4227\n",
      "     17        0.6924  0.4225\n",
      "     18        0.6938  0.4235\n",
      "     19        0.6921  0.4236\n",
      "     20        0.6917  0.4240\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7000\u001b[0m  0.4214\n",
      "      2        \u001b[36m0.6947\u001b[0m  0.4202\n",
      "      3        \u001b[36m0.6934\u001b[0m  0.4204\n",
      "      4        \u001b[36m0.6904\u001b[0m  0.4205\n",
      "      5        0.6927  0.4205\n",
      "      6        0.6921  0.4205\n",
      "      7        0.6946  0.4207\n",
      "      8        0.7046  0.4209\n",
      "      9        0.6959  0.4192\n",
      "     10        0.6947  0.4208\n",
      "     11        0.6947  0.4206\n",
      "     12        0.6977  0.4198\n",
      "     13        0.6910  0.4211\n",
      "     14        0.6944  0.4213\n",
      "     15        0.6944  0.4205\n",
      "     16        0.6906  0.4205\n",
      "     17        0.6928  0.4194\n",
      "     18        0.6934  0.4192\n",
      "     19        0.6940  0.4205\n",
      "     20        0.6937  0.4207\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6934\u001b[0m  0.4230\n",
      "      2        \u001b[36m0.6915\u001b[0m  0.4223\n",
      "      3        0.6939  0.4210\n",
      "      4        0.6932  0.4225\n",
      "      5        \u001b[36m0.6863\u001b[0m  0.4202\n",
      "      6        0.6890  0.4192\n",
      "      7        0.6895  0.4192\n",
      "      8        0.6959  0.4177\n",
      "      9        0.6914  0.4196\n",
      "     10        0.6901  0.4188\n",
      "     11        0.6938  0.4185\n",
      "     12        0.6877  0.4203\n",
      "     13        0.6915  0.4192\n",
      "     14        0.6952  0.4186\n",
      "     15        0.6872  0.4190\n",
      "     16        0.6942  0.4193\n",
      "     17        0.6885  0.4191\n",
      "     18        0.6885  0.4195\n",
      "     19        0.6938  0.4201\n",
      "     20        0.6887  0.4197\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6939\u001b[0m  0.4376\n",
      "      2        \u001b[36m0.6899\u001b[0m  0.4368\n",
      "      3        \u001b[36m0.6898\u001b[0m  0.4354\n",
      "      4        \u001b[36m0.6890\u001b[0m  0.4368\n",
      "      5        0.6902  0.4365\n",
      "      6        0.6891  0.4355\n",
      "      7        0.6896  0.4366\n",
      "      8        \u001b[36m0.6888\u001b[0m  0.4361\n",
      "      9        0.6899  0.4355\n",
      "     10        0.6897  0.4364\n",
      "     11        0.6895  0.4371\n",
      "     12        0.6891  0.4360\n",
      "     13        0.6895  0.4360\n",
      "     14        \u001b[36m0.6883\u001b[0m  0.4370\n",
      "     15        0.6897  0.4353\n",
      "     16        0.6896  0.4354\n",
      "     17        0.6895  0.4356\n",
      "     18        0.6894  0.4366\n",
      "     19        0.6896  0.4354\n",
      "     20        0.6896  0.4360\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6987\u001b[0m  0.4369\n",
      "      2        \u001b[36m0.6936\u001b[0m  0.4369\n",
      "      3        \u001b[36m0.6903\u001b[0m  0.4376\n",
      "      4        \u001b[36m0.6901\u001b[0m  0.4368\n",
      "      5        \u001b[36m0.6894\u001b[0m  0.4379\n",
      "      6        0.6897  0.4371\n",
      "      7        0.6896  0.4363\n",
      "      8        0.6899  0.4373\n",
      "      9        0.6896  0.4382\n",
      "     10        \u001b[36m0.6893\u001b[0m  0.4370\n",
      "     11        0.6897  0.4374\n",
      "     12        0.6894  0.4375\n",
      "     13        0.6902  0.4384\n",
      "     14        0.6897  0.4366\n",
      "     15        0.6893  0.4380\n",
      "     16        0.6901  0.4379\n",
      "     17        0.6897  0.4379\n",
      "     18        0.6895  0.4379\n",
      "     19        0.6900  0.4378\n",
      "     20        0.6896  0.4372\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6968\u001b[0m  0.4392\n",
      "      2        \u001b[36m0.6919\u001b[0m  0.4373\n",
      "      3        \u001b[36m0.6899\u001b[0m  0.4376\n",
      "      4        0.6899  0.4374\n",
      "      5        \u001b[36m0.6897\u001b[0m  0.4372\n",
      "      6        0.6899  0.4354\n",
      "      7        \u001b[36m0.6893\u001b[0m  0.4369\n",
      "      8        0.6908  0.4378\n",
      "      9        \u001b[36m0.6890\u001b[0m  0.4360\n",
      "     10        0.6896  0.4371\n",
      "     11        0.6903  0.4372\n",
      "     12        0.6895  0.4353\n",
      "     13        0.6897  0.4365\n",
      "     14        0.6895  0.4353\n",
      "     15        \u001b[36m0.6889\u001b[0m  0.4361\n",
      "     16        0.6893  0.4365\n",
      "     17        \u001b[36m0.6879\u001b[0m  0.4365\n",
      "     18        0.6918  0.4359\n",
      "     19        0.6887  0.4364\n",
      "     20        0.6891  0.4358\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6982\u001b[0m  0.4481\n",
      "      2        \u001b[36m0.6919\u001b[0m  0.4477\n",
      "      3        \u001b[36m0.6917\u001b[0m  0.4482\n",
      "      4        \u001b[36m0.6906\u001b[0m  0.4469\n",
      "      5        \u001b[36m0.6900\u001b[0m  0.4471\n",
      "      6        \u001b[36m0.6898\u001b[0m  0.4483\n",
      "      7        \u001b[36m0.6896\u001b[0m  0.4476\n",
      "      8        \u001b[36m0.6895\u001b[0m  0.4490\n",
      "      9        \u001b[36m0.6894\u001b[0m  0.4484\n",
      "     10        0.6895  0.4472\n",
      "     11        0.6895  0.4487\n",
      "     12        0.6895  0.4479\n",
      "     13        \u001b[36m0.6894\u001b[0m  0.4469\n",
      "     14        0.6895  0.4494\n",
      "     15        0.6899  0.4481\n",
      "     16        0.6897  0.4487\n",
      "     17        0.6895  0.4492\n",
      "     18        \u001b[36m0.6894\u001b[0m  0.4479\n",
      "     19        0.6895  0.4483\n",
      "     20        0.6897  0.4491\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6945\u001b[0m  0.4485\n",
      "      2        \u001b[36m0.6915\u001b[0m  0.4485\n",
      "      3        \u001b[36m0.6903\u001b[0m  0.4501\n",
      "      4        \u001b[36m0.6897\u001b[0m  0.4477\n",
      "      5        \u001b[36m0.6895\u001b[0m  0.4486\n",
      "      6        0.6897  0.4506\n",
      "      7        \u001b[36m0.6895\u001b[0m  0.4495\n",
      "      8        \u001b[36m0.6893\u001b[0m  0.4491\n",
      "      9        \u001b[36m0.6893\u001b[0m  0.4489\n",
      "     10        0.6894  0.4485\n",
      "     11        0.6894  0.4492\n",
      "     12        0.6894  0.4497\n",
      "     13        0.6893  0.4486\n",
      "     14        0.6894  0.4487\n",
      "     15        0.6893  0.4484\n",
      "     16        0.6895  0.4481\n",
      "     17        0.6894  0.4491\n",
      "     18        0.6895  0.4490\n",
      "     19        0.6893  0.4495\n",
      "     20        0.6894  0.4486\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6956\u001b[0m  0.4497\n",
      "      2        \u001b[36m0.6905\u001b[0m  0.4479\n",
      "      3        \u001b[36m0.6902\u001b[0m  0.4476\n",
      "      4        \u001b[36m0.6902\u001b[0m  0.4491\n",
      "      5        \u001b[36m0.6897\u001b[0m  0.4474\n",
      "      6        \u001b[36m0.6894\u001b[0m  0.4483\n",
      "      7        0.6895  0.4478\n",
      "      8        0.6895  0.4472\n",
      "      9        \u001b[36m0.6894\u001b[0m  0.4486\n",
      "     10        \u001b[36m0.6893\u001b[0m  0.4481\n",
      "     11        0.6896  0.4467\n",
      "     12        0.6897  0.4488\n",
      "     13        0.6893  0.4486\n",
      "     14        \u001b[36m0.6893\u001b[0m  0.4482\n",
      "     15        0.6895  0.4478\n",
      "     16        0.6894  0.4475\n",
      "     17        0.6895  0.4472\n",
      "     18        0.6898  0.4485\n",
      "     19        0.6895  0.4491\n",
      "     20        0.6894  0.4480\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7287\u001b[0m  0.5255\n",
      "      2        \u001b[36m0.6980\u001b[0m  0.5269\n",
      "      3        0.7124  0.5268\n",
      "      4        0.6984  0.5250\n",
      "      5        0.6994  0.5245\n",
      "      6        \u001b[36m0.6974\u001b[0m  0.5264\n",
      "      7        \u001b[36m0.6964\u001b[0m  0.5268\n",
      "      8        0.7162  0.5265\n",
      "      9        0.6979  0.5279\n",
      "     10        0.6975  0.5271\n",
      "     11        0.7050  0.5241\n",
      "     12        0.6988  0.5239\n",
      "     13        0.7061  0.5255\n",
      "     14        0.6973  0.5240\n",
      "     15        \u001b[36m0.6939\u001b[0m  0.5246\n",
      "     16        0.7004  0.5238\n",
      "     17        0.7016  0.5240\n",
      "     18        0.7070  0.5238\n",
      "     19        \u001b[36m0.6926\u001b[0m  0.5242\n",
      "     20        0.6947  0.5246\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7057\u001b[0m  0.5275\n",
      "      2        \u001b[36m0.6959\u001b[0m  0.5237\n",
      "      3        0.7045  0.5236\n",
      "      4        \u001b[36m0.6945\u001b[0m  0.5227\n",
      "      5        \u001b[36m0.6876\u001b[0m  0.5251\n",
      "      6        0.6983  0.5242\n",
      "      7        0.6962  0.5258\n",
      "      8        0.6973  0.5236\n",
      "      9        0.6964  0.5240\n",
      "     10        0.7030  0.5235\n",
      "     11        0.6963  0.5220\n",
      "     12        0.6923  0.5262\n",
      "     13        0.7040  0.5273\n",
      "     14        0.6936  0.5231\n",
      "     15        0.6921  0.5210\n",
      "     16        0.6941  0.5238\n",
      "     17        0.6951  0.5230\n",
      "     18        0.6941  0.5226\n",
      "     19        0.6914  0.5253\n",
      "     20        0.6973  0.5251\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7275\u001b[0m  0.5268\n",
      "      2        \u001b[36m0.6907\u001b[0m  0.5274\n",
      "      3        0.6979  0.5278\n",
      "      4        0.7018  0.5259\n",
      "      5        0.6945  0.5245\n",
      "      6        0.7063  0.5272\n",
      "      7        0.6989  0.5270\n",
      "      8        0.7004  0.5280\n",
      "      9        0.7014  0.5282\n",
      "     10        0.6991  0.5272\n",
      "     11        0.6968  0.5279\n",
      "     12        0.6971  0.5273\n",
      "     13        0.6920  0.5274\n",
      "     14        0.6956  0.5284\n",
      "     15        0.6982  0.5265\n",
      "     16        0.6964  0.5259\n",
      "     17        0.6983  0.5284\n",
      "     18        0.6975  0.5306\n",
      "     19        0.7004  0.5280\n",
      "     20        0.6994  0.5252\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6952\u001b[0m  0.5522\n",
      "      2        \u001b[36m0.6906\u001b[0m  0.5531\n",
      "      3        \u001b[36m0.6898\u001b[0m  0.5538\n",
      "      4        0.6898  0.5534\n",
      "      5        \u001b[36m0.6898\u001b[0m  0.5533\n",
      "      6        0.6903  0.5536\n",
      "      7        \u001b[36m0.6895\u001b[0m  0.5541\n",
      "      8        0.6898  0.5543\n",
      "      9        0.6896  0.5543\n",
      "     10        \u001b[36m0.6894\u001b[0m  0.5531\n",
      "     11        0.6897  0.5542\n",
      "     12        \u001b[36m0.6894\u001b[0m  0.5541\n",
      "     13        0.6902  0.5538\n",
      "     14        \u001b[36m0.6893\u001b[0m  0.5539\n",
      "     15        0.6898  0.5549\n",
      "     16        0.6897  0.5545\n",
      "     17        0.6895  0.5540\n",
      "     18        0.6897  0.5548\n",
      "     19        0.6895  0.5539\n",
      "     20        0.6900  0.5546\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  11.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7001\u001b[0m  0.5418\n",
      "      2        \u001b[36m0.6894\u001b[0m  0.5445\n",
      "      3        0.6899  0.5436\n",
      "      4        0.6899  0.5427\n",
      "      5        \u001b[36m0.6889\u001b[0m  0.5433\n",
      "      6        0.6901  0.5434\n",
      "      7        0.6895  0.5429\n",
      "      8        0.6897  0.5427\n",
      "      9        0.6897  0.5420\n",
      "     10        0.6893  0.5407\n",
      "     11        0.6895  0.5424\n",
      "     12        \u001b[36m0.6882\u001b[0m  0.5396\n",
      "     13        0.6898  0.5402\n",
      "     14        0.6893  0.5396\n",
      "     15        0.6896  0.5420\n",
      "     16        0.6894  0.5418\n",
      "     17        0.6896  0.5412\n",
      "     18        0.6894  0.5415\n",
      "     19        0.6894  0.5411\n",
      "     20        0.6898  0.5421\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6994\u001b[0m  0.5434\n",
      "      2        \u001b[36m0.6887\u001b[0m  0.5436\n",
      "      3        0.6898  0.5454\n",
      "      4        \u001b[36m0.6884\u001b[0m  0.5452\n",
      "      5        0.6886  0.5447\n",
      "      6        0.6903  0.5441\n",
      "      7        0.6894  0.5444\n",
      "      8        0.6890  0.5470\n",
      "      9        0.6900  0.5455\n",
      "     10        0.6896  0.5457\n",
      "     11        0.6891  0.5472\n",
      "     12        0.6889  0.5452\n",
      "     13        0.6886  0.5465\n",
      "     14        0.6887  0.5469\n",
      "     15        0.6886  0.5480\n",
      "     16        0.6892  0.5462\n",
      "     17        0.6887  0.5432\n",
      "     18        0.6897  0.5427\n",
      "     19        0.6892  0.5436\n",
      "     20        0.6889  0.5429\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  11.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7012\u001b[0m  0.5661\n",
      "      2        \u001b[36m0.6917\u001b[0m  0.5716\n",
      "      3        0.6917  0.5751\n",
      "      4        \u001b[36m0.6904\u001b[0m  0.5725\n",
      "      5        \u001b[36m0.6896\u001b[0m  0.5704\n",
      "      6        0.6898  0.5712\n",
      "      7        \u001b[36m0.6894\u001b[0m  0.5705\n",
      "      8        0.6899  0.5735\n",
      "      9        \u001b[36m0.6894\u001b[0m  0.5723\n",
      "     10        0.6895  0.5716\n",
      "     11        0.6895  0.5718\n",
      "     12        0.6899  0.5739\n",
      "     13        0.6895  0.5728\n",
      "     14        0.6896  0.5770\n",
      "     15        0.6895  0.5747\n",
      "     16        \u001b[36m0.6893\u001b[0m  0.5717\n",
      "     17        0.6895  0.5735\n",
      "     18        0.6893  0.5731\n",
      "     19        0.6896  0.5779\n",
      "     20        0.6895  0.5751\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6985\u001b[0m  0.5631\n",
      "      2        \u001b[36m0.6942\u001b[0m  0.5603\n",
      "      3        \u001b[36m0.6894\u001b[0m  0.5603\n",
      "      4        \u001b[36m0.6894\u001b[0m  0.5608\n",
      "      5        0.6898  0.5602\n",
      "      6        0.6897  0.5609\n",
      "      7        0.6895  0.5618\n",
      "      8        \u001b[36m0.6894\u001b[0m  0.5610\n",
      "      9        \u001b[36m0.6893\u001b[0m  0.5612\n",
      "     10        \u001b[36m0.6892\u001b[0m  0.5642\n",
      "     11        0.6896  0.5624\n",
      "     12        0.6893  0.5632\n",
      "     13        0.6894  0.5629\n",
      "     14        0.6895  0.5635\n",
      "     15        0.6893  0.5629\n",
      "     16        0.6895  0.5625\n",
      "     17        0.6894  0.5646\n",
      "     18        0.6894  0.5622\n",
      "     19        0.6894  0.5623\n",
      "     20        0.6894  0.5619\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7054\u001b[0m  0.5606\n",
      "      2        \u001b[36m0.6930\u001b[0m  0.5622\n",
      "      3        \u001b[36m0.6897\u001b[0m  0.5633\n",
      "      4        \u001b[36m0.6896\u001b[0m  0.5616\n",
      "      5        \u001b[36m0.6896\u001b[0m  0.5627\n",
      "      6        0.6899  0.5618\n",
      "      7        0.6899  0.5614\n",
      "      8        0.6896  0.5621\n",
      "      9        0.6898  0.5645\n",
      "     10        \u001b[36m0.6895\u001b[0m  0.5622\n",
      "     11        \u001b[36m0.6894\u001b[0m  0.5616\n",
      "     12        0.6895  0.5616\n",
      "     13        \u001b[36m0.6894\u001b[0m  0.5610\n",
      "     14        \u001b[36m0.6893\u001b[0m  0.5624\n",
      "     15        0.6896  0.5626\n",
      "     16        0.6895  0.5624\n",
      "     17        0.6895  0.5623\n",
      "     18        0.6898  0.5632\n",
      "     19        0.6893  0.5627\n",
      "     20        0.6894  0.5619\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7163\u001b[0m  0.8023\n",
      "      2        0.7204  0.8037\n",
      "      3        0.7285  0.8022\n",
      "      4        \u001b[36m0.7048\u001b[0m  0.8024\n",
      "      5        0.7050  0.8017\n",
      "      6        0.7107  0.7987\n",
      "      7        \u001b[36m0.7028\u001b[0m  0.8015\n",
      "      8        \u001b[36m0.6982\u001b[0m  0.8000\n",
      "      9        \u001b[36m0.6964\u001b[0m  0.8005\n",
      "     10        0.7019  0.8005\n",
      "     11        0.7136  0.7987\n",
      "     12        0.6965  0.8013\n",
      "     13        0.6998  0.7988\n",
      "     14        0.7058  0.8000\n",
      "     15        0.7102  0.8000\n",
      "     16        0.6989  0.8012\n",
      "     17        0.7062  0.8006\n",
      "     18        0.7118  0.7998\n",
      "     19        0.7176  0.8004\n",
      "     20        0.7032  0.8007\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7825\u001b[0m  0.8073\n",
      "      2        \u001b[36m0.6988\u001b[0m  0.8080\n",
      "      3        0.7052  0.8089\n",
      "      4        0.7009  0.8075\n",
      "      5        0.7069  0.8059\n",
      "      6        0.7070  0.8058\n",
      "      7        0.7073  0.8062\n",
      "      8        0.7171  0.8055\n",
      "      9        0.7027  0.8062\n",
      "     10        0.7124  0.8109\n",
      "     11        0.7079  0.8062\n",
      "     12        0.7124  0.8061\n",
      "     13        0.7045  0.8072\n",
      "     14        0.7056  0.8118\n",
      "     15        0.7164  0.8070\n",
      "     16        0.7064  0.8055\n",
      "     17        0.7037  0.8052\n",
      "     18        \u001b[36m0.6979\u001b[0m  0.8113\n",
      "     19        0.7170  0.8061\n",
      "     20        0.7225  0.8072\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  16.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7406\u001b[0m  0.8010\n",
      "      2        \u001b[36m0.7097\u001b[0m  0.8014\n",
      "      3        \u001b[36m0.7066\u001b[0m  0.8021\n",
      "      4        0.7151  0.8013\n",
      "      5        0.7106  0.8009\n",
      "      6        0.7119  0.8014\n",
      "      7        \u001b[36m0.7054\u001b[0m  0.8014\n",
      "      8        \u001b[36m0.7003\u001b[0m  0.8020\n",
      "      9        0.7141  0.8002\n",
      "     10        0.7175  0.8008\n",
      "     11        0.7130  0.8005\n",
      "     12        0.7035  0.8007\n",
      "     13        0.7042  0.8007\n",
      "     14        0.7071  0.8001\n",
      "     15        0.7138  0.8007\n",
      "     16        0.7241  0.8010\n",
      "     17        0.7228  0.8009\n",
      "     18        0.7102  0.8016\n",
      "     19        0.7003  0.8015\n",
      "     20        \u001b[36m0.6971\u001b[0m  0.8027\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7208\u001b[0m  0.8444\n",
      "      2        \u001b[36m0.6897\u001b[0m  0.8433\n",
      "      3        0.6900  0.8472\n",
      "      4        0.6897  0.8430\n",
      "      5        \u001b[36m0.6893\u001b[0m  0.8423\n",
      "      6        0.6894  0.8436\n",
      "      7        0.6895  0.8428\n",
      "      8        \u001b[36m0.6891\u001b[0m  0.8435\n",
      "      9        \u001b[36m0.6890\u001b[0m  0.8446\n",
      "     10        0.6892  0.8444\n",
      "     11        0.6892  0.8444\n",
      "     12        \u001b[36m0.6889\u001b[0m  0.8447\n",
      "     13        0.6889  0.8432\n",
      "     14        0.6890  0.8442\n",
      "     15        \u001b[36m0.6887\u001b[0m  0.8476\n",
      "     16        \u001b[36m0.6884\u001b[0m  0.8444\n",
      "     17        0.6888  0.8434\n",
      "     18        0.6886  0.8455\n",
      "     19        0.6886  0.8462\n",
      "     20        \u001b[36m0.6881\u001b[0m  0.8458\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  17.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6958\u001b[0m  0.8324\n",
      "      2        \u001b[36m0.6906\u001b[0m  0.8344\n",
      "      3        \u001b[36m0.6900\u001b[0m  0.8335\n",
      "      4        \u001b[36m0.6894\u001b[0m  0.8330\n",
      "      5        0.6900  0.8322\n",
      "      6        0.6904  0.8311\n",
      "      7        0.6907  0.8347\n",
      "      8        0.6895  0.8320\n",
      "      9        0.6898  0.8328\n",
      "     10        0.6900  0.8325\n",
      "     11        0.6899  0.8332\n",
      "     12        0.6907  0.8321\n",
      "     13        0.6909  0.8324\n",
      "     14        0.6903  0.8337\n",
      "     15        0.6896  0.8339\n",
      "     16        0.6898  0.8381\n",
      "     17        0.6906  0.8338\n",
      "     18        0.6910  0.8404\n",
      "     19        0.6909  0.8348\n",
      "     20        0.6910  0.8363\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  16.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7062\u001b[0m  0.8374\n",
      "      2        \u001b[36m0.6903\u001b[0m  0.8408\n",
      "      3        \u001b[36m0.6896\u001b[0m  0.8437\n",
      "      4        0.6897  0.8395\n",
      "      5        \u001b[36m0.6894\u001b[0m  0.8394\n",
      "      6        0.6896  0.8409\n",
      "      7        0.6898  0.8413\n",
      "      8        0.6897  0.8440\n",
      "      9        0.6895  0.8424\n",
      "     10        0.6900  0.8415\n",
      "     11        0.6894  0.8409\n",
      "     12        0.6898  0.8436\n",
      "     13        0.6894  0.8433\n",
      "     14        0.6896  0.8455\n",
      "     15        0.6896  0.8450\n",
      "     16        0.6900  0.8460\n",
      "     17        0.6895  0.8450\n",
      "     18        0.6898  0.8435\n",
      "     19        0.6899  0.8440\n",
      "     20        0.6899  0.8447\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  17.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7335\u001b[0m  0.8647\n",
      "      2        \u001b[36m0.6930\u001b[0m  0.8735\n",
      "      3        \u001b[36m0.6925\u001b[0m  0.8663\n",
      "      4        \u001b[36m0.6890\u001b[0m  0.8664\n",
      "      5        0.6898  0.8665\n",
      "      6        0.6897  0.8648\n",
      "      7        0.6899  0.8655\n",
      "      8        0.6893  0.8649\n",
      "      9        0.6895  0.8667\n",
      "     10        0.6894  0.8671\n",
      "     11        0.6896  0.8667\n",
      "     12        0.6895  0.8671\n",
      "     13        0.6894  0.8670\n",
      "     14        0.6898  0.8666\n",
      "     15        0.6895  0.8668\n",
      "     16        0.6896  0.8673\n",
      "     17        0.6897  0.8670\n",
      "     18        0.6896  0.8693\n",
      "     19        0.6895  0.8682\n",
      "     20        0.6896  0.8677\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  17.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7156\u001b[0m  0.8598\n",
      "      2        0.7192  0.8596\n",
      "      3        \u001b[36m0.6989\u001b[0m  0.8577\n",
      "      4        \u001b[36m0.6974\u001b[0m  0.8587\n",
      "      5        \u001b[36m0.6959\u001b[0m  0.8585\n",
      "      6        \u001b[36m0.6932\u001b[0m  0.8577\n",
      "      7        \u001b[36m0.6908\u001b[0m  0.8567\n",
      "      8        0.6939  0.8565\n",
      "      9        0.6918  0.8556\n",
      "     10        \u001b[36m0.6897\u001b[0m  0.8564\n",
      "     11        0.6900  0.8562\n",
      "     12        0.6899  0.8555\n",
      "     13        \u001b[36m0.6894\u001b[0m  0.8568\n",
      "     14        0.6900  0.8562\n",
      "     15        0.6894  0.8562\n",
      "     16        0.6895  0.8573\n",
      "     17        0.6895  0.8578\n",
      "     18        0.6898  0.8568\n",
      "     19        \u001b[36m0.6894\u001b[0m  0.8588\n",
      "     20        0.6895  0.8601\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  17.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7145\u001b[0m  0.8670\n",
      "      2        \u001b[36m0.6985\u001b[0m  0.8619\n",
      "      3        \u001b[36m0.6946\u001b[0m  0.8626\n",
      "      4        \u001b[36m0.6905\u001b[0m  0.8636\n",
      "      5        \u001b[36m0.6898\u001b[0m  0.8668\n",
      "      6        0.6911  0.8629\n",
      "      7        0.6908  0.8630\n",
      "      8        \u001b[36m0.6895\u001b[0m  0.8620\n",
      "      9        \u001b[36m0.6894\u001b[0m  0.8660\n",
      "     10        0.6898  0.8627\n",
      "     11        0.6899  0.8628\n",
      "     12        0.6895  0.8638\n",
      "     13        0.6894  0.8636\n",
      "     14        0.6897  0.8629\n",
      "     15        0.6896  0.8629\n",
      "     16        0.6894  0.8655\n",
      "     17        0.6895  0.8642\n",
      "     18        0.6896  0.8660\n",
      "     19        \u001b[36m0.6891\u001b[0m  0.8643\n",
      "     20        0.6899  0.8637\n",
      "[CV] END lr=0.01, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  17.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6923\u001b[0m  0.4209\n",
      "      2        0.6991  0.4199\n",
      "      3        0.7014  0.4205\n",
      "      4        0.6986  0.4206\n",
      "      5        0.7002  0.4196\n",
      "      6        0.6961  0.4193\n",
      "      7        0.6981  0.4204\n",
      "      8        0.6993  0.4194\n",
      "      9        0.7005  0.4198\n",
      "     10        0.6970  0.4206\n",
      "     11        0.6932  0.4203\n",
      "     12        0.7040  0.4193\n",
      "     13        0.6980  0.4200\n",
      "     14        0.6960  0.4187\n",
      "     15        0.7003  0.4198\n",
      "     16        0.6998  0.4204\n",
      "     17        0.6958  0.4208\n",
      "     18        0.7030  0.4198\n",
      "     19        0.6987  0.4203\n",
      "     20        0.7013  0.4201\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7101\u001b[0m  0.4198\n",
      "      2        \u001b[36m0.6922\u001b[0m  0.4209\n",
      "      3        0.6998  0.4205\n",
      "      4        0.7083  0.4191\n",
      "      5        0.6974  0.4204\n",
      "      6        0.6986  0.4200\n",
      "      7        0.7080  0.4202\n",
      "      8        0.7004  0.4203\n",
      "      9        0.6995  0.4208\n",
      "     10        0.6960  0.4197\n",
      "     11        0.6952  0.4206\n",
      "     12        0.6986  0.4208\n",
      "     13        0.7027  0.4201\n",
      "     14        0.7051  0.4197\n",
      "     15        0.6990  0.4207\n",
      "     16        0.7066  0.4200\n",
      "     17        0.7052  0.4199\n",
      "     18        0.6998  0.4205\n",
      "     19        0.7063  0.4201\n",
      "     20        0.6950  0.4201\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7062\u001b[0m  0.4210\n",
      "      2        \u001b[36m0.6925\u001b[0m  0.4201\n",
      "      3        0.7070  0.4186\n",
      "      4        \u001b[36m0.6900\u001b[0m  0.4203\n",
      "      5        0.6952  0.4196\n",
      "      6        0.7019  0.4196\n",
      "      7        0.6985  0.4190\n",
      "      8        0.7015  0.4201\n",
      "      9        0.6966  0.4191\n",
      "     10        0.6979  0.4197\n",
      "     11        0.7015  0.4202\n",
      "     12        0.7012  0.4191\n",
      "     13        0.7032  0.4189\n",
      "     14        0.7173  0.4204\n",
      "     15        0.6958  0.4200\n",
      "     16        0.6959  0.4191\n",
      "     17        0.6953  0.4199\n",
      "     18        0.6947  0.4194\n",
      "     19        0.6964  0.4184\n",
      "     20        0.6944  0.4205\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6999\u001b[0m  0.4341\n",
      "      2        0.7045  0.4314\n",
      "      3        0.7006  0.4314\n",
      "      4        \u001b[36m0.6977\u001b[0m  0.4323\n",
      "      5        \u001b[36m0.6943\u001b[0m  0.4313\n",
      "      6        \u001b[36m0.6931\u001b[0m  0.4343\n",
      "      7        0.7005  0.4310\n",
      "      8        0.6950  0.4311\n",
      "      9        0.7125  0.4314\n",
      "     10        0.7064  0.4319\n",
      "     11        0.6986  0.4315\n",
      "     12        0.6986  0.4324\n",
      "     13        \u001b[36m0.6910\u001b[0m  0.4312\n",
      "     14        0.7040  0.4325\n",
      "     15        0.6945  0.4330\n",
      "     16        0.7070  0.4330\n",
      "     17        0.7011  0.4314\n",
      "     18        0.7010  0.4309\n",
      "     19        0.6982  0.4316\n",
      "     20        0.6960  0.4317\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7022\u001b[0m  0.4367\n",
      "      2        \u001b[36m0.6921\u001b[0m  0.4335\n",
      "      3        0.6996  0.4330\n",
      "      4        0.6995  0.4339\n",
      "      5        0.7012  0.4338\n",
      "      6        0.6999  0.4336\n",
      "      7        0.7086  0.4351\n",
      "      8        0.7050  0.4346\n",
      "      9        0.7019  0.4343\n",
      "     10        0.6941  0.4345\n",
      "     11        0.7055  0.4339\n",
      "     12        0.6938  0.4333\n",
      "     13        0.6979  0.4339\n",
      "     14        0.6955  0.4360\n",
      "     15        0.7138  0.4350\n",
      "     16        0.7026  0.4343\n",
      "     17        0.6973  0.4342\n",
      "     18        0.7062  0.4338\n",
      "     19        0.7148  0.4331\n",
      "     20        0.6969  0.4336\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6996\u001b[0m  0.4350\n",
      "      2        0.7044  0.4340\n",
      "      3        \u001b[36m0.6975\u001b[0m  0.4347\n",
      "      4        \u001b[36m0.6943\u001b[0m  0.4344\n",
      "      5        0.6993  0.4335\n",
      "      6        0.7008  0.4325\n",
      "      7        0.6982  0.4343\n",
      "      8        0.7036  0.4343\n",
      "      9        \u001b[36m0.6937\u001b[0m  0.4341\n",
      "     10        0.6995  0.4344\n",
      "     11        0.7106  0.4329\n",
      "     12        0.7004  0.4354\n",
      "     13        0.6986  0.4358\n",
      "     14        0.6953  0.4356\n",
      "     15        0.6964  0.4352\n",
      "     16        0.6942  0.4339\n",
      "     17        0.6997  0.4338\n",
      "     18        0.6989  0.4348\n",
      "     19        0.6976  0.4343\n",
      "     20        0.7021  0.4341\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6984\u001b[0m  0.4497\n",
      "      2        0.6995  0.4475\n",
      "      3        \u001b[36m0.6976\u001b[0m  0.4471\n",
      "      4        \u001b[36m0.6973\u001b[0m  0.4482\n",
      "      5        0.7000  0.4472\n",
      "      6        0.6974  0.4480\n",
      "      7        0.7079  0.4467\n",
      "      8        0.6989  0.4473\n",
      "      9        0.6995  0.4463\n",
      "     10        0.6979  0.4470\n",
      "     11        \u001b[36m0.6944\u001b[0m  0.4464\n",
      "     12        0.6989  0.4473\n",
      "     13        0.6999  0.4480\n",
      "     14        0.7083  0.4478\n",
      "     15        0.6969  0.4460\n",
      "     16        0.7034  0.4469\n",
      "     17        0.7036  0.4476\n",
      "     18        0.7007  0.4461\n",
      "     19        0.6948  0.4478\n",
      "     20        0.6952  0.4477\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6957\u001b[0m  0.4471\n",
      "      2        0.6960  0.4465\n",
      "      3        0.6987  0.4448\n",
      "      4        \u001b[36m0.6938\u001b[0m  0.4469\n",
      "      5        0.7025  0.4461\n",
      "      6        0.7006  0.4454\n",
      "      7        0.6946  0.4455\n",
      "      8        0.7022  0.4467\n",
      "      9        0.7064  0.4456\n",
      "     10        0.7049  0.4466\n",
      "     11        0.7020  0.4463\n",
      "     12        0.6943  0.4461\n",
      "     13        0.6977  0.4463\n",
      "     14        0.7036  0.4460\n",
      "     15        0.6986  0.4458\n",
      "     16        0.6989  0.4463\n",
      "     17        0.6971  0.4459\n",
      "     18        0.7044  0.4445\n",
      "     19        0.6968  0.4454\n",
      "     20        0.7017  0.4457\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7054\u001b[0m  0.4487\n",
      "      2        \u001b[36m0.6955\u001b[0m  0.4468\n",
      "      3        \u001b[36m0.6951\u001b[0m  0.4473\n",
      "      4        0.6965  0.4461\n",
      "      5        0.6973  0.4461\n",
      "      6        0.7053  0.4474\n",
      "      7        0.6975  0.4466\n",
      "      8        0.7081  0.4450\n",
      "      9        \u001b[36m0.6949\u001b[0m  0.4462\n",
      "     10        0.6954  0.4461\n",
      "     11        0.7018  0.4470\n",
      "     12        0.7063  0.4464\n",
      "     13        0.7088  0.4457\n",
      "     14        0.6962  0.4468\n",
      "     15        0.6977  0.4473\n",
      "     16        \u001b[36m0.6945\u001b[0m  0.4465\n",
      "     17        0.7062  0.4473\n",
      "     18        0.7003  0.4463\n",
      "     19        0.7039  0.4459\n",
      "     20        0.6977  0.4461\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7364\u001b[0m  0.5183\n",
      "      2        \u001b[36m0.7089\u001b[0m  0.5169\n",
      "      3        \u001b[36m0.7070\u001b[0m  0.5177\n",
      "      4        0.7103  0.5176\n",
      "      5        \u001b[36m0.6963\u001b[0m  0.5175\n",
      "      6        0.7120  0.5166\n",
      "      7        0.7012  0.5164\n",
      "      8        0.7027  0.5167\n",
      "      9        0.7028  0.5161\n",
      "     10        0.7136  0.5171\n",
      "     11        0.7068  0.5181\n",
      "     12        0.7004  0.5178\n",
      "     13        0.7157  0.5170\n",
      "     14        0.6965  0.5173\n",
      "     15        0.7103  0.5184\n",
      "     16        0.7112  0.5169\n",
      "     17        0.7107  0.5167\n",
      "     18        0.7015  0.5166\n",
      "     19        0.7243  0.5171\n",
      "     20        0.7018  0.5168\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7691\u001b[0m  0.5183\n",
      "      2        \u001b[36m0.7064\u001b[0m  0.5170\n",
      "      3        0.7176  0.5181\n",
      "      4        0.7228  0.5190\n",
      "      5        \u001b[36m0.6998\u001b[0m  0.5172\n",
      "      6        0.7112  0.5148\n",
      "      7        0.7172  0.5155\n",
      "      8        0.7177  0.5171\n",
      "      9        0.7095  0.5180\n",
      "     10        0.7048  0.5169\n",
      "     11        0.7076  0.5180\n",
      "     12        0.7491  0.5164\n",
      "     13        0.7039  0.5194\n",
      "     14        0.7080  0.5175\n",
      "     15        0.7178  0.5175\n",
      "     16        \u001b[36m0.6967\u001b[0m  0.5172\n",
      "     17        0.7013  0.5160\n",
      "     18        0.7147  0.5172\n",
      "     19        0.7046  0.5192\n",
      "     20        0.7063  0.5132\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7115\u001b[0m  0.5121\n",
      "      2        \u001b[36m0.7028\u001b[0m  0.5122\n",
      "      3        0.7168  0.5112\n",
      "      4        0.7117  0.5138\n",
      "      5        \u001b[36m0.6999\u001b[0m  0.5168\n",
      "      6        0.7040  0.5145\n",
      "      7        0.7276  0.5136\n",
      "      8        0.7017  0.5154\n",
      "      9        0.7127  0.5156\n",
      "     10        0.7129  0.5137\n",
      "     11        0.7073  0.5157\n",
      "     12        0.7029  0.5157\n",
      "     13        0.7019  0.5161\n",
      "     14        0.7007  0.5157\n",
      "     15        \u001b[36m0.6969\u001b[0m  0.5170\n",
      "     16        0.7099  0.5160\n",
      "     17        0.6976  0.5174\n",
      "     18        \u001b[36m0.6958\u001b[0m  0.5168\n",
      "     19        0.7097  0.5159\n",
      "     20        0.6973  0.5151\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7213\u001b[0m  0.5369\n",
      "      2        \u001b[36m0.7130\u001b[0m  0.5379\n",
      "      3        \u001b[36m0.7112\u001b[0m  0.5382\n",
      "      4        \u001b[36m0.7027\u001b[0m  0.5391\n",
      "      5        0.7067  0.5374\n",
      "      6        0.7122  0.5377\n",
      "      7        0.7057  0.5377\n",
      "      8        0.7148  0.5418\n",
      "      9        0.7147  0.5433\n",
      "     10        \u001b[36m0.6990\u001b[0m  0.5414\n",
      "     11        0.7149  0.5422\n",
      "     12        0.7151  0.5408\n",
      "     13        0.7073  0.5391\n",
      "     14        0.7140  0.5390\n",
      "     15        0.7119  0.5408\n",
      "     16        0.7115  0.5391\n",
      "     17        0.7109  0.5398\n",
      "     18        0.7076  0.5386\n",
      "     19        0.7139  0.5388\n",
      "     20        0.7078  0.5376\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  10.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7275\u001b[0m  0.5341\n",
      "      2        \u001b[36m0.7117\u001b[0m  0.5343\n",
      "      3        \u001b[36m0.7033\u001b[0m  0.5344\n",
      "      4        \u001b[36m0.6994\u001b[0m  0.5352\n",
      "      5        0.7053  0.5343\n",
      "      6        0.7030  0.5351\n",
      "      7        0.7116  0.5366\n",
      "      8        0.7091  0.5351\n",
      "      9        0.7068  0.5345\n",
      "     10        0.7081  0.5345\n",
      "     11        0.7136  0.5349\n",
      "     12        0.7089  0.5353\n",
      "     13        0.7140  0.5356\n",
      "     14        0.7052  0.5376\n",
      "     15        0.7043  0.5337\n",
      "     16        0.7021  0.5343\n",
      "     17        0.7052  0.5333\n",
      "     18        0.7094  0.5346\n",
      "     19        0.7130  0.5342\n",
      "     20        \u001b[36m0.6992\u001b[0m  0.5350\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  10.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7262\u001b[0m  0.5373\n",
      "      2        \u001b[36m0.7074\u001b[0m  0.5348\n",
      "      3        \u001b[36m0.7053\u001b[0m  0.5350\n",
      "      4        \u001b[36m0.6993\u001b[0m  0.5351\n",
      "      5        0.7037  0.5354\n",
      "      6        0.7147  0.5353\n",
      "      7        0.7007  0.5355\n",
      "      8        0.7061  0.5359\n",
      "      9        0.7058  0.5354\n",
      "     10        0.7048  0.5352\n",
      "     11        0.7045  0.5387\n",
      "     12        0.7173  0.5377\n",
      "     13        0.7072  0.5358\n",
      "     14        0.7098  0.5372\n",
      "     15        0.7144  0.5356\n",
      "     16        0.7205  0.5381\n",
      "     17        0.7245  0.5381\n",
      "     18        0.7097  0.5380\n",
      "     19        0.7198  0.5345\n",
      "     20        0.7098  0.5387\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  10.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7246\u001b[0m  0.5546\n",
      "      2        \u001b[36m0.7011\u001b[0m  0.5580\n",
      "      3        0.7104  0.5583\n",
      "      4        \u001b[36m0.6976\u001b[0m  0.5603\n",
      "      5        0.7000  0.5616\n",
      "      6        0.7177  0.5633\n",
      "      7        0.7062  0.5639\n",
      "      8        0.7086  0.5645\n",
      "      9        0.7114  0.5646\n",
      "     10        0.7170  0.5642\n",
      "     11        0.7105  0.5603\n",
      "     12        0.7078  0.5567\n",
      "     13        \u001b[36m0.6968\u001b[0m  0.5592\n",
      "     14        0.7062  0.5618\n",
      "     15        0.7006  0.5623\n",
      "     16        0.7052  0.5644\n",
      "     17        0.7124  0.5631\n",
      "     18        0.7168  0.5634\n",
      "     19        0.7027  0.5651\n",
      "     20        0.7119  0.5644\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7197\u001b[0m  0.5572\n",
      "      2        \u001b[36m0.7114\u001b[0m  0.5595\n",
      "      3        \u001b[36m0.7070\u001b[0m  0.5598\n",
      "      4        \u001b[36m0.7049\u001b[0m  0.5600\n",
      "      5        0.7055  0.5594\n",
      "      6        0.7077  0.5625\n",
      "      7        \u001b[36m0.7045\u001b[0m  0.5604\n",
      "      8        0.7139  0.5590\n",
      "      9        0.7138  0.5621\n",
      "     10        \u001b[36m0.7036\u001b[0m  0.5607\n",
      "     11        0.7262  0.5632\n",
      "     12        0.7112  0.5625\n",
      "     13        0.7086  0.5610\n",
      "     14        0.7131  0.5604\n",
      "     15        0.7115  0.5601\n",
      "     16        0.7122  0.5601\n",
      "     17        0.7074  0.5601\n",
      "     18        0.7104  0.5601\n",
      "     19        0.7154  0.5593\n",
      "     20        0.7085  0.5617\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7205\u001b[0m  0.5587\n",
      "      2        \u001b[36m0.7087\u001b[0m  0.5544\n",
      "      3        0.7089  0.5593\n",
      "      4        \u001b[36m0.7030\u001b[0m  0.5617\n",
      "      5        \u001b[36m0.7014\u001b[0m  0.5583\n",
      "      6        0.7045  0.5565\n",
      "      7        0.7089  0.5622\n",
      "      8        0.7142  0.5622\n",
      "      9        0.7184  0.5606\n",
      "     10        0.7032  0.5566\n",
      "     11        0.7015  0.5538\n",
      "     12        0.7131  0.5579\n",
      "     13        0.7120  0.5606\n",
      "     14        0.7099  0.5603\n",
      "     15        \u001b[36m0.7013\u001b[0m  0.5622\n",
      "     16        0.7058  0.5592\n",
      "     17        0.7021  0.5589\n",
      "     18        0.7163  0.5579\n",
      "     19        0.7094  0.5614\n",
      "     20        0.7092  0.5619\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7880\u001b[0m  0.7999\n",
      "      2        \u001b[36m0.7062\u001b[0m  0.7994\n",
      "      3        0.7267  0.7984\n",
      "      4        0.7109  0.7975\n",
      "      5        0.7441  0.7971\n",
      "      6        0.7619  0.7970\n",
      "      7        0.7145  0.7969\n",
      "      8        0.7135  0.7975\n",
      "      9        0.7552  0.7978\n",
      "     10        0.7242  0.7980\n",
      "     11        0.7263  0.7965\n",
      "     12        0.7447  0.7964\n",
      "     13        0.7420  0.7976\n",
      "     14        0.7257  0.7972\n",
      "     15        0.7065  0.7981\n",
      "     16        0.7124  0.7977\n",
      "     17        0.7182  0.7969\n",
      "     18        0.7414  0.7967\n",
      "     19        0.7237  0.7977\n",
      "     20        0.7074  0.7966\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  16.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8317\u001b[0m  0.7968\n",
      "      2        \u001b[36m0.7116\u001b[0m  0.7948\n",
      "      3        \u001b[36m0.7093\u001b[0m  0.7941\n",
      "      4        0.7311  0.7940\n",
      "      5        0.7265  0.7938\n",
      "      6        0.7356  0.7940\n",
      "      7        \u001b[36m0.7060\u001b[0m  0.7946\n",
      "      8        0.7273  0.7942\n",
      "      9        0.7780  0.7940\n",
      "     10        0.7806  0.7941\n",
      "     11        0.7169  0.7948\n",
      "     12        \u001b[36m0.7055\u001b[0m  0.7945\n",
      "     13        0.7400  0.7934\n",
      "     14        0.7079  0.7934\n",
      "     15        0.7287  0.7939\n",
      "     16        0.7215  0.7930\n",
      "     17        0.7153  0.7932\n",
      "     18        0.7333  0.7927\n",
      "     19        0.7396  0.7929\n",
      "     20        0.7097  0.7932\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  16.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7933\u001b[0m  0.7989\n",
      "      2        \u001b[36m0.7171\u001b[0m  0.7965\n",
      "      3        \u001b[36m0.7077\u001b[0m  0.7952\n",
      "      4        \u001b[36m0.7034\u001b[0m  0.7961\n",
      "      5        \u001b[36m0.6983\u001b[0m  0.7967\n",
      "      6        0.7092  0.7996\n",
      "      7        0.7109  0.7963\n",
      "      8        0.7359  0.7952\n",
      "      9        0.7167  0.7993\n",
      "     10        0.7144  0.7952\n",
      "     11        0.7424  0.7962\n",
      "     12        0.7134  0.7953\n",
      "     13        0.7030  0.7996\n",
      "     14        0.7315  0.7947\n",
      "     15        0.7164  0.7952\n",
      "     16        0.7098  0.7940\n",
      "     17        0.7426  0.7956\n",
      "     18        0.7166  0.7947\n",
      "     19        0.7147  0.7940\n",
      "     20        0.7201  0.7946\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  16.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7707\u001b[0m  0.8274\n",
      "      2        \u001b[36m0.7154\u001b[0m  0.8240\n",
      "      3        0.7378  0.8232\n",
      "      4        \u001b[36m0.7118\u001b[0m  0.8251\n",
      "      5        0.7224  0.8235\n",
      "      6        \u001b[36m0.7096\u001b[0m  0.8247\n",
      "      7        0.7159  0.8229\n",
      "      8        0.7258  0.8269\n",
      "      9        0.7305  0.8229\n",
      "     10        0.7535  0.8239\n",
      "     11        0.7328  0.8228\n",
      "     12        0.7316  0.8241\n",
      "     13        \u001b[36m0.7063\u001b[0m  0.8238\n",
      "     14        0.7239  0.8209\n",
      "     15        0.7095  0.8236\n",
      "     16        0.7463  0.8223\n",
      "     17        0.7595  0.8229\n",
      "     18        0.7636  0.8227\n",
      "     19        0.7652  0.8224\n",
      "     20        0.7219  0.8232\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8373\u001b[0m  0.8274\n",
      "      2        \u001b[36m0.7218\u001b[0m  0.8241\n",
      "      3        \u001b[36m0.7191\u001b[0m  0.8235\n",
      "      4        0.7199  0.8235\n",
      "      5        0.7266  0.8234\n",
      "      6        0.7292  0.8248\n",
      "      7        \u001b[36m0.7184\u001b[0m  0.8236\n",
      "      8        0.7291  0.8239\n",
      "      9        \u001b[36m0.7109\u001b[0m  0.8247\n",
      "     10        0.7549  0.8255\n",
      "     11        \u001b[36m0.7073\u001b[0m  0.8228\n",
      "     12        0.7185  0.8231\n",
      "     13        0.7149  0.8253\n",
      "     14        0.7421  0.8238\n",
      "     15        0.7371  0.8235\n",
      "     16        0.7136  0.8254\n",
      "     17        0.7525  0.8239\n",
      "     18        0.7640  0.8225\n",
      "     19        0.7635  0.8237\n",
      "     20        0.7281  0.8250\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7824\u001b[0m  0.8257\n",
      "      2        \u001b[36m0.7275\u001b[0m  0.8261\n",
      "      3        0.7299  0.8245\n",
      "      4        \u001b[36m0.7108\u001b[0m  0.8258\n",
      "      5        0.7138  0.8244\n",
      "      6        0.7312  0.8237\n",
      "      7        0.7301  0.8254\n",
      "      8        0.7141  0.8263\n",
      "      9        0.7170  0.8252\n",
      "     10        0.7284  0.8303\n",
      "     11        0.7737  0.8242\n",
      "     12        0.7154  0.8272\n",
      "     13        0.7494  0.8254\n",
      "     14        0.7176  0.8318\n",
      "     15        0.7398  0.8253\n",
      "     16        0.7109  0.8253\n",
      "     17        0.7242  0.8258\n",
      "     18        0.7247  0.8305\n",
      "     19        0.7166  0.8253\n",
      "     20        0.7308  0.8227\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8038\u001b[0m  0.8577\n",
      "      2        \u001b[36m0.7110\u001b[0m  0.8577\n",
      "      3        0.7203  0.8565\n",
      "      4        0.7508  0.8587\n",
      "      5        0.7193  0.8559\n",
      "      6        0.7139  0.8565\n",
      "      7        0.7436  0.8563\n",
      "      8        0.7174  0.8552\n",
      "      9        0.7141  0.8570\n",
      "     10        0.7151  0.8556\n",
      "     11        0.7449  0.8560\n",
      "     12        0.7284  0.8550\n",
      "     13        \u001b[36m0.7045\u001b[0m  0.8547\n",
      "     14        0.7146  0.8569\n",
      "     15        0.7477  0.8557\n",
      "     16        \u001b[36m0.7036\u001b[0m  0.8567\n",
      "     17        0.7216  0.8621\n",
      "     18        0.7415  0.8545\n",
      "     19        0.7044  0.8549\n",
      "     20        0.7092  0.8558\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  17.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7608\u001b[0m  0.8547\n",
      "      2        \u001b[36m0.7277\u001b[0m  0.8554\n",
      "      3        \u001b[36m0.7018\u001b[0m  0.8550\n",
      "      4        0.7237  0.8531\n",
      "      5        0.7092  0.8533\n",
      "      6        0.7424  0.8514\n",
      "      7        0.7277  0.8557\n",
      "      8        0.7306  0.8526\n",
      "      9        0.7231  0.8537\n",
      "     10        0.7149  0.8546\n",
      "     11        0.7140  0.8534\n",
      "     12        0.7364  0.8534\n",
      "     13        0.7156  0.8543\n",
      "     14        0.7641  0.8531\n",
      "     15        0.7297  0.8541\n",
      "     16        0.7342  0.8544\n",
      "     17        0.7121  0.8544\n",
      "     18        0.7406  0.8550\n",
      "     19        0.7028  0.8561\n",
      "     20        0.7173  0.8571\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  17.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7859\u001b[0m  0.8539\n",
      "      2        \u001b[36m0.7398\u001b[0m  0.8522\n",
      "      3        \u001b[36m0.7314\u001b[0m  0.8513\n",
      "      4        \u001b[36m0.7293\u001b[0m  0.8519\n",
      "      5        \u001b[36m0.7218\u001b[0m  0.8527\n",
      "      6        0.7395  0.8521\n",
      "      7        \u001b[36m0.7177\u001b[0m  0.8522\n",
      "      8        0.7206  0.8528\n",
      "      9        0.7322  0.8522\n",
      "     10        \u001b[36m0.7103\u001b[0m  0.8535\n",
      "     11        \u001b[36m0.7067\u001b[0m  0.8547\n",
      "     12        \u001b[36m0.7054\u001b[0m  0.8540\n",
      "     13        0.7278  0.8544\n",
      "     14        0.7180  0.8543\n",
      "     15        0.7657  0.8537\n",
      "     16        0.7182  0.8563\n",
      "     17        0.7549  0.8546\n",
      "     18        0.7328  0.8535\n",
      "     19        0.7520  0.8573\n",
      "     20        0.7319  0.8531\n",
      "[CV] END lr=0.01, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  17.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m20.9140\u001b[0m  0.4223\n",
      "      2        \u001b[36m0.6924\u001b[0m  0.4215\n",
      "      3        \u001b[36m0.6915\u001b[0m  0.4206\n",
      "      4        \u001b[36m0.6904\u001b[0m  0.4221\n",
      "      5        0.6912  0.4220\n",
      "      6        0.6911  0.4201\n",
      "      7        0.6914  0.4219\n",
      "      8        \u001b[36m0.6903\u001b[0m  0.4232\n",
      "      9        0.6917  0.4221\n",
      "     10        0.6904  0.4220\n",
      "     11        0.6905  0.4217\n",
      "     12        0.6911  0.4212\n",
      "     13        0.6909  0.4216\n",
      "     14        0.6930  0.4216\n",
      "     15        0.6924  0.4207\n",
      "     16        0.6907  0.4219\n",
      "     17        \u001b[36m0.6901\u001b[0m  0.4221\n",
      "     18        \u001b[36m0.6901\u001b[0m  0.4231\n",
      "     19        0.6916  0.4220\n",
      "     20        0.6914  0.4230\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m13.9257\u001b[0m  0.4233\n",
      "      2        \u001b[36m0.6926\u001b[0m  0.4232\n",
      "      3        \u001b[36m0.6916\u001b[0m  0.4223\n",
      "      4        \u001b[36m0.6893\u001b[0m  0.4224\n",
      "      5        0.6922  0.4210\n",
      "      6        0.6907  0.4215\n",
      "      7        0.6919  0.4220\n",
      "      8        0.6903  0.4225\n",
      "      9        0.6915  0.4222\n",
      "     10        0.6918  0.4225\n",
      "     11        0.6925  0.4211\n",
      "     12        0.6946  0.4227\n",
      "     13        0.6909  0.4236\n",
      "     14        0.6912  0.4217\n",
      "     15        0.6908  0.4226\n",
      "     16        0.6905  0.4220\n",
      "     17        0.6909  0.4211\n",
      "     18        0.6917  0.4235\n",
      "     19        0.6920  0.4237\n",
      "     20        0.6908  0.4228\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m21.7797\u001b[0m  0.4232\n",
      "      2        \u001b[36m0.6910\u001b[0m  0.4240\n",
      "      3        \u001b[36m0.6907\u001b[0m  0.4226\n",
      "      4        0.6921  0.4227\n",
      "      5        0.6910  0.4226\n",
      "      6        \u001b[36m0.6901\u001b[0m  0.4219\n",
      "      7        0.6913  0.4221\n",
      "      8        0.6922  0.4224\n",
      "      9        0.6913  0.4225\n",
      "     10        0.6918  0.4225\n",
      "     11        0.6908  0.4230\n",
      "     12        0.6920  0.4231\n",
      "     13        0.6916  0.4219\n",
      "     14        0.6917  0.4234\n",
      "     15        0.6912  0.4229\n",
      "     16        \u001b[36m0.6897\u001b[0m  0.4225\n",
      "     17        0.6934  0.4218\n",
      "     18        0.6907  0.4230\n",
      "     19        0.6912  0.4215\n",
      "     20        0.6913  0.4219\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m28.2700\u001b[0m  0.4376\n",
      "      2        \u001b[36m1.1128\u001b[0m  0.4350\n",
      "      3        \u001b[36m0.6912\u001b[0m  0.4350\n",
      "      4        \u001b[36m0.6911\u001b[0m  0.4347\n",
      "      5        \u001b[36m0.6907\u001b[0m  0.4340\n",
      "      6        \u001b[36m0.6898\u001b[0m  0.4351\n",
      "      7        0.6907  0.4348\n",
      "      8        0.6912  0.4351\n",
      "      9        0.6913  0.4356\n",
      "     10        0.6930  0.4343\n",
      "     11        0.6904  0.4355\n",
      "     12        0.6916  0.4350\n",
      "     13        0.6908  0.4361\n",
      "     14        0.6916  0.4351\n",
      "     15        0.6899  0.4359\n",
      "     16        0.6906  0.4356\n",
      "     17        0.6923  0.4353\n",
      "     18        0.6908  0.4372\n",
      "     19        0.6928  0.4381\n",
      "     20        \u001b[36m0.6896\u001b[0m  0.4375\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m29.8799\u001b[0m  0.4376\n",
      "      2        \u001b[36m0.8744\u001b[0m  0.4374\n",
      "      3        \u001b[36m0.6901\u001b[0m  0.4370\n",
      "      4        \u001b[36m0.6892\u001b[0m  0.4371\n",
      "      5        0.6924  0.4368\n",
      "      6        \u001b[36m0.6891\u001b[0m  0.4356\n",
      "      7        0.6910  0.4360\n",
      "      8        0.6903  0.4371\n",
      "      9        0.6894  0.4356\n",
      "     10        0.6904  0.4362\n",
      "     11        0.6897  0.4371\n",
      "     12        0.6903  0.4375\n",
      "     13        0.6895  0.4375\n",
      "     14        0.6898  0.4370\n",
      "     15        \u001b[36m0.6882\u001b[0m  0.4361\n",
      "     16        0.6895  0.4356\n",
      "     17        0.6902  0.4361\n",
      "     18        0.6887  0.4374\n",
      "     19        0.6895  0.4362\n",
      "     20        0.6890  0.4370\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m64.6582\u001b[0m  0.4357\n",
      "      2        \u001b[36m3.2729\u001b[0m  0.4362\n",
      "      3        \u001b[36m0.6903\u001b[0m  0.4365\n",
      "      4        0.6932  0.4357\n",
      "      5        0.6918  0.4353\n",
      "      6        0.6936  0.4354\n",
      "      7        0.6916  0.4370\n",
      "      8        0.6915  0.4361\n",
      "      9        0.6926  0.4365\n",
      "     10        0.6921  0.4370\n",
      "     11        0.6916  0.4357\n",
      "     12        \u001b[36m0.6901\u001b[0m  0.4368\n",
      "     13        0.6904  0.4365\n",
      "     14        0.6929  0.4350\n",
      "     15        \u001b[36m0.6900\u001b[0m  0.4360\n",
      "     16        \u001b[36m0.6900\u001b[0m  0.4359\n",
      "     17        0.6906  0.4346\n",
      "     18        0.6910  0.4461\n",
      "     19        0.6923  0.4357\n",
      "     20        0.6907  0.4355\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m33.0879\u001b[0m  0.4484\n",
      "      2        \u001b[36m0.9159\u001b[0m  0.4471\n",
      "      3        3.7345  0.4460\n",
      "      4        \u001b[36m0.6923\u001b[0m  0.4462\n",
      "      5        0.6930  0.4459\n",
      "      6        0.6927  0.4447\n",
      "      7        \u001b[36m0.6917\u001b[0m  0.4466\n",
      "      8        0.6946  0.4462\n",
      "      9        \u001b[36m0.6912\u001b[0m  0.4448\n",
      "     10        0.6923  0.4468\n",
      "     11        0.6926  0.4463\n",
      "     12        0.6933  0.4461\n",
      "     13        0.6919  0.4456\n",
      "     14        \u001b[36m0.6908\u001b[0m  0.4463\n",
      "     15        0.6938  0.4448\n",
      "     16        \u001b[36m0.6905\u001b[0m  0.4463\n",
      "     17        0.6915  0.4471\n",
      "     18        0.6956  0.4452\n",
      "     19        0.6916  0.4472\n",
      "     20        0.6926  0.4461\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.6591\u001b[0m  0.4482\n",
      "      2        \u001b[36m5.8345\u001b[0m  0.4509\n",
      "      3        9.7947  0.4490\n",
      "      4        \u001b[36m0.6916\u001b[0m  0.4504\n",
      "      5        0.6951  0.4493\n",
      "      6        0.6962  0.4494\n",
      "      7        0.7010  0.4517\n",
      "      8        0.6960  0.4499\n",
      "      9        0.6944  0.4486\n",
      "     10        0.6948  0.4501\n",
      "     11        0.6921  0.4503\n",
      "     12        0.6932  0.4488\n",
      "     13        0.6928  0.4501\n",
      "     14        0.6946  0.4507\n",
      "     15        0.6922  0.4482\n",
      "     16        0.6935  0.4491\n",
      "     17        0.6939  0.4502\n",
      "     18        0.6938  0.4485\n",
      "     19        0.6996  0.4503\n",
      "     20        0.6922  0.4490\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m24.4686\u001b[0m  0.4517\n",
      "      2        \u001b[36m0.8378\u001b[0m  0.4489\n",
      "      3        \u001b[36m0.6915\u001b[0m  0.4478\n",
      "      4        \u001b[36m0.6905\u001b[0m  0.4470\n",
      "      5        0.6907  0.4488\n",
      "      6        0.6937  0.4479\n",
      "      7        \u001b[36m0.6894\u001b[0m  0.4478\n",
      "      8        0.6912  0.4497\n",
      "      9        0.6897  0.4499\n",
      "     10        0.6922  0.4494\n",
      "     11        0.6900  0.4487\n",
      "     12        0.6908  0.4501\n",
      "     13        0.6900  0.4490\n",
      "     14        0.6921  0.4495\n",
      "     15        0.6907  0.4482\n",
      "     16        0.6908  0.4480\n",
      "     17        0.6907  0.4465\n",
      "     18        0.6901  0.4458\n",
      "     19        0.6902  0.4481\n",
      "     20        0.6905  0.4503\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m56.2591\u001b[0m  0.5246\n",
      "      2        \u001b[36m1.1785\u001b[0m  0.5254\n",
      "      3        \u001b[36m0.6898\u001b[0m  0.5253\n",
      "      4        0.6899  0.5261\n",
      "      5        0.6905  0.5262\n",
      "      6        0.6904  0.5286\n",
      "      7        0.6904  0.5296\n",
      "      8        \u001b[36m0.6897\u001b[0m  0.5258\n",
      "      9        0.6912  0.5259\n",
      "     10        0.6914  0.5264\n",
      "     11        0.6899  0.5265\n",
      "     12        0.6898  0.5260\n",
      "     13        0.6914  0.5254\n",
      "     14        0.6925  0.5254\n",
      "     15        0.6898  0.5261\n",
      "     16        0.6911  0.5245\n",
      "     17        0.6918  0.5254\n",
      "     18        0.6919  0.5238\n",
      "     19        0.6917  0.5250\n",
      "     20        0.6910  0.5295\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m44.6813\u001b[0m  0.5284\n",
      "      2        \u001b[36m1.5163\u001b[0m  0.5272\n",
      "      3        \u001b[36m0.6942\u001b[0m  0.5279\n",
      "      4        \u001b[36m0.6904\u001b[0m  0.5288\n",
      "      5        \u001b[36m0.6902\u001b[0m  0.5284\n",
      "      6        0.6923  0.5264\n",
      "      7        0.6903  0.5262\n",
      "      8        \u001b[36m0.6895\u001b[0m  0.5265\n",
      "      9        0.6906  0.5267\n",
      "     10        0.6917  0.5285\n",
      "     11        0.6900  0.5283\n",
      "     12        0.6906  0.5282\n",
      "     13        0.6925  0.5282\n",
      "     14        0.6914  0.5281\n",
      "     15        0.6912  0.5290\n",
      "     16        0.6915  0.5279\n",
      "     17        0.6912  0.5281\n",
      "     18        0.6907  0.5282\n",
      "     19        0.6909  0.5276\n",
      "     20        0.6898  0.5281\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m58.0314\u001b[0m  0.5244\n",
      "      2        \u001b[36m0.8204\u001b[0m  0.5248\n",
      "      3        \u001b[36m0.6906\u001b[0m  0.5238\n",
      "      4        \u001b[36m0.6905\u001b[0m  0.5247\n",
      "      5        0.6922  0.5258\n",
      "      6        0.6910  0.5249\n",
      "      7        \u001b[36m0.6901\u001b[0m  0.5255\n",
      "      8        0.6907  0.5257\n",
      "      9        0.6917  0.5257\n",
      "     10        0.6917  0.5248\n",
      "     11        0.6910  0.5253\n",
      "     12        0.6915  0.5231\n",
      "     13        0.6905  0.5221\n",
      "     14        0.6906  0.5246\n",
      "     15        0.6907  0.5249\n",
      "     16        0.6903  0.5245\n",
      "     17        0.6913  0.5247\n",
      "     18        0.6905  0.5247\n",
      "     19        0.6919  0.5247\n",
      "     20        0.6903  0.5240\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m189.9411\u001b[0m  0.5428\n",
      "      2        \u001b[36m1.5566\u001b[0m  0.5399\n",
      "      3        \u001b[36m0.6984\u001b[0m  0.5404\n",
      "      4        \u001b[36m0.6903\u001b[0m  0.5415\n",
      "      5        0.6919  0.5416\n",
      "      6        0.6914  0.5424\n",
      "      7        0.6905  0.5440\n",
      "      8        \u001b[36m0.6898\u001b[0m  0.5416\n",
      "      9        0.6902  0.5412\n",
      "     10        \u001b[36m0.6895\u001b[0m  0.5417\n",
      "     11        0.6899  0.5417\n",
      "     12        \u001b[36m0.6889\u001b[0m  0.5439\n",
      "     13        0.6906  0.5433\n",
      "     14        0.6900  0.5430\n",
      "     15        0.6901  0.5446\n",
      "     16        0.6894  0.5405\n",
      "     17        0.6904  0.5406\n",
      "     18        \u001b[36m0.6876\u001b[0m  0.5396\n",
      "     19        0.6890  0.5397\n",
      "     20        0.6877  0.5413\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m107.7464\u001b[0m  0.5417\n",
      "      2        \u001b[36m4.0083\u001b[0m  0.5372\n",
      "      3        \u001b[36m0.6942\u001b[0m  0.5389\n",
      "      4        \u001b[36m0.6915\u001b[0m  0.5397\n",
      "      5        0.6960  0.5397\n",
      "      6        0.6940  0.5386\n",
      "      7        0.6954  0.5397\n",
      "      8        0.6940  0.5400\n",
      "      9        0.6925  0.5391\n",
      "     10        0.6954  0.5414\n",
      "     11        0.6930  0.5381\n",
      "     12        0.6935  0.5418\n",
      "     13        0.6943  0.5403\n",
      "     14        0.6943  0.5365\n",
      "     15        0.6949  0.5396\n",
      "     16        0.6933  0.5401\n",
      "     17        \u001b[36m0.6914\u001b[0m  0.5418\n",
      "     18        0.6965  0.5407\n",
      "     19        0.6955  0.5390\n",
      "     20        \u001b[36m0.6909\u001b[0m  0.5432\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m146.0938\u001b[0m  0.5453\n",
      "      2        \u001b[36m4.7214\u001b[0m  0.5383\n",
      "      3        \u001b[36m0.6992\u001b[0m  0.5382\n",
      "      4        \u001b[36m0.6954\u001b[0m  0.5404\n",
      "      5        \u001b[36m0.6924\u001b[0m  0.5405\n",
      "      6        0.6943  0.5410\n",
      "      7        0.6926  0.5412\n",
      "      8        0.7003  0.5390\n",
      "      9        0.7012  0.5400\n",
      "     10        0.6945  0.5400\n",
      "     11        0.6935  0.5390\n",
      "     12        0.6969  0.5383\n",
      "     13        0.6925  0.5375\n",
      "     14        0.6948  0.5377\n",
      "     15        \u001b[36m0.6921\u001b[0m  0.5385\n",
      "     16        0.6933  0.5398\n",
      "     17        0.6950  0.5400\n",
      "     18        0.6981  0.5394\n",
      "     19        0.6936  0.5377\n",
      "     20        \u001b[36m0.6919\u001b[0m  0.5392\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=2; total time=  10.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m192.3573\u001b[0m  0.5598\n",
      "      2       \u001b[36m70.4344\u001b[0m  0.5596\n",
      "      3        \u001b[36m0.9887\u001b[0m  0.5608\n",
      "      4        \u001b[36m0.6917\u001b[0m  0.5601\n",
      "      5        0.6955  0.5600\n",
      "      6        0.7014  0.5587\n",
      "      7        0.6929  0.5594\n",
      "      8        0.6960  0.5593\n",
      "      9        0.6965  0.5618\n",
      "     10        0.6969  0.5589\n",
      "     11        0.6949  0.5620\n",
      "     12        0.6955  0.5630\n",
      "     13        0.6958  0.5628\n",
      "     14        0.6992  0.5621\n",
      "     15        0.6932  0.5626\n",
      "     16        0.6976  0.5631\n",
      "     17        0.6948  0.5617\n",
      "     18        0.6919  0.5623\n",
      "     19        0.6950  0.5629\n",
      "     20        0.6921  0.5624\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m516.7161\u001b[0m  0.5592\n",
      "      2        \u001b[36m0.9100\u001b[0m  0.5587\n",
      "      3        \u001b[36m0.6933\u001b[0m  0.5603\n",
      "      4        \u001b[36m0.6902\u001b[0m  0.5576\n",
      "      5        0.6908  0.5622\n",
      "      6        0.6922  0.5620\n",
      "      7        0.6933  0.5632\n",
      "      8        0.6904  0.5619\n",
      "      9        0.6928  0.5594\n",
      "     10        0.6941  0.5607\n",
      "     11        0.6915  0.5598\n",
      "     12        \u001b[36m0.6900\u001b[0m  0.5599\n",
      "     13        0.6915  0.5608\n",
      "     14        0.6928  0.5620\n",
      "     15        0.6920  0.5620\n",
      "     16        0.6954  0.5615\n",
      "     17        0.6921  0.5626\n",
      "     18        0.6918  0.5614\n",
      "     19        0.6903  0.5623\n",
      "     20        0.6907  0.5625\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m133.3527\u001b[0m  0.5634\n",
      "      2        \u001b[36m8.7404\u001b[0m  0.5596\n",
      "      3        \u001b[36m1.6935\u001b[0m  0.5581\n",
      "      4        \u001b[36m1.0397\u001b[0m  0.5595\n",
      "      5        \u001b[36m0.6892\u001b[0m  0.5613\n",
      "      6        0.6892  0.5612\n",
      "      7        \u001b[36m0.6890\u001b[0m  0.5656\n",
      "      8        0.6893  0.5603\n",
      "      9        0.6901  0.5595\n",
      "     10        0.6894  0.5595\n",
      "     11        \u001b[36m0.6884\u001b[0m  0.5619\n",
      "     12        0.6907  0.5616\n",
      "     13        0.6892  0.5609\n",
      "     14        0.6898  0.5604\n",
      "     15        0.6888  0.5586\n",
      "     16        0.6905  0.5596\n",
      "     17        0.6901  0.5595\n",
      "     18        0.6896  0.5603\n",
      "     19        0.6899  0.5640\n",
      "     20        0.6897  0.5625\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m87.1563\u001b[0m  0.7974\n",
      "      2        \u001b[36m0.7516\u001b[0m  0.7964\n",
      "      3        \u001b[36m0.6886\u001b[0m  0.7964\n",
      "      4        0.6902  0.7967\n",
      "      5        0.6898  0.7955\n",
      "      6        0.6892  0.7957\n",
      "      7        0.6893  0.7975\n",
      "      8        0.6916  0.7967\n",
      "      9        0.6896  0.7974\n",
      "     10        0.6896  0.7956\n",
      "     11        0.6926  0.7961\n",
      "     12        0.6909  0.7959\n",
      "     13        0.6902  0.8061\n",
      "     14        0.6895  0.7957\n",
      "     15        0.6911  0.7959\n",
      "     16        0.6901  0.7965\n",
      "     17        0.6904  0.7955\n",
      "     18        0.6908  0.7951\n",
      "     19        0.6903  0.7965\n",
      "     20        0.6913  0.8030\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m115.2444\u001b[0m  0.8004\n",
      "      2        \u001b[36m0.8656\u001b[0m  0.7977\n",
      "      3        \u001b[36m0.6906\u001b[0m  0.8044\n",
      "      4        0.6911  0.7989\n",
      "      5        \u001b[36m0.6898\u001b[0m  0.7975\n",
      "      6        0.6908  0.7984\n",
      "      7        0.6911  0.8011\n",
      "      8        0.6904  0.7978\n",
      "      9        0.6916  0.7997\n",
      "     10        0.6919  0.7999\n",
      "     11        0.6912  0.8065\n",
      "     12        \u001b[36m0.6898\u001b[0m  0.7996\n",
      "     13        0.6906  0.7975\n",
      "     14        0.6907  0.7997\n",
      "     15        0.6912  0.7989\n",
      "     16        0.6903  0.7995\n",
      "     17        0.6937  0.7997\n",
      "     18        0.6924  0.8000\n",
      "     19        0.6899  0.7976\n",
      "     20        0.6919  0.7985\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m66.8464\u001b[0m  0.8014\n",
      "      2        \u001b[36m1.1805\u001b[0m  0.7997\n",
      "      3        \u001b[36m0.6902\u001b[0m  0.8009\n",
      "      4        \u001b[36m0.6898\u001b[0m  0.8017\n",
      "      5        \u001b[36m0.6894\u001b[0m  0.8017\n",
      "      6        0.6900  0.8004\n",
      "      7        \u001b[36m0.6893\u001b[0m  0.7996\n",
      "      8        0.6912  0.7992\n",
      "      9        0.6907  0.8000\n",
      "     10        0.6904  0.8003\n",
      "     11        0.6895  0.8000\n",
      "     12        0.6898  0.8008\n",
      "     13        0.6905  0.7996\n",
      "     14        0.6907  0.7992\n",
      "     15        0.6898  0.8016\n",
      "     16        0.6924  0.8018\n",
      "     17        0.6906  0.8019\n",
      "     18        0.6894  0.8016\n",
      "     19        \u001b[36m0.6893\u001b[0m  0.8024\n",
      "     20        \u001b[36m0.6890\u001b[0m  0.8023\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m914.0919\u001b[0m  0.8342\n",
      "      2        \u001b[36m3.8909\u001b[0m  0.8237\n",
      "      3        \u001b[36m0.6995\u001b[0m  0.8251\n",
      "      4        \u001b[36m0.6984\u001b[0m  0.8233\n",
      "      5        0.6990  0.8250\n",
      "      6        0.7006  0.8242\n",
      "      7        \u001b[36m0.6936\u001b[0m  0.8242\n",
      "      8        0.6960  0.8241\n",
      "      9        \u001b[36m0.6930\u001b[0m  0.8221\n",
      "     10        0.6972  0.8243\n",
      "     11        \u001b[36m0.6920\u001b[0m  0.8240\n",
      "     12        0.6941  0.8238\n",
      "     13        0.6992  0.8254\n",
      "     14        0.6938  0.8249\n",
      "     15        0.6951  0.8254\n",
      "     16        \u001b[36m0.6903\u001b[0m  0.8256\n",
      "     17        0.6936  0.8251\n",
      "     18        0.6919  0.8276\n",
      "     19        0.6940  0.8243\n",
      "     20        0.6963  0.8240\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m558.6459\u001b[0m  0.8259\n",
      "      2       \u001b[36m54.3777\u001b[0m  0.8249\n",
      "      3        \u001b[36m0.6896\u001b[0m  0.8242\n",
      "      4        0.6896  0.8245\n",
      "      5        0.6907  0.8239\n",
      "      6        0.6897  0.8224\n",
      "      7        0.6904  0.8215\n",
      "      8        \u001b[36m0.6894\u001b[0m  0.8210\n",
      "      9        0.6901  0.8238\n",
      "     10        0.6914  0.8218\n",
      "     11        \u001b[36m0.6892\u001b[0m  0.8216\n",
      "     12        0.6895  0.8232\n",
      "     13        0.6898  0.8225\n",
      "     14        0.6902  0.8242\n",
      "     15        0.6903  0.8258\n",
      "     16        0.6914  0.8221\n",
      "     17        0.6897  0.8228\n",
      "     18        0.6905  0.8252\n",
      "     19        0.6903  0.8215\n",
      "     20        0.6910  0.8233\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m734.6500\u001b[0m  0.8373\n",
      "      2        \u001b[36m7.3353\u001b[0m  0.8336\n",
      "      3        \u001b[36m0.6925\u001b[0m  0.8336\n",
      "      4        \u001b[36m0.6898\u001b[0m  0.8324\n",
      "      5        0.6898  0.8324\n",
      "      6        0.6906  0.8333\n",
      "      7        0.6906  0.8322\n",
      "      8        0.6910  0.8310\n",
      "      9        \u001b[36m0.6893\u001b[0m  0.8315\n",
      "     10        0.6927  0.8370\n",
      "     11        0.6898  0.8333\n",
      "     12        0.6903  0.8358\n",
      "     13        0.6896  0.8328\n",
      "     14        \u001b[36m0.6891\u001b[0m  0.8330\n",
      "     15        0.6910  0.8329\n",
      "     16        0.6913  0.8359\n",
      "     17        0.6906  0.8315\n",
      "     18        0.6917  0.8297\n",
      "     19        0.6901  0.8299\n",
      "     20        0.6892  0.8304\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=2; total time=  16.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1     \u001b[36m1041.0276\u001b[0m  0.8591\n",
      "      2      \u001b[36m286.3763\u001b[0m  0.8592\n",
      "      3        \u001b[36m0.9476\u001b[0m  0.8600\n",
      "      4        \u001b[36m0.9074\u001b[0m  0.8589\n",
      "      5        \u001b[36m0.7941\u001b[0m  0.8588\n",
      "      6        \u001b[36m0.7247\u001b[0m  0.8581\n",
      "      7        \u001b[36m0.7218\u001b[0m  0.8586\n",
      "      8        \u001b[36m0.7133\u001b[0m  0.8605\n",
      "      9        \u001b[36m0.7012\u001b[0m  0.8585\n",
      "     10        \u001b[36m0.6973\u001b[0m  0.8610\n",
      "     11        0.7255  0.8621\n",
      "     12        0.6995  0.8604\n",
      "     13        \u001b[36m0.6964\u001b[0m  0.8588\n",
      "     14        \u001b[36m0.6924\u001b[0m  0.8600\n",
      "     15        0.6961  0.8619\n",
      "     16        0.6986  0.8576\n",
      "     17        0.7010  0.8596\n",
      "     18        0.6960  0.8604\n",
      "     19        0.6930  0.8605\n",
      "     20        0.6945  0.8607\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1     \u001b[36m3744.3067\u001b[0m  0.8626\n",
      "      2       \u001b[36m47.0705\u001b[0m  0.8578\n",
      "      3        \u001b[36m0.6975\u001b[0m  0.8582\n",
      "      4        0.6983  0.8590\n",
      "      5        0.7045  0.8584\n",
      "      6        0.7057  0.8576\n",
      "      7        \u001b[36m0.6971\u001b[0m  0.8586\n",
      "      8        0.6978  0.8567\n",
      "      9        0.7019  0.8591\n",
      "     10        \u001b[36m0.6968\u001b[0m  0.8578\n",
      "     11        \u001b[36m0.6920\u001b[0m  0.8574\n",
      "     12        0.6937  0.8595\n",
      "     13        0.6979  0.8581\n",
      "     14        0.6928  0.8580\n",
      "     15        0.6980  0.8558\n",
      "     16        0.6956  0.8591\n",
      "     17        0.7007  0.8581\n",
      "     18        0.7079  0.8579\n",
      "     19        0.6964  0.8589\n",
      "     20        0.6960  0.8569\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1     \u001b[36m4169.0192\u001b[0m  0.8610\n",
      "      2      \u001b[36m194.3668\u001b[0m  0.8564\n",
      "      3        \u001b[36m6.8801\u001b[0m  0.8595\n",
      "      4        \u001b[36m3.0208\u001b[0m  0.8576\n",
      "      5        \u001b[36m0.6987\u001b[0m  0.8578\n",
      "      6        \u001b[36m0.6983\u001b[0m  0.8569\n",
      "      7        0.7062  0.8550\n",
      "      8        0.6988  0.8571\n",
      "      9        \u001b[36m0.6963\u001b[0m  0.8579\n",
      "     10        \u001b[36m0.6938\u001b[0m  0.8568\n",
      "     11        0.6972  0.8558\n",
      "     12        0.6980  0.8634\n",
      "     13        0.6979  0.8566\n",
      "     14        0.7029  0.8611\n",
      "     15        0.6984  0.8578\n",
      "     16        0.7000  0.8630\n",
      "     17        0.7073  0.8572\n",
      "     18        \u001b[36m0.6913\u001b[0m  0.8555\n",
      "     19        0.6956  0.8606\n",
      "     20        0.7070  0.8552\n",
      "[CV] END lr=0.1, module__activation_func=<function relu at 0x7cad8477f1f0>, module__hidden_dim=256, module__n_layers=3; total time=  17.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7379\u001b[0m  0.4198\n",
      "      2        0.7517  0.4202\n",
      "      3        \u001b[36m0.7021\u001b[0m  0.4208\n",
      "      4        0.7498  0.4212\n",
      "      5        0.8222  0.4213\n",
      "      6        0.7114  0.4212\n",
      "      7        0.7257  0.4212\n",
      "      8        0.7602  0.4210\n",
      "      9        0.7418  0.4197\n",
      "     10        0.7416  0.4212\n",
      "     11        0.7214  0.4215\n",
      "     12        0.7394  0.4202\n",
      "     13        0.7082  0.4215\n",
      "     14        0.7580  0.4209\n",
      "     15        0.7376  0.4206\n",
      "     16        0.7205  0.4223\n",
      "     17        0.7083  0.4216\n",
      "     18        0.7059  0.4208\n",
      "     19        0.7726  0.4212\n",
      "     20        0.7452  0.4218\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7755\u001b[0m  0.4234\n",
      "      2        \u001b[36m0.7396\u001b[0m  0.4226\n",
      "      3        0.7606  0.4224\n",
      "      4        \u001b[36m0.7176\u001b[0m  0.4206\n",
      "      5        0.7191  0.4211\n",
      "      6        0.7438  0.4224\n",
      "      7        \u001b[36m0.7141\u001b[0m  0.4204\n",
      "      8        0.7290  0.4219\n",
      "      9        0.7263  0.4215\n",
      "     10        0.7428  0.4217\n",
      "     11        0.7150  0.4201\n",
      "     12        0.7279  0.4213\n",
      "     13        0.7686  0.4215\n",
      "     14        0.7845  0.4202\n",
      "     15        0.7318  0.4209\n",
      "     16        0.7168  0.4215\n",
      "     17        0.7436  0.4212\n",
      "     18        0.7153  0.4220\n",
      "     19        0.7278  0.4226\n",
      "     20        0.7283  0.4217\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8042\u001b[0m  0.4238\n",
      "      2        \u001b[36m0.7713\u001b[0m  0.4237\n",
      "      3        \u001b[36m0.7376\u001b[0m  0.4229\n",
      "      4        \u001b[36m0.7250\u001b[0m  0.4238\n",
      "      5        \u001b[36m0.7219\u001b[0m  0.4244\n",
      "      6        0.7739  0.4233\n",
      "      7        \u001b[36m0.7115\u001b[0m  0.4241\n",
      "      8        0.7172  0.4245\n",
      "      9        0.7170  0.4230\n",
      "     10        0.7301  0.4228\n",
      "     11        0.7152  0.4238\n",
      "     12        0.7137  0.4231\n",
      "     13        0.7395  0.4222\n",
      "     14        0.7277  0.4230\n",
      "     15        0.7160  0.4238\n",
      "     16        0.7313  0.4231\n",
      "     17        0.7338  0.4237\n",
      "     18        0.7377  0.4240\n",
      "     19        \u001b[36m0.7028\u001b[0m  0.4233\n",
      "     20        0.7130  0.4232\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7062\u001b[0m  0.4352\n",
      "      2        \u001b[36m0.6912\u001b[0m  0.4339\n",
      "      3        0.6914  0.4338\n",
      "      4        0.6924  0.4352\n",
      "      5        0.6923  0.4347\n",
      "      6        0.6916  0.4365\n",
      "      7        \u001b[36m0.6911\u001b[0m  0.4351\n",
      "      8        0.6915  0.4345\n",
      "      9        \u001b[36m0.6899\u001b[0m  0.4346\n",
      "     10        0.6920  0.4350\n",
      "     11        0.6906  0.4338\n",
      "     12        0.6917  0.4344\n",
      "     13        0.6905  0.4338\n",
      "     14        0.6903  0.4335\n",
      "     15        0.6920  0.4347\n",
      "     16        0.6932  0.4348\n",
      "     17        0.6921  0.4345\n",
      "     18        0.6911  0.4345\n",
      "     19        0.6909  0.4354\n",
      "     20        0.6924  0.4345\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7139\u001b[0m  0.4355\n",
      "      2        \u001b[36m0.6898\u001b[0m  0.4347\n",
      "      3        0.6920  0.4339\n",
      "      4        0.6901  0.4353\n",
      "      5        0.6918  0.4346\n",
      "      6        0.6903  0.4341\n",
      "      7        0.6913  0.4343\n",
      "      8        0.6905  0.4340\n",
      "      9        0.6928  0.4327\n",
      "     10        0.6917  0.4346\n",
      "     11        0.6906  0.4339\n",
      "     12        0.6917  0.4342\n",
      "     13        0.6915  0.4349\n",
      "     14        0.6938  0.4343\n",
      "     15        0.6926  0.4341\n",
      "     16        0.6912  0.4339\n",
      "     17        0.6920  0.4343\n",
      "     18        0.6917  0.4346\n",
      "     19        0.6911  0.4341\n",
      "     20        0.6910  0.4352\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7159\u001b[0m  0.4344\n",
      "      2        \u001b[36m0.6906\u001b[0m  0.4337\n",
      "      3        \u001b[36m0.6899\u001b[0m  0.4327\n",
      "      4        0.6911  0.4329\n",
      "      5        0.6910  0.4336\n",
      "      6        0.6905  0.4325\n",
      "      7        0.6907  0.4340\n",
      "      8        0.6912  0.4323\n",
      "      9        0.6904  0.4336\n",
      "     10        0.6916  0.4335\n",
      "     11        0.6923  0.4327\n",
      "     12        0.6922  0.4340\n",
      "     13        0.6916  0.4334\n",
      "     14        0.6918  0.4319\n",
      "     15        0.6915  0.4339\n",
      "     16        0.6905  0.4341\n",
      "     17        0.6907  0.4339\n",
      "     18        0.6909  0.4346\n",
      "     19        0.6905  0.4346\n",
      "     20        0.6936  0.4423\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=2; total time=   8.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7169\u001b[0m  0.4471\n",
      "      2        \u001b[36m0.6910\u001b[0m  0.4473\n",
      "      3        \u001b[36m0.6893\u001b[0m  0.4455\n",
      "      4        0.6914  0.4470\n",
      "      5        0.6923  0.4473\n",
      "      6        0.6906  0.4532\n",
      "      7        0.6905  0.4471\n",
      "      8        0.6912  0.4465\n",
      "      9        0.6919  0.4457\n",
      "     10        0.6936  0.4475\n",
      "     11        0.6909  0.4472\n",
      "     12        0.6906  0.4460\n",
      "     13        0.6924  0.4560\n",
      "     14        0.6908  0.4478\n",
      "     15        0.6939  0.4462\n",
      "     16        0.6906  0.4468\n",
      "     17        0.6928  0.4466\n",
      "     18        0.6911  0.4462\n",
      "     19        0.6908  0.4470\n",
      "     20        0.6920  0.4478\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7204\u001b[0m  0.4458\n",
      "      2        \u001b[36m0.6954\u001b[0m  0.4464\n",
      "      3        \u001b[36m0.6950\u001b[0m  0.4463\n",
      "      4        \u001b[36m0.6938\u001b[0m  0.4470\n",
      "      5        \u001b[36m0.6904\u001b[0m  0.4472\n",
      "      6        0.6962  0.4463\n",
      "      7        0.6941  0.4473\n",
      "      8        0.6923  0.4474\n",
      "      9        0.6913  0.4467\n",
      "     10        0.6914  0.4465\n",
      "     11        0.6926  0.4471\n",
      "     12        0.6954  0.4466\n",
      "     13        0.6928  0.4480\n",
      "     14        0.6925  0.4474\n",
      "     15        0.6944  0.4473\n",
      "     16        0.6907  0.4472\n",
      "     17        0.6944  0.4470\n",
      "     18        0.6945  0.4470\n",
      "     19        0.6959  0.4467\n",
      "     20        0.6926  0.4482\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7273\u001b[0m  0.4447\n",
      "      2        \u001b[36m0.6919\u001b[0m  0.4455\n",
      "      3        \u001b[36m0.6907\u001b[0m  0.4452\n",
      "      4        0.6911  0.4453\n",
      "      5        \u001b[36m0.6905\u001b[0m  0.4441\n",
      "      6        0.6914  0.4454\n",
      "      7        0.6913  0.4442\n",
      "      8        0.6916  0.4450\n",
      "      9        0.6909  0.4454\n",
      "     10        0.6922  0.4452\n",
      "     11        \u001b[36m0.6903\u001b[0m  0.4453\n",
      "     12        0.6922  0.4450\n",
      "     13        \u001b[36m0.6903\u001b[0m  0.4453\n",
      "     14        0.6908  0.4450\n",
      "     15        0.6921  0.4459\n",
      "     16        0.6910  0.4447\n",
      "     17        0.6918  0.4460\n",
      "     18        0.6907  0.4463\n",
      "     19        0.6921  0.4445\n",
      "     20        0.6910  0.4455\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=64, module__n_layers=3; total time=   9.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8624\u001b[0m  0.5198\n",
      "      2        \u001b[36m0.7546\u001b[0m  0.5202\n",
      "      3        0.7746  0.5198\n",
      "      4        0.7588  0.5199\n",
      "      5        0.7845  0.5229\n",
      "      6        0.7834  0.5223\n",
      "      7        0.8130  0.5219\n",
      "      8        0.7564  0.5180\n",
      "      9        0.7792  0.5201\n",
      "     10        0.7610  0.5225\n",
      "     11        0.8330  0.5184\n",
      "     12        0.7719  0.5202\n",
      "     13        0.7597  0.5220\n",
      "     14        0.7908  0.5201\n",
      "     15        \u001b[36m0.7484\u001b[0m  0.5211\n",
      "     16        \u001b[36m0.7282\u001b[0m  0.5214\n",
      "     17        0.8443  0.5227\n",
      "     18        0.7526  0.5226\n",
      "     19        0.7681  0.5235\n",
      "     20        0.7677  0.5220\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8368\u001b[0m  0.5243\n",
      "      2        \u001b[36m0.7554\u001b[0m  0.5262\n",
      "      3        \u001b[36m0.7526\u001b[0m  0.5254\n",
      "      4        0.7815  0.5239\n",
      "      5        0.7541  0.5244\n",
      "      6        0.7804  0.5275\n",
      "      7        \u001b[36m0.7291\u001b[0m  0.5239\n",
      "      8        0.7772  0.5235\n",
      "      9        0.7700  0.5238\n",
      "     10        0.7485  0.5251\n",
      "     11        \u001b[36m0.7065\u001b[0m  0.5229\n",
      "     12        0.7435  0.5234\n",
      "     13        0.8021  0.5238\n",
      "     14        0.7363  0.5251\n",
      "     15        0.8044  0.5237\n",
      "     16        0.7831  0.5234\n",
      "     17        0.7404  0.5255\n",
      "     18        0.7430  0.5270\n",
      "     19        0.7576  0.5239\n",
      "     20        0.7316  0.5248\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8455\u001b[0m  0.5183\n",
      "      2        \u001b[36m0.8332\u001b[0m  0.5217\n",
      "      3        \u001b[36m0.7455\u001b[0m  0.5228\n",
      "      4        0.7523  0.5211\n",
      "      5        0.7816  0.5209\n",
      "      6        0.8946  0.5208\n",
      "      7        0.7463  0.5199\n",
      "      8        0.7781  0.5189\n",
      "      9        \u001b[36m0.7351\u001b[0m  0.5198\n",
      "     10        0.7500  0.5194\n",
      "     11        0.7662  0.5219\n",
      "     12        0.7796  0.5220\n",
      "     13        \u001b[36m0.7289\u001b[0m  0.5204\n",
      "     14        0.7309  0.5211\n",
      "     15        0.7529  0.5241\n",
      "     16        0.7411  0.5225\n",
      "     17        0.7394  0.5184\n",
      "     18        0.8007  0.5192\n",
      "     19        0.7304  0.5202\n",
      "     20        0.7618  0.5188\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7930\u001b[0m  0.5402\n",
      "      2        \u001b[36m0.7277\u001b[0m  0.5371\n",
      "      3        0.7448  0.5368\n",
      "      4        0.7642  0.5354\n",
      "      5        0.7548  0.5364\n",
      "      6        0.7565  0.5350\n",
      "      7        0.7342  0.5358\n",
      "      8        0.7470  0.5386\n",
      "      9        0.7623  0.5346\n",
      "     10        0.7473  0.5349\n",
      "     11        0.7308  0.5361\n",
      "     12        \u001b[36m0.7053\u001b[0m  0.5359\n",
      "     13        0.7366  0.5358\n",
      "     14        0.7379  0.5416\n",
      "     15        0.7091  0.5372\n",
      "     16        0.7160  0.5360\n",
      "     17        0.7311  0.5378\n",
      "     18        \u001b[36m0.7052\u001b[0m  0.5345\n",
      "     19        0.7826  0.5368\n",
      "     20        0.7164  0.5366\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  10.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7312\u001b[0m  0.5384\n",
      "      2        \u001b[36m0.6909\u001b[0m  0.5379\n",
      "      3        0.6914  0.5429\n",
      "      4        0.6924  0.5432\n",
      "      5        0.6912  0.5446\n",
      "      6        0.6912  0.5443\n",
      "      7        \u001b[36m0.6908\u001b[0m  0.5428\n",
      "      8        0.6921  0.5407\n",
      "      9        0.6913  0.5450\n",
      "     10        0.6909  0.5442\n",
      "     11        \u001b[36m0.6907\u001b[0m  0.5418\n",
      "     12        0.6938  0.5395\n",
      "     13        0.6909  0.5402\n",
      "     14        0.6913  0.5373\n",
      "     15        \u001b[36m0.6906\u001b[0m  0.5378\n",
      "     16        0.6910  0.5381\n",
      "     17        0.6908  0.5374\n",
      "     18        0.6906  0.5372\n",
      "     19        0.6928  0.5376\n",
      "     20        0.6906  0.5371\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7709\u001b[0m  0.5402\n",
      "      2        \u001b[36m0.7085\u001b[0m  0.5393\n",
      "      3        \u001b[36m0.7081\u001b[0m  0.5399\n",
      "      4        0.7358  0.5366\n",
      "      5        0.7208  0.5372\n",
      "      6        0.7257  0.5368\n",
      "      7        0.7290  0.5358\n",
      "      8        0.7099  0.5360\n",
      "      9        0.7083  0.5368\n",
      "     10        0.7288  0.5408\n",
      "     11        0.7130  0.5378\n",
      "     12        0.7160  0.5406\n",
      "     13        0.7086  0.5402\n",
      "     14        0.7327  0.5400\n",
      "     15        0.7101  0.5418\n",
      "     16        \u001b[36m0.6977\u001b[0m  0.5417\n",
      "     17        0.7094  0.5432\n",
      "     18        0.7036  0.5399\n",
      "     19        0.7057  0.5371\n",
      "     20        0.7139  0.5415\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=2; total time=  10.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8324\u001b[0m  0.5656\n",
      "      2        \u001b[36m0.7378\u001b[0m  0.5637\n",
      "      3        0.7392  0.5627\n",
      "      4        0.7864  0.5627\n",
      "      5        0.7381  0.5666\n",
      "      6        \u001b[36m0.7322\u001b[0m  0.5693\n",
      "      7        0.7597  0.5691\n",
      "      8        \u001b[36m0.7192\u001b[0m  0.5657\n",
      "      9        0.7646  0.5636\n",
      "     10        0.7364  0.5644\n",
      "     11        0.7476  0.5692\n",
      "     12        0.7407  0.5688\n",
      "     13        0.7505  0.5641\n",
      "     14        0.7370  0.5665\n",
      "     15        0.7283  0.5671\n",
      "     16        0.7538  0.5650\n",
      "     17        0.7595  0.5683\n",
      "     18        0.7487  0.5686\n",
      "     19        0.7663  0.5647\n",
      "     20        0.7548  0.5661\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.5s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9301\u001b[0m  0.5564\n",
      "      2        \u001b[36m0.7417\u001b[0m  0.5578\n",
      "      3        0.7695  0.5589\n",
      "      4        \u001b[36m0.7303\u001b[0m  0.5573\n",
      "      5        0.8017  0.5589\n",
      "      6        0.7340  0.5597\n",
      "      7        0.7739  0.5579\n",
      "      8        0.7425  0.5620\n",
      "      9        0.7936  0.5588\n",
      "     10        0.7815  0.5594\n",
      "     11        0.7785  0.5596\n",
      "     12        \u001b[36m0.7297\u001b[0m  0.5605\n",
      "     13        0.7364  0.5584\n",
      "     14        0.7397  0.5578\n",
      "     15        0.7923  0.5577\n",
      "     16        0.7389  0.5593\n",
      "     17        0.7712  0.5591\n",
      "     18        0.7609  0.5582\n",
      "     19        0.7498  0.5580\n",
      "     20        0.7737  0.5603\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8721\u001b[0m  0.5610\n",
      "      2        \u001b[36m0.7714\u001b[0m  0.5629\n",
      "      3        0.7799  0.5629\n",
      "      4        0.7744  0.5638\n",
      "      5        0.7775  0.5629\n",
      "      6        \u001b[36m0.7331\u001b[0m  0.5646\n",
      "      7        0.7571  0.5651\n",
      "      8        0.7400  0.5651\n",
      "      9        0.7613  0.5649\n",
      "     10        0.7798  0.5651\n",
      "     11        0.7517  0.5668\n",
      "     12        \u001b[36m0.7309\u001b[0m  0.5644\n",
      "     13        0.7496  0.5659\n",
      "     14        0.8210  0.5628\n",
      "     15        0.7384  0.5668\n",
      "     16        0.7417  0.5610\n",
      "     17        0.7383  0.5646\n",
      "     18        0.7397  0.5631\n",
      "     19        0.8414  0.5646\n",
      "     20        0.7750  0.5632\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0537\u001b[0m  0.8003\n",
      "      2        \u001b[36m0.7413\u001b[0m  0.7951\n",
      "      3        0.7673  0.7969\n",
      "      4        0.9039  0.7977\n",
      "      5        0.9192  0.7943\n",
      "      6        1.0338  0.7936\n",
      "      7        0.9387  0.7945\n",
      "      8        0.8726  0.7936\n",
      "      9        \u001b[36m0.7306\u001b[0m  0.7941\n",
      "     10        0.8001  0.7937\n",
      "     11        0.7806  0.7946\n",
      "     12        0.7824  0.7958\n",
      "     13        0.7984  0.7952\n",
      "     14        0.8193  0.7937\n",
      "     15        0.9460  0.7940\n",
      "     16        0.7544  0.7945\n",
      "     17        0.7928  0.7943\n",
      "     18        0.8079  0.7957\n",
      "     19        0.8156  0.7931\n",
      "     20        0.8088  0.7932\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  16.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0128\u001b[0m  0.8017\n",
      "      2        \u001b[36m1.0014\u001b[0m  0.8003\n",
      "      3        \u001b[36m0.8341\u001b[0m  0.7990\n",
      "      4        \u001b[36m0.7584\u001b[0m  0.7988\n",
      "      5        0.8124  0.7995\n",
      "      6        0.9439  0.7988\n",
      "      7        0.8286  0.7988\n",
      "      8        \u001b[36m0.7537\u001b[0m  0.8005\n",
      "      9        0.8602  0.7991\n",
      "     10        0.8186  0.7987\n",
      "     11        0.7868  0.8009\n",
      "     12        0.8423  0.7984\n",
      "     13        0.8181  0.8002\n",
      "     14        0.7614  0.7991\n",
      "     15        0.9195  0.7993\n",
      "     16        0.9053  0.8003\n",
      "     17        0.7843  0.7990\n",
      "     18        0.7789  0.7988\n",
      "     19        0.8350  0.7985\n",
      "     20        0.9903  0.7982\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1202\u001b[0m  0.7984\n",
      "      2        \u001b[36m0.8007\u001b[0m  0.7976\n",
      "      3        0.8176  0.7975\n",
      "      4        0.8412  0.7980\n",
      "      5        0.9175  0.7963\n",
      "      6        \u001b[36m0.7866\u001b[0m  0.7968\n",
      "      7        0.8152  0.7966\n",
      "      8        0.9402  0.7966\n",
      "      9        0.8281  0.7970\n",
      "     10        \u001b[36m0.7840\u001b[0m  0.7985\n",
      "     11        \u001b[36m0.7761\u001b[0m  0.7964\n",
      "     12        0.7964  0.7964\n",
      "     13        0.8585  0.7973\n",
      "     14        0.7928  0.7980\n",
      "     15        0.7908  0.7982\n",
      "     16        0.8223  0.7976\n",
      "     17        0.7916  0.7961\n",
      "     18        \u001b[36m0.7590\u001b[0m  0.7976\n",
      "     19        0.9386  0.7963\n",
      "     20        0.8503  0.7964\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=1; total time=  16.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0106\u001b[0m  0.8410\n",
      "      2        \u001b[36m0.8440\u001b[0m  0.8347\n",
      "      3        \u001b[36m0.7576\u001b[0m  0.8356\n",
      "      4        0.7659  0.8347\n",
      "      5        0.8504  0.8357\n",
      "      6        0.8965  0.8334\n",
      "      7        0.7869  0.8344\n",
      "      8        0.7688  0.8353\n",
      "      9        0.7771  0.8324\n",
      "     10        0.8247  0.8323\n",
      "     11        0.9936  0.8399\n",
      "     12        0.7893  0.8409\n",
      "     13        0.8350  0.8324\n",
      "     14        0.8535  0.8337\n",
      "     15        0.8727  0.8355\n",
      "     16        0.8139  0.8379\n",
      "     17        0.9242  0.8338\n",
      "     18        0.8270  0.8350\n",
      "     19        0.7747  0.8352\n",
      "     20        0.9173  0.8378\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  16.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0746\u001b[0m  0.8245\n",
      "      2        \u001b[36m0.8003\u001b[0m  0.8202\n",
      "      3        \u001b[36m0.7970\u001b[0m  0.8205\n",
      "      4        0.8399  0.8214\n",
      "      5        0.8603  0.8210\n",
      "      6        \u001b[36m0.7607\u001b[0m  0.8212\n",
      "      7        0.8066  0.8194\n",
      "      8        0.7766  0.8198\n",
      "      9        \u001b[36m0.7398\u001b[0m  0.8200\n",
      "     10        0.8882  0.8190\n",
      "     11        0.8801  0.8199\n",
      "     12        0.8688  0.8188\n",
      "     13        0.8572  0.8183\n",
      "     14        0.7730  0.8181\n",
      "     15        0.8157  0.8193\n",
      "     16        0.8415  0.8197\n",
      "     17        0.7894  0.8196\n",
      "     18        0.8364  0.8196\n",
      "     19        0.8140  0.8203\n",
      "     20        0.7816  0.8193\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  16.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7722\u001b[0m  0.8333\n",
      "      2        \u001b[36m0.6974\u001b[0m  0.8313\n",
      "      3        0.7045  0.8326\n",
      "      4        \u001b[36m0.6968\u001b[0m  0.8300\n",
      "      5        0.7003  0.8301\n",
      "      6        0.7047  0.8289\n",
      "      7        0.6979  0.8287\n",
      "      8        0.6986  0.8295\n",
      "      9        \u001b[36m0.6948\u001b[0m  0.8282\n",
      "     10        \u001b[36m0.6938\u001b[0m  0.8295\n",
      "     11        0.6975  0.8289\n",
      "     12        0.6958  0.8295\n",
      "     13        0.6963  0.8307\n",
      "     14        0.6951  0.8288\n",
      "     15        0.6980  0.8304\n",
      "     16        0.6946  0.8294\n",
      "     17        0.6950  0.8336\n",
      "     18        0.6956  0.8314\n",
      "     19        0.6977  0.8289\n",
      "     20        0.6969  0.8302\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=2; total time=  16.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1125\u001b[0m  0.8551\n",
      "      2        \u001b[36m0.7806\u001b[0m  0.8522\n",
      "      3        0.8271  0.8573\n",
      "      4        0.8178  0.8562\n",
      "      5        \u001b[36m0.7481\u001b[0m  0.8549\n",
      "      6        0.7745  0.8530\n",
      "      7        0.7802  0.8556\n",
      "      8        0.8640  0.8552\n",
      "      9        0.8809  0.8535\n",
      "     10        0.9243  0.8519\n",
      "     11        0.7861  0.8527\n",
      "     12        0.7636  0.8534\n",
      "     13        0.8345  0.8535\n",
      "     14        0.7900  0.8520\n",
      "     15        0.7776  0.8528\n",
      "     16        0.8686  0.8535\n",
      "     17        0.8054  0.8534\n",
      "     18        0.7997  0.8540\n",
      "     19        0.7607  0.8546\n",
      "     20        0.9376  0.8535\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  17.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9591\u001b[0m  0.8561\n",
      "      2        \u001b[36m0.8753\u001b[0m  0.8546\n",
      "      3        \u001b[36m0.8607\u001b[0m  0.8545\n",
      "      4        \u001b[36m0.7832\u001b[0m  0.8552\n",
      "      5        0.8510  0.8545\n",
      "      6        0.7893  0.8522\n",
      "      7        0.8057  0.8523\n",
      "      8        0.9255  0.8529\n",
      "      9        0.8270  0.8533\n",
      "     10        0.7894  0.8557\n",
      "     11        0.8906  0.8604\n",
      "     12        0.8188  0.8534\n",
      "     13        0.9201  0.8552\n",
      "     14        0.8245  0.8529\n",
      "     15        \u001b[36m0.7791\u001b[0m  0.8613\n",
      "     16        0.8129  0.8545\n",
      "     17        0.9000  0.8543\n",
      "     18        0.8386  0.8557\n",
      "     19        0.7871  0.8563\n",
      "     20        0.7955  0.8556\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  17.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0974\u001b[0m  0.8495\n",
      "      2        \u001b[36m0.7766\u001b[0m  0.8488\n",
      "      3        0.8453  0.8478\n",
      "      4        0.7771  0.8468\n",
      "      5        0.8684  0.8462\n",
      "      6        0.8760  0.8467\n",
      "      7        0.8792  0.8473\n",
      "      8        0.8449  0.8468\n",
      "      9        0.8240  0.8506\n",
      "     10        0.8626  0.8462\n",
      "     11        0.7989  0.8487\n",
      "     12        0.8916  0.8491\n",
      "     13        0.8816  0.8485\n",
      "     14        0.9570  0.8480\n",
      "     15        0.8159  0.8466\n",
      "     16        0.7891  0.8482\n",
      "     17        0.8634  0.8483\n",
      "     18        0.8295  0.8526\n",
      "     19        0.7820  0.8532\n",
      "     20        0.8244  0.8524\n",
      "[CV] END lr=0.1, module__activation_func=<function sigmoid at 0x7cad8477fb80>, module__hidden_dim=256, module__n_layers=3; total time=  17.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7915\u001b[0m  0.4236\n",
      "      2        0.8102  0.4224\n",
      "      3        \u001b[36m0.7896\u001b[0m  0.4225\n",
      "      4        \u001b[36m0.7380\u001b[0m  0.4233\n",
      "      5        \u001b[36m0.7279\u001b[0m  0.4228\n",
      "      6        0.7466  0.4229\n",
      "      7        0.7379  0.4219\n",
      "      8        0.8660  0.4222\n",
      "      9        0.7739  0.4224\n",
      "     10        0.7414  0.4216\n",
      "     11        0.7853  0.4235\n",
      "     12        0.7392  0.4244\n",
      "     13        0.8262  0.4233\n",
      "     14        0.8074  0.4239\n",
      "     15        0.7384  0.4244\n",
      "     16        0.7690  0.4235\n",
      "     17        0.7365  0.4232\n",
      "     18        0.7808  0.4240\n",
      "     19        0.7320  0.4243\n",
      "     20        0.8380  0.4235\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7818\u001b[0m  0.4234\n",
      "      2        \u001b[36m0.7425\u001b[0m  0.4233\n",
      "      3        0.8026  0.4216\n",
      "      4        \u001b[36m0.7404\u001b[0m  0.4220\n",
      "      5        0.7879  0.4217\n",
      "      6        0.8173  0.4209\n",
      "      7        0.7472  0.4220\n",
      "      8        \u001b[36m0.7381\u001b[0m  0.4213\n",
      "      9        \u001b[36m0.7368\u001b[0m  0.4210\n",
      "     10        0.7756  0.4217\n",
      "     11        0.8151  0.4358\n",
      "     12        0.8436  0.4215\n",
      "     13        \u001b[36m0.7206\u001b[0m  0.4228\n",
      "     14        0.7430  0.4233\n",
      "     15        0.8143  0.4219\n",
      "     16        0.7770  0.4226\n",
      "     17        0.7389  0.4224\n",
      "     18        0.7376  0.4211\n",
      "     19        0.8243  0.4206\n",
      "     20        0.7877  0.4214\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7549\u001b[0m  0.4233\n",
      "      2        \u001b[36m0.7319\u001b[0m  0.4216\n",
      "      3        0.7877  0.4224\n",
      "      4        0.7767  0.4219\n",
      "      5        0.7729  0.4206\n",
      "      6        0.7719  0.4225\n",
      "      7        \u001b[36m0.7319\u001b[0m  0.4217\n",
      "      8        0.8257  0.4205\n",
      "      9        0.8179  0.4218\n",
      "     10        0.7749  0.4214\n",
      "     11        0.7947  0.4209\n",
      "     12        0.7881  0.4211\n",
      "     13        \u001b[36m0.7221\u001b[0m  0.4216\n",
      "     14        0.7601  0.4210\n",
      "     15        0.7580  0.4217\n",
      "     16        0.7468  0.4217\n",
      "     17        0.7895  0.4215\n",
      "     18        0.7457  0.4217\n",
      "     19        0.7259  0.4212\n",
      "     20        0.8104  0.4217\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=1; total time=   8.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8713\u001b[0m  0.4368\n",
      "      2        \u001b[36m0.8062\u001b[0m  0.4363\n",
      "      3        \u001b[36m0.7412\u001b[0m  0.4350\n",
      "      4        0.7606  0.4364\n",
      "      5        0.7994  0.4373\n",
      "      6        0.7529  0.4383\n",
      "      7        0.7655  0.4359\n",
      "      8        0.7738  0.4366\n",
      "      9        0.7492  0.4354\n",
      "     10        0.7645  0.4361\n",
      "     11        0.8429  0.4365\n",
      "     12        0.7781  0.4366\n",
      "     13        0.8001  0.4356\n",
      "     14        0.7534  0.4357\n",
      "     15        \u001b[36m0.7179\u001b[0m  0.4364\n",
      "     16        0.7848  0.4355\n",
      "     17        0.7719  0.4367\n",
      "     18        0.7790  0.4364\n",
      "     19        0.7519  0.4352\n",
      "     20        0.7444  0.4359\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8797\u001b[0m  0.4375\n",
      "      2        \u001b[36m0.7659\u001b[0m  0.4374\n",
      "      3        \u001b[36m0.7567\u001b[0m  0.4363\n",
      "      4        0.7902  0.4371\n",
      "      5        \u001b[36m0.7478\u001b[0m  0.4353\n",
      "      6        0.7608  0.4365\n",
      "      7        0.7956  0.4366\n",
      "      8        0.7585  0.4348\n",
      "      9        0.7714  0.4363\n",
      "     10        \u001b[36m0.7279\u001b[0m  0.4358\n",
      "     11        0.8987  0.4360\n",
      "     12        0.7600  0.4373\n",
      "     13        0.8084  0.4370\n",
      "     14        0.7920  0.4367\n",
      "     15        0.7641  0.4371\n",
      "     16        0.7643  0.4378\n",
      "     17        0.8520  0.4366\n",
      "     18        0.7472  0.4364\n",
      "     19        0.7592  0.4360\n",
      "     20        0.7710  0.4356\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8165\u001b[0m  0.4360\n",
      "      2        \u001b[36m0.7869\u001b[0m  0.4345\n",
      "      3        \u001b[36m0.7403\u001b[0m  0.4346\n",
      "      4        0.8103  0.4361\n",
      "      5        0.7605  0.4357\n",
      "      6        0.7434  0.4364\n",
      "      7        0.8118  0.4369\n",
      "      8        0.8186  0.4380\n",
      "      9        0.7928  0.4352\n",
      "     10        \u001b[36m0.7366\u001b[0m  0.4366\n",
      "     11        0.7761  0.4365\n",
      "     12        0.7812  0.4359\n",
      "     13        0.7794  0.4365\n",
      "     14        0.7836  0.4368\n",
      "     15        0.7753  0.4379\n",
      "     16        0.8178  0.4367\n",
      "     17        0.7746  0.4360\n",
      "     18        0.7900  0.4358\n",
      "     19        0.8036  0.4361\n",
      "     20        0.7779  0.4356\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=2; total time=   8.9s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8463\u001b[0m  0.4490\n",
      "      2        \u001b[36m0.7648\u001b[0m  0.4499\n",
      "      3        \u001b[36m0.7481\u001b[0m  0.4469\n",
      "      4        0.8134  0.4471\n",
      "      5        0.7618  0.4475\n",
      "      6        0.7689  0.4473\n",
      "      7        0.7797  0.4459\n",
      "      8        \u001b[36m0.7207\u001b[0m  0.4468\n",
      "      9        0.8253  0.4471\n",
      "     10        0.7794  0.4472\n",
      "     11        0.7477  0.4473\n",
      "     12        0.7778  0.4468\n",
      "     13        0.7710  0.4457\n",
      "     14        0.7788  0.4470\n",
      "     15        0.7309  0.4469\n",
      "     16        0.7211  0.4469\n",
      "     17        0.7742  0.4468\n",
      "     18        0.7427  0.4464\n",
      "     19        0.7613  0.4470\n",
      "     20        1.0200  0.4477\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8483\u001b[0m  0.4478\n",
      "      2        \u001b[36m0.8035\u001b[0m  0.4467\n",
      "      3        \u001b[36m0.7791\u001b[0m  0.4485\n",
      "      4        0.7841  0.4486\n",
      "      5        \u001b[36m0.7452\u001b[0m  0.4475\n",
      "      6        0.7546  0.4482\n",
      "      7        0.7911  0.4477\n",
      "      8        0.7532  0.4463\n",
      "      9        0.7996  0.4480\n",
      "     10        0.7471  0.4472\n",
      "     11        0.7732  0.4452\n",
      "     12        0.7458  0.4470\n",
      "     13        0.7989  0.4471\n",
      "     14        0.7473  0.4461\n",
      "     15        0.7639  0.4476\n",
      "     16        0.8028  0.4470\n",
      "     17        0.7776  0.4461\n",
      "     18        0.7806  0.4465\n",
      "     19        0.7542  0.4462\n",
      "     20        0.7929  0.4455\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8196\u001b[0m  0.4484\n",
      "      2        \u001b[36m0.7710\u001b[0m  0.4495\n",
      "      3        \u001b[36m0.7252\u001b[0m  0.4495\n",
      "      4        0.7605  0.4490\n",
      "      5        0.7957  0.4490\n",
      "      6        \u001b[36m0.7248\u001b[0m  0.4501\n",
      "      7        0.8372  0.4495\n",
      "      8        0.7540  0.4489\n",
      "      9        0.7884  0.4486\n",
      "     10        0.7379  0.4631\n",
      "     11        0.8279  0.4502\n",
      "     12        0.7457  0.4502\n",
      "     13        0.7737  0.4487\n",
      "     14        0.7644  0.4485\n",
      "     15        0.7711  0.4506\n",
      "     16        0.7734  0.4496\n",
      "     17        0.8072  0.4492\n",
      "     18        0.7317  0.4493\n",
      "     19        0.7600  0.4490\n",
      "     20        0.7597  0.4487\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=64, module__n_layers=3; total time=   9.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8615\u001b[0m  0.5282\n",
      "      2        \u001b[36m0.8417\u001b[0m  0.5259\n",
      "      3        \u001b[36m0.8057\u001b[0m  0.5252\n",
      "      4        0.8813  0.5251\n",
      "      5        \u001b[36m0.7618\u001b[0m  0.5258\n",
      "      6        0.9284  0.5256\n",
      "      7        0.8901  0.5259\n",
      "      8        0.7651  0.5261\n",
      "      9        0.7883  0.5258\n",
      "     10        0.9460  0.5246\n",
      "     11        0.8810  0.5268\n",
      "     12        0.8880  0.5261\n",
      "     13        0.7887  0.5241\n",
      "     14        0.9948  0.5240\n",
      "     15        \u001b[36m0.7456\u001b[0m  0.5243\n",
      "     16        0.8761  0.5229\n",
      "     17        0.8256  0.5234\n",
      "     18        0.7732  0.5228\n",
      "     19        0.8270  0.5237\n",
      "     20        0.8140  0.5192\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9424\u001b[0m  0.5235\n",
      "      2        \u001b[36m0.8729\u001b[0m  0.5224\n",
      "      3        \u001b[36m0.8507\u001b[0m  0.5221\n",
      "      4        0.9156  0.5207\n",
      "      5        \u001b[36m0.7923\u001b[0m  0.5219\n",
      "      6        0.8371  0.5223\n",
      "      7        \u001b[36m0.7804\u001b[0m  0.5232\n",
      "      8        0.9015  0.5219\n",
      "      9        0.9228  0.5222\n",
      "     10        0.9023  0.5211\n",
      "     11        0.8411  0.5216\n",
      "     12        0.8831  0.5217\n",
      "     13        0.8141  0.5221\n",
      "     14        0.7996  0.5225\n",
      "     15        0.8050  0.5220\n",
      "     16        \u001b[36m0.7308\u001b[0m  0.5216\n",
      "     17        0.8339  0.5222\n",
      "     18        0.8101  0.5229\n",
      "     19        0.9191  0.5227\n",
      "     20        0.8206  0.5213\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9724\u001b[0m  0.5257\n",
      "      2        \u001b[36m0.8298\u001b[0m  0.5246\n",
      "      3        0.8704  0.5241\n",
      "      4        0.9421  0.5240\n",
      "      5        \u001b[36m0.7799\u001b[0m  0.5247\n",
      "      6        \u001b[36m0.7717\u001b[0m  0.5241\n",
      "      7        \u001b[36m0.7619\u001b[0m  0.5237\n",
      "      8        0.8671  0.5237\n",
      "      9        0.7949  0.5231\n",
      "     10        0.7637  0.5233\n",
      "     11        0.7874  0.5244\n",
      "     12        0.8858  0.5236\n",
      "     13        0.9067  0.5237\n",
      "     14        0.9501  0.5241\n",
      "     15        0.8399  0.5236\n",
      "     16        0.8275  0.5235\n",
      "     17        0.8546  0.5236\n",
      "     18        0.8710  0.5233\n",
      "     19        0.9812  0.5239\n",
      "     20        0.7841  0.5239\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=1; total time=  10.6s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9565\u001b[0m  0.5460\n",
      "      2        \u001b[36m0.8910\u001b[0m  0.5430\n",
      "      3        \u001b[36m0.7791\u001b[0m  0.5428\n",
      "      4        0.7949  0.5427\n",
      "      5        0.8011  0.5431\n",
      "      6        1.0388  0.5441\n",
      "      7        0.9094  0.5425\n",
      "      8        0.7904  0.5425\n",
      "      9        0.8180  0.5437\n",
      "     10        0.8042  0.5392\n",
      "     11        0.8247  0.5423\n",
      "     12        0.7959  0.5428\n",
      "     13        0.7880  0.5415\n",
      "     14        0.7966  0.5429\n",
      "     15        0.8811  0.5441\n",
      "     16        0.9283  0.5431\n",
      "     17        0.9015  0.5455\n",
      "     18        0.8490  0.5434\n",
      "     19        0.8943  0.5432\n",
      "     20        0.9116  0.5435\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9648\u001b[0m  0.5377\n",
      "      2        \u001b[36m0.7950\u001b[0m  0.5377\n",
      "      3        0.8362  0.5375\n",
      "      4        0.8778  0.5387\n",
      "      5        0.8176  0.5371\n",
      "      6        0.9221  0.5378\n",
      "      7        0.8524  0.5384\n",
      "      8        0.8478  0.5408\n",
      "      9        \u001b[36m0.7943\u001b[0m  0.5417\n",
      "     10        0.8875  0.5412\n",
      "     11        0.8780  0.5419\n",
      "     12        0.8563  0.5389\n",
      "     13        \u001b[36m0.7588\u001b[0m  0.5397\n",
      "     14        0.8276  0.5423\n",
      "     15        0.7885  0.5412\n",
      "     16        0.8019  0.5401\n",
      "     17        0.8066  0.5404\n",
      "     18        0.8391  0.5399\n",
      "     19        0.8308  0.5436\n",
      "     20        0.7826  0.5431\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  11.0s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1802\u001b[0m  0.5441\n",
      "      2        \u001b[36m0.8335\u001b[0m  0.5457\n",
      "      3        0.8650  0.5472\n",
      "      4        0.9082  0.5446\n",
      "      5        \u001b[36m0.7449\u001b[0m  0.5449\n",
      "      6        0.7931  0.5449\n",
      "      7        0.8045  0.5431\n",
      "      8        0.7733  0.5449\n",
      "      9        1.1633  0.5448\n",
      "     10        0.7855  0.5449\n",
      "     11        0.7541  0.5459\n",
      "     12        0.9360  0.5444\n",
      "     13        0.7649  0.5439\n",
      "     14        0.7999  0.5436\n",
      "     15        0.9160  0.5462\n",
      "     16        0.8187  0.5450\n",
      "     17        0.8578  0.5445\n",
      "     18        0.7788  0.5444\n",
      "     19        0.9442  0.5454\n",
      "     20        0.7588  0.5446\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=2; total time=  11.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9032\u001b[0m  0.5549\n",
      "      2        \u001b[36m0.8398\u001b[0m  0.5570\n",
      "      3        0.8480  0.5585\n",
      "      4        \u001b[36m0.7986\u001b[0m  0.5583\n",
      "      5        0.8402  0.5585\n",
      "      6        \u001b[36m0.7501\u001b[0m  0.5575\n",
      "      7        0.8692  0.5577\n",
      "      8        0.7935  0.5587\n",
      "      9        0.8177  0.5566\n",
      "     10        0.8469  0.5592\n",
      "     11        0.9252  0.5593\n",
      "     12        0.7757  0.5632\n",
      "     13        0.8751  0.5605\n",
      "     14        0.7707  0.5591\n",
      "     15        0.9587  0.5578\n",
      "     16        0.8174  0.5573\n",
      "     17        0.9082  0.5600\n",
      "     18        0.9125  0.5599\n",
      "     19        0.8870  0.5584\n",
      "     20        0.8448  0.5600\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8274\u001b[0m  0.5583\n",
      "      2        \u001b[36m0.8272\u001b[0m  0.5572\n",
      "      3        \u001b[36m0.8048\u001b[0m  0.5581\n",
      "      4        0.8887  0.5579\n",
      "      5        0.8164  0.5581\n",
      "      6        0.8054  0.5591\n",
      "      7        0.8231  0.5615\n",
      "      8        0.8747  0.5624\n",
      "      9        \u001b[36m0.7626\u001b[0m  0.5608\n",
      "     10        0.8992  0.5593\n",
      "     11        0.9504  0.5598\n",
      "     12        0.8661  0.5606\n",
      "     13        0.9937  0.5617\n",
      "     14        0.8165  0.5633\n",
      "     15        0.8648  0.5645\n",
      "     16        0.8854  0.5618\n",
      "     17        0.8060  0.5590\n",
      "     18        0.7729  0.5599\n",
      "     19        0.8643  0.5603\n",
      "     20        0.7800  0.5602\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9480\u001b[0m  0.5594\n",
      "      2        \u001b[36m0.8128\u001b[0m  0.5595\n",
      "      3        0.8224  0.5594\n",
      "      4        \u001b[36m0.7824\u001b[0m  0.5598\n",
      "      5        0.8285  0.5602\n",
      "      6        0.8049  0.5621\n",
      "      7        0.8513  0.5597\n",
      "      8        0.9199  0.5588\n",
      "      9        0.8105  0.5598\n",
      "     10        0.9213  0.5591\n",
      "     11        0.8592  0.5645\n",
      "     12        0.7988  0.5613\n",
      "     13        0.7988  0.5642\n",
      "     14        0.8563  0.5630\n",
      "     15        0.8932  0.5595\n",
      "     16        0.9905  0.5591\n",
      "     17        \u001b[36m0.7474\u001b[0m  0.5586\n",
      "     18        0.8355  0.5594\n",
      "     19        0.8379  0.5588\n",
      "     20        0.8347  0.5590\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=128, module__n_layers=3; total time=  11.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5299\u001b[0m  0.8095\n",
      "      2        \u001b[36m0.8916\u001b[0m  0.7992\n",
      "      3        0.9845  0.7997\n",
      "      4        1.5457  0.7986\n",
      "      5        0.9255  0.8038\n",
      "      6        \u001b[36m0.8345\u001b[0m  0.7973\n",
      "      7        0.9825  0.7983\n",
      "      8        1.6142  0.7984\n",
      "      9        1.5524  0.8040\n",
      "     10        1.2645  0.7974\n",
      "     11        0.9582  0.7984\n",
      "     12        0.9481  0.7994\n",
      "     13        0.9333  0.7988\n",
      "     14        0.9076  0.7985\n",
      "     15        0.9520  0.7983\n",
      "     16        1.0379  0.7974\n",
      "     17        1.1231  0.7974\n",
      "     18        0.9444  0.7978\n",
      "     19        1.0288  0.7995\n",
      "     20        0.9310  0.7985\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2301\u001b[0m  0.7976\n",
      "      2        \u001b[36m1.1304\u001b[0m  0.7943\n",
      "      3        \u001b[36m0.9059\u001b[0m  0.7969\n",
      "      4        1.0657  0.7961\n",
      "      5        1.0309  0.7963\n",
      "      6        1.0237  0.7938\n",
      "      7        1.0287  0.7954\n",
      "      8        1.4689  0.7958\n",
      "      9        1.0584  0.7958\n",
      "     10        0.9130  0.7949\n",
      "     11        0.9397  0.7943\n",
      "     12        \u001b[36m0.8789\u001b[0m  0.7956\n",
      "     13        0.9553  0.7943\n",
      "     14        1.1742  0.7940\n",
      "     15        1.0770  0.7944\n",
      "     16        0.8880  0.7934\n",
      "     17        0.9792  0.7940\n",
      "     18        1.0206  0.7942\n",
      "     19        0.9299  0.7942\n",
      "     20        1.4779  0.7940\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  16.1s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3945\u001b[0m  0.8029\n",
      "      2        \u001b[36m1.0061\u001b[0m  0.8004\n",
      "      3        \u001b[36m0.9645\u001b[0m  0.7996\n",
      "      4        1.0214  0.7989\n",
      "      5        1.1003  0.7991\n",
      "      6        1.0102  0.7985\n",
      "      7        1.2077  0.7989\n",
      "      8        0.9942  0.7983\n",
      "      9        \u001b[36m0.8420\u001b[0m  0.7993\n",
      "     10        0.8711  0.7995\n",
      "     11        1.0763  0.8002\n",
      "     12        1.6163  0.7996\n",
      "     13        1.0115  0.7989\n",
      "     14        0.9568  0.7989\n",
      "     15        1.1252  0.7986\n",
      "     16        1.0129  0.7991\n",
      "     17        1.3883  0.7991\n",
      "     18        1.1571  0.7987\n",
      "     19        0.9373  0.7998\n",
      "     20        1.0547  0.7980\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=1; total time=  16.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3011\u001b[0m  0.8316\n",
      "      2        \u001b[36m1.1689\u001b[0m  0.8295\n",
      "      3        \u001b[36m1.0093\u001b[0m  0.8298\n",
      "      4        \u001b[36m0.9004\u001b[0m  0.8284\n",
      "      5        1.1931  0.8296\n",
      "      6        1.0094  0.8286\n",
      "      7        \u001b[36m0.9003\u001b[0m  0.8295\n",
      "      8        1.1429  0.8287\n",
      "      9        1.4390  0.8303\n",
      "     10        \u001b[36m0.8450\u001b[0m  0.8285\n",
      "     11        1.1879  0.8262\n",
      "     12        1.4098  0.8289\n",
      "     13        1.0675  0.8354\n",
      "     14        1.0472  0.8290\n",
      "     15        0.9845  0.8282\n",
      "     16        0.9509  0.8266\n",
      "     17        1.0855  0.8343\n",
      "     18        0.9013  0.8269\n",
      "     19        1.0123  0.8276\n",
      "     20        0.9468  0.8308\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6095\u001b[0m  0.8381\n",
      "      2        \u001b[36m1.0206\u001b[0m  0.8293\n",
      "      3        1.0716  0.8267\n",
      "      4        \u001b[36m0.9030\u001b[0m  0.8287\n",
      "      5        1.1917  0.8277\n",
      "      6        0.9386  0.8264\n",
      "      7        1.0034  0.8262\n",
      "      8        1.0244  0.8282\n",
      "      9        0.9701  0.8280\n",
      "     10        1.1626  0.8269\n",
      "     11        0.9753  0.8262\n",
      "     12        1.0930  0.8270\n",
      "     13        1.2069  0.8272\n",
      "     14        0.9712  0.8269\n",
      "     15        1.1891  0.8269\n",
      "     16        0.9034  0.8268\n",
      "     17        0.9701  0.8269\n",
      "     18        1.0414  0.8267\n",
      "     19        1.0608  0.8276\n",
      "     20        \u001b[36m0.8922\u001b[0m  0.8282\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.7s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1972\u001b[0m  0.8355\n",
      "      2        \u001b[36m1.0298\u001b[0m  0.8310\n",
      "      3        \u001b[36m0.8533\u001b[0m  0.8310\n",
      "      4        0.9779  0.8309\n",
      "      5        1.0921  0.8332\n",
      "      6        0.8616  0.8309\n",
      "      7        1.1460  0.8312\n",
      "      8        0.8670  0.8316\n",
      "      9        1.4377  0.8314\n",
      "     10        1.0154  0.8327\n",
      "     11        1.0045  0.8375\n",
      "     12        1.1239  0.8301\n",
      "     13        0.8730  0.8301\n",
      "     14        1.2182  0.8317\n",
      "     15        1.1393  0.8310\n",
      "     16        1.2934  0.8319\n",
      "     17        1.0375  0.8316\n",
      "     18        1.0763  0.8329\n",
      "     19        1.3000  0.8317\n",
      "     20        1.1516  0.8329\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=2; total time=  16.8s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5882\u001b[0m  0.8614\n",
      "      2        \u001b[36m0.8778\u001b[0m  0.8613\n",
      "      3        0.9745  0.8605\n",
      "      4        0.9873  0.8612\n",
      "      5        1.0970  0.8612\n",
      "      6        0.9519  0.8613\n",
      "      7        1.0733  0.8603\n",
      "      8        1.1216  0.8614\n",
      "      9        0.9937  0.8616\n",
      "     10        0.9586  0.8645\n",
      "     11        1.2048  0.8603\n",
      "     12        1.2069  0.8607\n",
      "     13        0.9726  0.8611\n",
      "     14        0.9514  0.8609\n",
      "     15        1.2394  0.8615\n",
      "     16        1.0388  0.8638\n",
      "     17        1.2026  0.8617\n",
      "     18        0.9099  0.8633\n",
      "     19        1.1329  0.8618\n",
      "     20        1.0925  0.8606\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  17.4s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9634\u001b[0m  0.8514\n",
      "      2        1.0292  0.8511\n",
      "      3        1.0879  0.8500\n",
      "      4        \u001b[36m0.8660\u001b[0m  0.8521\n",
      "      5        0.9519  0.8499\n",
      "      6        1.1671  0.8478\n",
      "      7        1.1723  0.8496\n",
      "      8        1.3918  0.8478\n",
      "      9        1.1358  0.8492\n",
      "     10        0.9094  0.8501\n",
      "     11        1.1073  0.8498\n",
      "     12        0.9587  0.8488\n",
      "     13        1.1974  0.8500\n",
      "     14        0.9591  0.8502\n",
      "     15        \u001b[36m0.8617\u001b[0m  0.8565\n",
      "     16        0.8922  0.8505\n",
      "     17        1.4027  0.8517\n",
      "     18        0.9603  0.8571\n",
      "     19        1.3906  0.8481\n",
      "     20        0.9362  0.8489\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  17.2s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1526\u001b[0m  0.8598\n",
      "      2        \u001b[36m0.9996\u001b[0m  0.8653\n",
      "      3        1.1924  0.8578\n",
      "      4        1.1890  0.8571\n",
      "      5        1.0271  0.8571\n",
      "      6        1.0211  0.8572\n",
      "      7        \u001b[36m0.8461\u001b[0m  0.8570\n",
      "      8        1.0487  0.8546\n",
      "      9        0.9937  0.8555\n",
      "     10        0.9206  0.8538\n",
      "     11        1.0489  0.8549\n",
      "     12        0.9534  0.8552\n",
      "     13        0.9992  0.8554\n",
      "     14        0.9196  0.8556\n",
      "     15        0.8581  0.8560\n",
      "     16        1.2246  0.8551\n",
      "     17        1.1907  0.8551\n",
      "     18        0.9963  0.8571\n",
      "     19        1.0197  0.8563\n",
      "     20        0.9356  0.8563\n",
      "[CV] END lr=0.1, module__activation_func=<function tanh at 0x7cad8477faf0>, module__hidden_dim=256, module__n_layers=3; total time=  17.3s\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6948\u001b[0m  0.8329\n",
      "      2        \u001b[36m0.5805\u001b[0m  0.8318\n",
      "      3        \u001b[36m0.3740\u001b[0m  0.8317\n",
      "      4        \u001b[36m0.3543\u001b[0m  0.8326\n",
      "      5        \u001b[36m0.1735\u001b[0m  0.8336\n",
      "      6        \u001b[36m0.1487\u001b[0m  0.8318\n",
      "      7        \u001b[36m0.0853\u001b[0m  0.8321\n",
      "      8        \u001b[36m0.0386\u001b[0m  0.8342\n",
      "      9        \u001b[36m0.0221\u001b[0m  0.8310\n",
      "     10        0.0459  0.8295\n",
      "     11        0.0870  0.8335\n",
      "     12        0.0483  0.8311\n",
      "     13        \u001b[36m0.0054\u001b[0m  0.8308\n",
      "     14        \u001b[36m0.0006\u001b[0m  0.8309\n",
      "     15        \u001b[36m0.0004\u001b[0m  0.8313\n",
      "     16        \u001b[36m0.0003\u001b[0m  0.8337\n",
      "     17        \u001b[36m0.0002\u001b[0m  0.8387\n",
      "     18        \u001b[36m0.0002\u001b[0m  0.8347\n",
      "     19        \u001b[36m0.0001\u001b[0m  0.8342\n",
      "     20        \u001b[36m0.0001\u001b[0m  0.8332\n",
      "Best parameters found:  {'lr': 0.001, 'module__activation_func': <function relu at 0x7cad8477f1f0>, 'module__hidden_dim': 128, 'module__n_layers': 3}\n",
      "Best accuracy:  0.7054754168039455\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "#####\n",
    "#####\n",
    "#####\n",
    "#####\n",
    "#####\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Load your data\n",
    "#rdata = pd.read_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/train_count_matrix.csv')\n",
    "#qdata = pd.read_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/test_count_matrix.csv')\n",
    "#rlabel = pd.read_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/train_label.csv')\n",
    "#qlabel = pd.read_csv('../../preprocessed_data/inhibitory_neuron/train_test_set/test_label.csv')\n",
    "\n",
    "train_labels = pd.Series(rlabel['diagnosis'].values, index=rdata.columns[1:])\n",
    "test_labels = pd.Series(qlabel['diagnosis'].values, index=qdata.columns[1:]) \n",
    "\n",
    "label_mapping = {'AD_with_Plaques': 1, 'NCI_with_No_Plaques': 0}\n",
    "train_labels = train_labels.map(label_mapping)\n",
    "test_labels = test_labels.map(label_mapping)\n",
    "\n",
    "# Prepare data\n",
    "X_train = rdata.set_index('ensemble_gene_name').T\n",
    "X_test = qdata.set_index('ensemble_gene_name').T\n",
    "train_labels = train_labels.loc[X_train.index]\n",
    "test_labels = test_labels.loc[X_test.index]\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = train_labels.values\n",
    "X_test = X_test.values\n",
    "y_test = test_labels.values\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Select 10% of the data\n",
    "X_train_small, _, y_train_small, _ = train_test_split(X_train_tensor, y_train_tensor, test_size=0.9, stratify=y_train_tensor, random_state=42)\n",
    "# Model definition\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers=1, activation_func=F.relu):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        for _ in range(n_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation_func = activation_func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "            x = self.activation_func(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Grid search setup\n",
    "net = NeuralNetClassifier(\n",
    "    SimpleNN,\n",
    "    module__input_dim=X_train_small.shape[1],\n",
    "    module__output_dim=1,\n",
    "    max_epochs=20,\n",
    "    lr=0.01,\n",
    "    criterion=nn.BCEWithLogitsLoss,\n",
    "    optimizer=optim.Adam,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=None,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.01, 0.1],\n",
    "    'module__hidden_dim': [64, 128, 256],\n",
    "    'module__n_layers': [1, 2, 3],\n",
    "    'module__activation_func': [F.relu, F.sigmoid, F.tanh]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, param_grid, refit=True, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the grid search on the small dataset\n",
    "gs.fit(X_train_small, y_train_small)\n",
    "\n",
    "print(\"Best parameters found: \", gs.best_params_)\n",
    "print(\"Best accuracy: \", gs.best_score_)\n",
    "\n",
    "\n",
    "####\n",
    "#####\n",
    "#####\n",
    "#####\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "785d50a0-99ee-40e8-808d-73895e9f65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train_tensor.shape[1]  # Number of genes\n",
    "hidden_dim = 128  # Example hidden layer size\n",
    "output_dim = 1  # Binary classification: Alzheimer's vs. Control\n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "920b2e0b-cb56-466f-ad4a-63aed3dd2036",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([32, 1])) must be the same as input size (torch.Size([32]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/loss.py:731\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/functional.py:3224\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3221\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32, 1])) must be the same as input size (torch.Size([32]))"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 60\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e435577-197b-4887-9351-4638bc02fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train_tensor.shape[1]  # Number of genes\n",
    "hidden_dim = 128  # Example hidden layer size\n",
    "output_dim = 1  # Binary classification: Alzheimer's vs. Control\n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb947549-55db-41db-9eec-122e90aad2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skorch\n",
      "  Downloading skorch-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from skorch) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from skorch) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from skorch) (1.10.1)\n",
      "Collecting tabulate>=0.7.7 (from skorch)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from skorch) (4.66.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from scikit-learn>=0.22.0->skorch) (3.5.0)\n",
      "Downloading skorch-1.0.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate, skorch\n",
      "Successfully installed skorch-1.0.0 tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "036c7a15-e811-493a-a34c-e8ca8420c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train_tensor.shape[1]  # Number of genes (features)\n",
    "hidden_dim = 128  # Example hidden layer size\n",
    "output_dim = 1  # Binary classification: Alzheimer's vs. Control\n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93b1e12b-818b-4c46-943b-1b5497fb1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_tensor.numpy()\n",
    "y_train = y_train_tensor.numpy()\n",
    "\n",
    "# Reshape y_train to be a 2D array\n",
    "y_train = y_train.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5439584b-ffe2-4d56-9eaa-233596e89f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    SimpleNN,\n",
    "    module__input_dim=X_train.shape[1],\n",
    "    module__hidden_dim=128,  # Example hidden layer size, this can be tuned\n",
    "    module__output_dim=1,\n",
    "    max_epochs=20,\n",
    "    lr=0.01,\n",
    "    iterator_train__shuffle=True,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    criterion=nn.BCEWithLogitsLoss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "812307fd-14ab-4908-92f8-1151360c301a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m70\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule__hidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m],\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize GridSearchCV with the skorch classifier and parameter grid\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m(net, params, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Fit GridSearchCV\u001b[39;00m\n\u001b[1;32m     11\u001b[0m gs\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lr': [0.001, 0.01, 0.1],\n",
    "    'max_epochs': [20, 50, 70],\n",
    "    'module__hidden_dim': [64, 128, 256],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the skorch classifier and parameter grid\n",
    "gs = GridSearchCV(net, params, refit=True, cv=3, scoring='roc_auc')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters found: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb36b7e-da5c-4264-aa11-c5f0b7167d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Best parameters from GridSearchCV\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Initialize the final model with the best parameters\u001b[39;00m\n\u001b[1;32m     23\u001b[0m final_model \u001b[38;5;241m=\u001b[39m NeuralNetClassifier(\n\u001b[1;32m     24\u001b[0m     SimpleNN,\n\u001b[1;32m     25\u001b[0m     module__input_dim\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss\n\u001b[1;32m     33\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gs' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "# Define the neural network class (SimpleNN)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Best parameters from GridSearchCV\n",
    "best_params = gs.best_params_\n",
    "\n",
    "# Initialize the final model with the best parameters\n",
    "final_model = NeuralNetClassifier(\n",
    "    SimpleNN,\n",
    "    module__input_dim=X_train.shape[1],\n",
    "    module__hidden_dim=best_params['module__hidden_dim'],\n",
    "    module__output_dim=1,\n",
    "    max_epochs=best_params['max_epochs'],\n",
    "    lr=best_params['lr'],\n",
    "    iterator_train__shuffle=True,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    criterion=nn.BCEWithLogitsLoss\n",
    ")\n",
    "\n",
    "# Train the final model\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d133ebf0-3627-4749-aa41-292981fa15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming you have defined your model, criterion, optimizer, and data loaders\n",
    "\n",
    "# Example training loop\n",
    "for inputs, labels in train_loader:\n",
    "    # Ensure labels are reshaped to match the output shape of your model\n",
    "    labels = labels.view(-1, 1)  # Reshape labels to (batch_size, 1)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3d70eefb-5f87-42ae-ace9-9611db5f6e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.4880\n",
      "Epoch [2/50], Loss: 0.4303\n",
      "Epoch [3/50], Loss: 0.3954\n",
      "Epoch [4/50], Loss: 0.3486\n",
      "Epoch [5/50], Loss: 0.3176\n",
      "Epoch [6/50], Loss: 0.2904\n",
      "Epoch [7/50], Loss: 0.2548\n",
      "Epoch [8/50], Loss: 0.2137\n",
      "Epoch [9/50], Loss: 0.2007\n",
      "Epoch [10/50], Loss: 0.1738\n",
      "Epoch [11/50], Loss: 0.1517\n",
      "Epoch [12/50], Loss: 0.1411\n",
      "Epoch [13/50], Loss: 0.1754\n",
      "Epoch [14/50], Loss: 0.1617\n",
      "Epoch [15/50], Loss: 0.1415\n",
      "Epoch [16/50], Loss: 0.1354\n",
      "Epoch [17/50], Loss: 0.1199\n",
      "Epoch [18/50], Loss: 0.1076\n",
      "Epoch [19/50], Loss: 0.1120\n",
      "Epoch [20/50], Loss: 0.1027\n",
      "Epoch [21/50], Loss: 0.1112\n",
      "Epoch [22/50], Loss: 0.0862\n",
      "Epoch [23/50], Loss: 0.0871\n",
      "Epoch [24/50], Loss: 0.1017\n",
      "Epoch [25/50], Loss: 0.0803\n",
      "Epoch [26/50], Loss: 0.0687\n",
      "Epoch [27/50], Loss: 0.0738\n",
      "Epoch [28/50], Loss: 0.0650\n",
      "Epoch [29/50], Loss: 0.0635\n",
      "Epoch [30/50], Loss: 0.0653\n",
      "Epoch [31/50], Loss: 0.0765\n",
      "Epoch [32/50], Loss: 0.0534\n",
      "Epoch [33/50], Loss: 0.0586\n",
      "Epoch [34/50], Loss: 0.0457\n",
      "Epoch [35/50], Loss: 0.0651\n",
      "Epoch [36/50], Loss: 0.0516\n",
      "Epoch [37/50], Loss: 0.0510\n",
      "Epoch [38/50], Loss: 0.0400\n",
      "Epoch [39/50], Loss: 0.0609\n",
      "Epoch [40/50], Loss: 0.0614\n",
      "Epoch [41/50], Loss: 0.0472\n",
      "Epoch [42/50], Loss: 0.0392\n",
      "Epoch [43/50], Loss: 0.0478\n",
      "Epoch [44/50], Loss: 0.0490\n",
      "Epoch [45/50], Loss: 0.0380\n",
      "Epoch [46/50], Loss: 0.0344\n",
      "Epoch [47/50], Loss: 0.0449\n",
      "Epoch [48/50], Loss: 0.0348\n",
      "Epoch [49/50], Loss: 0.0403\n",
      "Epoch [50/50], Loss: 0.0508\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming you have defined your model, criterion, optimizer, and data loaders\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        # Ensure labels are reshaped to match the output shape of your model\n",
    "        labels = labels.view(-1, 1)  # Reshape labels to (batch_size, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)  # Accumulate the loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c1e02cc-131a-4288-b468-6ed261fbec36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4c868bef-2c8b-4b91-a894-f39ad6698410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "010ed40f-4f8a-44ce-bc0e-73c43681d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6247\n",
      "Test AUC: 0.6668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor).squeeze()\n",
    "    test_predictions = torch.round(torch.sigmoid(test_outputs))\n",
    "    accuracy = accuracy_score(y_test_tensor, test_predictions)\n",
    "    auc = roc_auc_score(y_test_tensor, test_outputs)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test AUC: {auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d38f24e-bbdb-4b14-96cd-7049cc835862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.44.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from shap) (1.24.4)\n",
      "Requirement already satisfied: scipy in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from shap) (2.0.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from shap) (24.1)\n",
      "Collecting slicer==0.0.7 (from shap)\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting numba (from shap)\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba->shap)\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from numba->shap) (8.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas->shap) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/usman/miniconda3/envs/myenv/lib/python3.8/site-packages (from importlib-metadata->numba->shap) (3.19.2)\n",
      "Downloading shap-0.44.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (538 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m538.6/538.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: slicer, llvmlite, cloudpickle, numba, shap\n",
      "Successfully installed cloudpickle-3.0.0 llvmlite-0.41.1 numba-0.58.1 shap-0.44.1 slicer-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ba4d0-33ac-4435-bd3e-d5b0f2bd5560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.DeepExplainer(model, X_train_tensor)\n",
    "shap_values = explainer.shap_values(X_test_tensor)\n",
    "\n",
    "# Visualize the feature importances\n",
    "shap.summary_plot(shap_values, X_test_tensor.numpy(), feature_names=rdata['ensemble_gene_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c2f5388-8153-4cdb-a778-c2cd0a2d74f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID_x</th>\n",
       "      <th>clinical_diagnosis_x</th>\n",
       "      <th>pathological_diagnosis_x</th>\n",
       "      <th>clinical_pathological_AD_x</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "      <th>individualID_y</th>\n",
       "      <th>clinical_diagnosis_y</th>\n",
       "      <th>pathological_diagnosis_y</th>\n",
       "      <th>clinical_pathological_AD_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGAACGCGT.6.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>2651</td>\n",
       "      <td>1533</td>\n",
       "      <td>8.185590</td>\n",
       "      <td>0.452659</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-90639</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGAACTGAT.10.12</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGAAGCGGG.31.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGAATCCCT.14.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15297</td>\n",
       "      <td>4688</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-68841</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424425</th>\n",
       "      <td>TTTGTTGTCTTAGCAG.7.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9309</td>\n",
       "      <td>3459</td>\n",
       "      <td>2.062520</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.891670</td>\n",
       "      <td>Inh VIP TSHZ2</td>\n",
       "      <td>ROSMAP-77886</td>\n",
       "      <td>no</td>\n",
       "      <td>R2554598</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R2554598</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424426</th>\n",
       "      <td>TTTGTTGTCTTCCCGA.28.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424427</th>\n",
       "      <td>TTTGTTGTCTTCGACC.3.13</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>16770</td>\n",
       "      <td>5431</td>\n",
       "      <td>2.098986</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-53472</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424428</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424430</th>\n",
       "      <td>TTTGTTGTCTTTGCAT.22.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15282</td>\n",
       "      <td>4330</td>\n",
       "      <td>3.291454</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>0.869104</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-22203</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329699 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "1         AAACCCAAGAACGCGT.6.6     ROSMAP        2651          1533   \n",
       "2       AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764   \n",
       "3        AAACCCAAGAAGCGGG.31.8     ROSMAP       11658          4377   \n",
       "4        AAACCCAAGAATCCCT.14.8     ROSMAP       15297          4688   \n",
       "...                        ...        ...         ...           ...   \n",
       "424425    TTTGTTGTCTTAGCAG.7.9     ROSMAP        9309          3459   \n",
       "424426   TTTGTTGTCTTCCCGA.28.6     ROSMAP       22844          5507   \n",
       "424427   TTTGTTGTCTTCGACC.3.13     ROSMAP       16770          5431   \n",
       "424428   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "424430   TTTGTTGTCTTTGCAT.22.8     ROSMAP       15282          4330   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "1         8.185590    0.452659          0.930517         Inh L3-5 SST MAFB   \n",
       "2         4.809160    0.274809          0.901814            Inh LAMP5 RELN   \n",
       "3         5.738549    0.394579          0.895381            Inh VIP CLSTN2   \n",
       "4         0.921749    0.307250          0.877260            Inh VIP CLSTN2   \n",
       "...            ...         ...               ...                       ...   \n",
       "424425    2.062520    0.225588          0.891670             Inh VIP TSHZ2   \n",
       "424426    0.153213    0.358956          0.858250           Inh PVALB SULF1   \n",
       "424427    2.098986    0.679785          0.884093             Inh CUX2 MSR1   \n",
       "424428    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "424430    3.291454    0.261746          0.869104            Inh PVALB HTR4   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD individualID_x  \\\n",
       "0       ROSMAP-65967                        yes       R3857147   \n",
       "1       ROSMAP-90639                        yes       R7090624   \n",
       "2       ROSMAP-57958                        yes       R2347173   \n",
       "3       ROSMAP-40761                        yes       R1287407   \n",
       "4       ROSMAP-68841                        yes       R3757880   \n",
       "...              ...                        ...            ...   \n",
       "424425  ROSMAP-77886                         no       R2554598   \n",
       "424426  ROSMAP-38931                         no       R6292415   \n",
       "424427  ROSMAP-53472                        yes       R3863249   \n",
       "424428  ROSMAP-44788                         no       R5221394   \n",
       "424430  ROSMAP-22203                        yes       R7583108   \n",
       "\n",
       "       clinical_diagnosis_x pathological_diagnosis_x  \\\n",
       "0                        AD                       AD   \n",
       "1                       NCI                       AD   \n",
       "2                       NCI                       AD   \n",
       "3                     False                       AD   \n",
       "4                       NCI                       AD   \n",
       "...                     ...                      ...   \n",
       "424425                  NCI                    False   \n",
       "424426                  NCI                    No AD   \n",
       "424427                False                    False   \n",
       "424428                  NCI                    No AD   \n",
       "424430                   AD                       AD   \n",
       "\n",
       "       clinical_pathological_AD_x train_test_clinical_and_pathological  \\\n",
       "0                 AD_with_Plaques                                train   \n",
       "1                           False                                  NaN   \n",
       "2                           False                                  NaN   \n",
       "3                           False                                  NaN   \n",
       "4                           False                                  NaN   \n",
       "...                           ...                                  ...   \n",
       "424425                      False                                  NaN   \n",
       "424426        NCI_with_No_Plaques                                train   \n",
       "424427                      False                                  NaN   \n",
       "424428        NCI_with_No_Plaques                                 test   \n",
       "424430            AD_with_Plaques                                train   \n",
       "\n",
       "       individualID_y clinical_diagnosis_y pathological_diagnosis_y  \\\n",
       "0            R3857147                   AD                       AD   \n",
       "1            R7090624                  NCI                       AD   \n",
       "2            R2347173                  NCI                       AD   \n",
       "3            R1287407                False                       AD   \n",
       "4            R3757880                  NCI                       AD   \n",
       "...               ...                  ...                      ...   \n",
       "424425       R2554598                  NCI                    False   \n",
       "424426       R6292415                  NCI                    No AD   \n",
       "424427       R3863249                False                    False   \n",
       "424428       R5221394                  NCI                    No AD   \n",
       "424430       R7583108                   AD                       AD   \n",
       "\n",
       "       clinical_pathological_AD_y  \n",
       "0                 AD_with_Plaques  \n",
       "1                           False  \n",
       "2                           False  \n",
       "3                           False  \n",
       "4                           False  \n",
       "...                           ...  \n",
       "424425                      False  \n",
       "424426        NCI_with_No_Plaques  \n",
       "424427                      False  \n",
       "424428        NCI_with_No_Plaques  \n",
       "424430            AD_with_Plaques  \n",
       "\n",
       "[329699 rows x 19 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981191d4-e4d8-42ad-8367-ea52cd5878e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "089991e4-c134-4cc3-883f-0d0e951f4ca5",
   "metadata": {},
   "source": [
    "# Correlation PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b01d24a-4cc7-4103-9ad7-894c6a90de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rdata = pd.read_csv('/12tb_dsk1/usman/Single_Cell_Microglia_Project/preprocessed_data/inhibitory_neuron/train_test_set/train_count_matrix.csv')\n",
    "qdata = pd.read_csv('/12tb_dsk1/usman/Single_Cell_Microglia_Project/preprocessed_data/inhibitory_neuron/train_test_set/test_count_matrix.csv')\n",
    "rdata.set_index('ensemble_gene_name', inplace =  True)\n",
    "qdata.set_index('ensemble_gene_name', inplace =  True)\n",
    "merged_data_clinical_pathological = pd.concat([rdata.T,qdata.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ecb9f5-b135-4a43-9bea-108963040143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ensemble_gene_name</th>\n",
       "      <th>ENSG00000163463</th>\n",
       "      <th>ENSG00000163462</th>\n",
       "      <th>ENSG00000185499</th>\n",
       "      <th>ENSG00000169231</th>\n",
       "      <th>ENSG00000261905</th>\n",
       "      <th>ENSG00000263290</th>\n",
       "      <th>ENSG00000261893</th>\n",
       "      <th>ENSG00000263324</th>\n",
       "      <th>ENSG00000262785</th>\n",
       "      <th>ENSG00000160752</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000228253</th>\n",
       "      <th>ENSG00000198899</th>\n",
       "      <th>ENSG00000198938</th>\n",
       "      <th>ENSG00000198840</th>\n",
       "      <th>ENSG00000212907</th>\n",
       "      <th>ENSG00000198886</th>\n",
       "      <th>ENSG00000198786</th>\n",
       "      <th>ENSG00000198695</th>\n",
       "      <th>ENSG00000198727</th>\n",
       "      <th>ENSG00000274847</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGATTCGCT.20.4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCATCCG.21.6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCTATTG.18.6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCTAGATA.25.10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>118</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGCAGGTTTAC.13.2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCAAACTGC.8.11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCCTCCACA.13.2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCCTGTAAG.32.11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTGGTGA.8.11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62202 rows × 22500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ensemble_gene_name      ENSG00000163463  ENSG00000163462  ENSG00000185499  \\\n",
       "AAACCCAAGAAATCCA.12.9                 0                0                0   \n",
       "AAACCCAAGATTCGCT.20.4                 0                0                0   \n",
       "AAACCCAAGCCATCCG.21.6                 0                0                0   \n",
       "AAACCCAAGCCTATTG.18.6                 0                0                0   \n",
       "AAACCCAAGCTAGATA.25.10                0                1                0   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGCAGGTTTAC.13.2                 0                0                0   \n",
       "TTTGTTGTCAAACTGC.8.11                 0                0                0   \n",
       "TTTGTTGTCCTCCACA.13.2                 0                0                0   \n",
       "TTTGTTGTCCTGTAAG.32.11                0                0                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                0                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000169231  ENSG00000261905  ENSG00000263290  \\\n",
       "AAACCCAAGAAATCCA.12.9                 0                0                0   \n",
       "AAACCCAAGATTCGCT.20.4                 0                0                0   \n",
       "AAACCCAAGCCATCCG.21.6                 0                0                0   \n",
       "AAACCCAAGCCTATTG.18.6                 0                0                0   \n",
       "AAACCCAAGCTAGATA.25.10                0                0                1   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGCAGGTTTAC.13.2                 0                0                0   \n",
       "TTTGTTGTCAAACTGC.8.11                 0                0                0   \n",
       "TTTGTTGTCCTCCACA.13.2                 0                0                1   \n",
       "TTTGTTGTCCTGTAAG.32.11                0                0                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                0                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000261893  ENSG00000263324  ENSG00000262785  \\\n",
       "AAACCCAAGAAATCCA.12.9                 0                2                0   \n",
       "AAACCCAAGATTCGCT.20.4                 0                1                0   \n",
       "AAACCCAAGCCATCCG.21.6                 0                0                0   \n",
       "AAACCCAAGCCTATTG.18.6                 0                0                0   \n",
       "AAACCCAAGCTAGATA.25.10                0                0                0   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGCAGGTTTAC.13.2                 1                0                0   \n",
       "TTTGTTGTCAAACTGC.8.11                 0                0                0   \n",
       "TTTGTTGTCCTCCACA.13.2                 0                1                0   \n",
       "TTTGTTGTCCTGTAAG.32.11                0                1                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                0                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000160752  ...  ENSG00000228253  \\\n",
       "AAACCCAAGAAATCCA.12.9                 1  ...                0   \n",
       "AAACCCAAGATTCGCT.20.4                 1  ...                0   \n",
       "AAACCCAAGCCATCCG.21.6                 0  ...                0   \n",
       "AAACCCAAGCCTATTG.18.6                 0  ...                0   \n",
       "AAACCCAAGCTAGATA.25.10                0  ...                1   \n",
       "...                                 ...  ...              ...   \n",
       "TTTGTTGCAGGTTTAC.13.2                 3  ...                1   \n",
       "TTTGTTGTCAAACTGC.8.11                 0  ...                0   \n",
       "TTTGTTGTCCTCCACA.13.2                 1  ...                1   \n",
       "TTTGTTGTCCTGTAAG.32.11                0  ...                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0  ...                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000198899  ENSG00000198938  ENSG00000198840  \\\n",
       "AAACCCAAGAAATCCA.12.9                 3                2                1   \n",
       "AAACCCAAGATTCGCT.20.4                40               34                6   \n",
       "AAACCCAAGCCATCCG.21.6                 4                5                1   \n",
       "AAACCCAAGCCTATTG.18.6                23               40               11   \n",
       "AAACCCAAGCTAGATA.25.10               90              118               43   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGCAGGTTTAC.13.2                79               75               20   \n",
       "TTTGTTGTCAAACTGC.8.11                37               63               12   \n",
       "TTTGTTGTCCTCCACA.13.2                36               44               22   \n",
       "TTTGTTGTCCTGTAAG.32.11                4                9                1   \n",
       "TTTGTTGTCTTGGTGA.8.11                 1                1                1   \n",
       "\n",
       "ensemble_gene_name      ENSG00000212907  ENSG00000198886  ENSG00000198786  \\\n",
       "AAACCCAAGAAATCCA.12.9                 0                0                3   \n",
       "AAACCCAAGATTCGCT.20.4                 0               12                4   \n",
       "AAACCCAAGCCATCCG.21.6                 0                3                0   \n",
       "AAACCCAAGCCTATTG.18.6                 2               21                2   \n",
       "AAACCCAAGCTAGATA.25.10                0               32               10   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGCAGGTTTAC.13.2                 1               25                5   \n",
       "TTTGTTGTCAAACTGC.8.11                 2               24                5   \n",
       "TTTGTTGTCCTCCACA.13.2                 0               19                6   \n",
       "TTTGTTGTCCTGTAAG.32.11                0                4                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                3                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000198695  ENSG00000198727  ENSG00000274847  \n",
       "AAACCCAAGAAATCCA.12.9                 0                4                0  \n",
       "AAACCCAAGATTCGCT.20.4                 0               14                0  \n",
       "AAACCCAAGCCATCCG.21.6                 0                1                0  \n",
       "AAACCCAAGCCTATTG.18.6                 0               18                0  \n",
       "AAACCCAAGCTAGATA.25.10                0               60                0  \n",
       "...                                 ...              ...              ...  \n",
       "TTTGTTGCAGGTTTAC.13.2                 0               38                0  \n",
       "TTTGTTGTCAAACTGC.8.11                 0               17                0  \n",
       "TTTGTTGTCCTCCACA.13.2                 0               15                0  \n",
       "TTTGTTGTCCTGTAAG.32.11                0                3                0  \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                1                0  \n",
       "\n",
       "[62202 rows x 22500 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_clinical_pathological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea870b8a-501f-4a34-946c-84dc6507522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>individualID</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "      <th>train_test_clinical_and_pathological</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3857147</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGAACGCGT.6.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>2651</td>\n",
       "      <td>1533</td>\n",
       "      <td>8.185590</td>\n",
       "      <td>0.452659</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-90639</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7090624</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGAACTGAT.10.12</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>6550</td>\n",
       "      <td>2764</td>\n",
       "      <td>4.809160</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.901814</td>\n",
       "      <td>Inh LAMP5 RELN</td>\n",
       "      <td>ROSMAP-57958</td>\n",
       "      <td>yes</td>\n",
       "      <td>R2347173</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGAAGCGGG.31.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11658</td>\n",
       "      <td>4377</td>\n",
       "      <td>5.738549</td>\n",
       "      <td>0.394579</td>\n",
       "      <td>0.895381</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-40761</td>\n",
       "      <td>yes</td>\n",
       "      <td>R1287407</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGAATCCCT.14.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15297</td>\n",
       "      <td>4688</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>Inh VIP CLSTN2</td>\n",
       "      <td>ROSMAP-68841</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3757880</td>\n",
       "      <td>NCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329694</th>\n",
       "      <td>TTTGTTGTCTTAGCAG.7.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9309</td>\n",
       "      <td>3459</td>\n",
       "      <td>2.062520</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.891670</td>\n",
       "      <td>Inh VIP TSHZ2</td>\n",
       "      <td>ROSMAP-77886</td>\n",
       "      <td>no</td>\n",
       "      <td>R2554598</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329695</th>\n",
       "      <td>TTTGTTGTCTTCCCGA.28.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>R6292415</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329696</th>\n",
       "      <td>TTTGTTGTCTTCGACC.3.13</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>16770</td>\n",
       "      <td>5431</td>\n",
       "      <td>2.098986</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-53472</td>\n",
       "      <td>yes</td>\n",
       "      <td>R3863249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329697</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>R5221394</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329698</th>\n",
       "      <td>TTTGTTGTCTTTGCAT.22.8</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>15282</td>\n",
       "      <td>4330</td>\n",
       "      <td>3.291454</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>0.869104</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-22203</td>\n",
       "      <td>yes</td>\n",
       "      <td>R7583108</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329699 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "1         AAACCCAAGAACGCGT.6.6     ROSMAP        2651          1533   \n",
       "2       AAACCCAAGAACTGAT.10.12     ROSMAP        6550          2764   \n",
       "3        AAACCCAAGAAGCGGG.31.8     ROSMAP       11658          4377   \n",
       "4        AAACCCAAGAATCCCT.14.8     ROSMAP       15297          4688   \n",
       "...                        ...        ...         ...           ...   \n",
       "329694    TTTGTTGTCTTAGCAG.7.9     ROSMAP        9309          3459   \n",
       "329695   TTTGTTGTCTTCCCGA.28.6     ROSMAP       22844          5507   \n",
       "329696   TTTGTTGTCTTCGACC.3.13     ROSMAP       16770          5431   \n",
       "329697   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "329698   TTTGTTGTCTTTGCAT.22.8     ROSMAP       15282          4330   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "1         8.185590    0.452659          0.930517         Inh L3-5 SST MAFB   \n",
       "2         4.809160    0.274809          0.901814            Inh LAMP5 RELN   \n",
       "3         5.738549    0.394579          0.895381            Inh VIP CLSTN2   \n",
       "4         0.921749    0.307250          0.877260            Inh VIP CLSTN2   \n",
       "...            ...         ...               ...                       ...   \n",
       "329694    2.062520    0.225588          0.891670             Inh VIP TSHZ2   \n",
       "329695    0.153213    0.358956          0.858250           Inh PVALB SULF1   \n",
       "329696    2.098986    0.679785          0.884093             Inh CUX2 MSR1   \n",
       "329697    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "329698    3.291454    0.261746          0.869104            Inh PVALB HTR4   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD individualID  \\\n",
       "0       ROSMAP-65967                        yes     R3857147   \n",
       "1       ROSMAP-90639                        yes     R7090624   \n",
       "2       ROSMAP-57958                        yes     R2347173   \n",
       "3       ROSMAP-40761                        yes     R1287407   \n",
       "4       ROSMAP-68841                        yes     R3757880   \n",
       "...              ...                        ...          ...   \n",
       "329694  ROSMAP-77886                         no     R2554598   \n",
       "329695  ROSMAP-38931                         no     R6292415   \n",
       "329696  ROSMAP-53472                        yes     R3863249   \n",
       "329697  ROSMAP-44788                         no     R5221394   \n",
       "329698  ROSMAP-22203                        yes     R7583108   \n",
       "\n",
       "       clinical_diagnosis pathological_diagnosis clinical_pathological_AD  \\\n",
       "0                      AD                     AD          AD_with_Plaques   \n",
       "1                     NCI                     AD                    False   \n",
       "2                     NCI                     AD                    False   \n",
       "3                   False                     AD                    False   \n",
       "4                     NCI                     AD                    False   \n",
       "...                   ...                    ...                      ...   \n",
       "329694                NCI                  False                    False   \n",
       "329695                NCI                  No AD      NCI_with_No_Plaques   \n",
       "329696              False                  False                    False   \n",
       "329697                NCI                  No AD      NCI_with_No_Plaques   \n",
       "329698                 AD                     AD          AD_with_Plaques   \n",
       "\n",
       "       train_test_clinical_and_pathological  \n",
       "0                                     train  \n",
       "1                                       NaN  \n",
       "2                                       NaN  \n",
       "3                                       NaN  \n",
       "4                                       NaN  \n",
       "...                                     ...  \n",
       "329694                                  NaN  \n",
       "329695                                train  \n",
       "329696                                  NaN  \n",
       "329697                                 test  \n",
       "329698                                train  \n",
       "\n",
       "[329699 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata = pd.read_csv('../../preprocessed_data/inhibitory_neuron/metadata_inhibitory_neurons.csv')\n",
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3876ccd-66c2-4272-ac19-5c7f97411bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>...</th>\n",
       "      <th>ceradsc_x</th>\n",
       "      <th>braaksc_x</th>\n",
       "      <th>pmi_df2_y</th>\n",
       "      <th>age_death_y</th>\n",
       "      <th>msex_y</th>\n",
       "      <th>educ_y</th>\n",
       "      <th>age_first_ad_dx_y</th>\n",
       "      <th>cogdx_y</th>\n",
       "      <th>ceradsc_y</th>\n",
       "      <th>braaksc_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>88.032854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGATTCGCT.20.4</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22353</td>\n",
       "      <td>5550</td>\n",
       "      <td>0.827629</td>\n",
       "      <td>0.317631</td>\n",
       "      <td>0.860888</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-57180</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>86.110883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGCCATCCG.21.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>1091</td>\n",
       "      <td>782</td>\n",
       "      <td>2.749771</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.952394</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-10132</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.00342231348391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGCCTATTG.18.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11199</td>\n",
       "      <td>4095</td>\n",
       "      <td>1.660863</td>\n",
       "      <td>0.517903</td>\n",
       "      <td>0.892095</td>\n",
       "      <td>Inh PTPRK FAM19A1</td>\n",
       "      <td>ROSMAP-37253</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>87.668720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.698836413415464</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGCTAGATA.25.10</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>36185</td>\n",
       "      <td>6967</td>\n",
       "      <td>1.608401</td>\n",
       "      <td>0.290175</td>\n",
       "      <td>0.843045</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-14589</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>86.984257357973988</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130050</th>\n",
       "      <td>TTTGTTGTCTTCCCGA.28.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22844</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>Inh PVALB SULF1</td>\n",
       "      <td>ROSMAP-38931</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130051</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130052</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130053</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130054</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130055 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "1        AAACCCAAGATTCGCT.20.4     ROSMAP       22353          5550   \n",
       "2        AAACCCAAGCCATCCG.21.6     ROSMAP        1091           782   \n",
       "3        AAACCCAAGCCTATTG.18.6     ROSMAP       11199          4095   \n",
       "4       AAACCCAAGCTAGATA.25.10     ROSMAP       36185          6967   \n",
       "...                        ...        ...         ...           ...   \n",
       "130050   TTTGTTGTCTTCCCGA.28.6     ROSMAP       22844          5507   \n",
       "130051   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "130052   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "130053   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "130054   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "1         0.827629    0.317631          0.860888            Inh PVALB HTR4   \n",
       "2         2.749771    0.641613          0.952394             Inh CUX2 MSR1   \n",
       "3         1.660863    0.517903          0.892095         Inh PTPRK FAM19A1   \n",
       "4         1.608401    0.290175          0.843045            Inh PVALB HTR4   \n",
       "...            ...         ...               ...                       ...   \n",
       "130050    0.153213    0.358956          0.858250           Inh PVALB SULF1   \n",
       "130051    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "130052    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "130053    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "130054    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD  ... ceradsc_x braaksc_x  \\\n",
       "0       ROSMAP-65967                        yes  ...       1.0       5.0   \n",
       "1       ROSMAP-57180                         no  ...       4.0       1.0   \n",
       "2       ROSMAP-10132                        yes  ...       1.0       5.0   \n",
       "3       ROSMAP-37253                        yes  ...       1.0       5.0   \n",
       "4       ROSMAP-14589                        yes  ...       1.0       4.0   \n",
       "...              ...                        ...  ...       ...       ...   \n",
       "130050  ROSMAP-38931                         no  ...       4.0       3.0   \n",
       "130051  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "130052  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "130053  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "130054  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "\n",
       "        pmi_df2_y age_death_y msex_y  educ_y   age_first_ad_dx_y  cogdx_y  \\\n",
       "0        4.416667   88.032854    0.0    18.0                 NaN      4.0   \n",
       "1        3.616667   86.110883    0.0    17.0                 NaN      1.0   \n",
       "2        6.866667   90.000000    0.0     7.0   87.00342231348391      4.0   \n",
       "3       17.416667   87.668720    0.0    20.0  75.698836413415464      4.0   \n",
       "4        5.000000   90.000000    0.0    11.0  86.984257357973988      4.0   \n",
       "...           ...         ...    ...     ...                 ...      ...   \n",
       "130050   6.250000   90.000000    0.0    12.0                 NaN      1.0   \n",
       "130051   6.166667   87.868583    1.0    18.0  85.489390828199859      1.0   \n",
       "130052   6.166667   87.868583    1.0    18.0  85.489390828199859      1.0   \n",
       "130053   6.166667   87.868583    1.0    18.0  85.489390828199859      1.0   \n",
       "130054   6.166667   87.868583    1.0    18.0  85.489390828199859      1.0   \n",
       "\n",
       "        ceradsc_y braaksc_y  \n",
       "0             1.0       5.0  \n",
       "1             4.0       1.0  \n",
       "2             1.0       5.0  \n",
       "3             1.0       5.0  \n",
       "4             1.0       4.0  \n",
       "...           ...       ...  \n",
       "130050        4.0       3.0  \n",
       "130051        4.0       1.0  \n",
       "130052        4.0       1.0  \n",
       "130053        4.0       1.0  \n",
       "130054        4.0       1.0  \n",
       "\n",
       "[130055 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata = single_cell_metadata[single_cell_metadata.cell_id.isin(merged_data_clinical_pathological.index.tolist())]\n",
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75e82842-9d1b-4b7c-975e-04b544487566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individualID</th>\n",
       "      <th>individualIdSource</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>subject</th>\n",
       "      <th>projid</th>\n",
       "      <th>Study</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>...</th>\n",
       "      <th>age_death</th>\n",
       "      <th>cts_mmse30_first_ad_dx</th>\n",
       "      <th>cts_mmse30_lv</th>\n",
       "      <th>braaksc</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>dcfdx_lv</th>\n",
       "      <th>clinical_diagnosis</th>\n",
       "      <th>pathological_diagnosis</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2626559</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>ROSMAP-45310</td>\n",
       "      <td>1211411</td>\n",
       "      <td>ROS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.549624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>No AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R9936070</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>ROSMAP-34387</td>\n",
       "      <td>2899847</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.450376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R2367199</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>ROSMAP-69520</td>\n",
       "      <td>3713990</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.928816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R9891381</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>ROSMAP-53306</td>\n",
       "      <td>3889845</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R9033345</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>ROSMAP-79585</td>\n",
       "      <td>6107196</td>\n",
       "      <td>MAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>R9738414</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>ROSMAP-90149</td>\n",
       "      <td>20976799</td>\n",
       "      <td>ROS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>No AD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>R7737688</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69866926</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.104038</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>R7844746</td>\n",
       "      <td>Rush</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29286432</td>\n",
       "      <td>ROS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>R6692433</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48331728</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.715948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI</td>\n",
       "      <td>No AD</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>R5309342</td>\n",
       "      <td>Rush</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.733333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10371937</td>\n",
       "      <td>MAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.032170</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    individualID individualIdSource     sex  ethnicity   pmi_df2  \\\n",
       "0       R2626559               Rush    male        NaN  6.500000   \n",
       "1       R9936070               Rush    male        NaN  7.016667   \n",
       "2       R2367199               Rush    male        NaN  4.333333   \n",
       "3       R9891381               Rush  female        NaN  6.916667   \n",
       "4       R9033345               Rush    male        NaN  4.166667   \n",
       "..           ...                ...     ...        ...       ...   \n",
       "509     R9738414               Rush  female        NaN  9.250000   \n",
       "510     R7737688               Rush  female        NaN  7.000000   \n",
       "511     R7844746               Rush    male        NaN  0.866667   \n",
       "512     R6692433               Rush  female        NaN  6.583333   \n",
       "513     R5309342               Rush  female        NaN  7.733333   \n",
       "\n",
       "          subject    projid Study  msex  educ  ...  age_death  \\\n",
       "0    ROSMAP-45310   1211411   ROS   1.0  12.0  ...  85.549624   \n",
       "1    ROSMAP-34387   2899847   MAP   1.0  14.0  ...  74.450376   \n",
       "2    ROSMAP-69520   3713990   MAP   1.0  12.0  ...  87.928816   \n",
       "3    ROSMAP-53306   3889845   MAP   0.0  13.0  ...  90.000000   \n",
       "4    ROSMAP-79585   6107196   MAP   1.0  15.0  ...  90.000000   \n",
       "..            ...       ...   ...   ...   ...  ...        ...   \n",
       "509  ROSMAP-90149  20976799   ROS   0.0  18.0  ...  90.000000   \n",
       "510           NaN  69866926   MAP   0.0  13.0  ...  84.104038   \n",
       "511           NaN  29286432   ROS   1.0  24.0  ...  90.000000   \n",
       "512           NaN  48331728   MAP   0.0  14.0  ...  82.715948   \n",
       "513           NaN  10371937   MAP   0.0  18.0  ...  81.032170   \n",
       "\n",
       "     cts_mmse30_first_ad_dx cts_mmse30_lv braaksc  ceradsc  cogdx  dcfdx_lv  \\\n",
       "0                       NaN          24.0     1.0      4.0    4.0       4.0   \n",
       "1                       NaN          27.0     2.0      2.0    3.0       3.0   \n",
       "2                       NaN          30.0     4.0      2.0    1.0       1.0   \n",
       "3                       NaN          22.0     2.0      1.0    2.0       2.0   \n",
       "4                       NaN          22.0     5.0      1.0    4.0       4.0   \n",
       "..                      ...           ...     ...      ...    ...       ...   \n",
       "509                     NaN          19.0     2.0      4.0    2.0       2.0   \n",
       "510                    20.0           3.0     6.0      1.0    4.0       4.0   \n",
       "511                     NaN          29.0     5.0      2.0    2.0       2.0   \n",
       "512                     NaN          27.0     2.0      4.0    1.0       1.0   \n",
       "513                    25.0          25.0     5.0      1.0    4.0       4.0   \n",
       "\n",
       "     clinical_diagnosis  pathological_diagnosis  clinical_pathological_AD  \n",
       "0                    AD                   No AD                     False  \n",
       "1                 False                   False                     False  \n",
       "2                   NCI                   False                     False  \n",
       "3                 False                      AD                     False  \n",
       "4                    AD                      AD           AD_with_Plaques  \n",
       "..                  ...                     ...                       ...  \n",
       "509               False                   No AD                     False  \n",
       "510                  AD                      AD           AD_with_Plaques  \n",
       "511               False                   False                     False  \n",
       "512                 NCI                   No AD       NCI_with_No_Plaques  \n",
       "513                  AD                      AD           AD_with_Plaques  \n",
       "\n",
       "[514 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data = pd.read_csv('/12tb_dsk1/danish/preprocessed_data/clinical/clinical_single_cell.csv')\n",
    "clinical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e5ad05f-0e7b-4d5f-abfa-29e9c4433f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['individualID', 'individualIdSource', 'sex', 'ethnicity', 'pmi_df2',\n",
       "       'subject', 'projid', 'Study', 'msex', 'educ', 'spanish',\n",
       "       'apoe_genotype', 'age_at_visit_max', 'age_first_ad_dx', 'age_death',\n",
       "       'cts_mmse30_first_ad_dx', 'cts_mmse30_lv', 'braaksc', 'ceradsc',\n",
       "       'cogdx', 'dcfdx_lv', 'clinical_diagnosis', 'pathological_diagnosis',\n",
       "       'clinical_pathological_AD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14e38da6-16cb-452b-a7bf-36308748d122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_first_ad_dx\n",
       "90+                   40\n",
       "77.097878165639969     3\n",
       "79.991786447638603     2\n",
       "79.89596167008898      2\n",
       "82.35455167693361      2\n",
       "                      ..\n",
       "81.51403148528405      1\n",
       "83.036276522929498     1\n",
       "73.051334702258728     1\n",
       "82.472279260780283     1\n",
       "85.62354551676934      1\n",
       "Name: count, Length: 107, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data.age_first_ad_dx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31844df0-1834-4788-b6a9-684efe0f9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_metadata = pd.merge(single_cell_metadata,clinical_data[['subject','pmi_df2','age_death','msex','educ','age_first_ad_dx','cogdx','ceradsc','braaksc','apoe_genotype']], on = 'subject', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "593a0d5f-d276-4ee4-a9aa-5b524903299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>...</th>\n",
       "      <th>ceradsc_y</th>\n",
       "      <th>braaksc_y</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>age_death</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>age_first_ad_dx</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>braaksc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>88.032854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGATTCGCT.20.4</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22353</td>\n",
       "      <td>5550</td>\n",
       "      <td>0.827629</td>\n",
       "      <td>0.317631</td>\n",
       "      <td>0.860888</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-57180</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>86.110883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGCCATCCG.21.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>1091</td>\n",
       "      <td>782</td>\n",
       "      <td>2.749771</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.952394</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-10132</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.00342231348391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGCCTATTG.18.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11199</td>\n",
       "      <td>4095</td>\n",
       "      <td>1.660863</td>\n",
       "      <td>0.517903</td>\n",
       "      <td>0.892095</td>\n",
       "      <td>Inh PTPRK FAM19A1</td>\n",
       "      <td>ROSMAP-37253</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>87.668720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.698836413415464</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGCTAGATA.25.10</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>36185</td>\n",
       "      <td>6967</td>\n",
       "      <td>1.608401</td>\n",
       "      <td>0.290175</td>\n",
       "      <td>0.843045</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-14589</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>86.984257357973988</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221234</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221235</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221236</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221237</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221238</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221239 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "1        AAACCCAAGATTCGCT.20.4     ROSMAP       22353          5550   \n",
       "2        AAACCCAAGCCATCCG.21.6     ROSMAP        1091           782   \n",
       "3        AAACCCAAGCCTATTG.18.6     ROSMAP       11199          4095   \n",
       "4       AAACCCAAGCTAGATA.25.10     ROSMAP       36185          6967   \n",
       "...                        ...        ...         ...           ...   \n",
       "221234   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "221235   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "221236   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "221237   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "221238   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "1         0.827629    0.317631          0.860888            Inh PVALB HTR4   \n",
       "2         2.749771    0.641613          0.952394             Inh CUX2 MSR1   \n",
       "3         1.660863    0.517903          0.892095         Inh PTPRK FAM19A1   \n",
       "4         1.608401    0.290175          0.843045            Inh PVALB HTR4   \n",
       "...            ...         ...               ...                       ...   \n",
       "221234    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "221235    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "221236    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "221237    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "221238    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD  ... ceradsc_y braaksc_y  \\\n",
       "0       ROSMAP-65967                        yes  ...       1.0       5.0   \n",
       "1       ROSMAP-57180                         no  ...       4.0       1.0   \n",
       "2       ROSMAP-10132                        yes  ...       1.0       5.0   \n",
       "3       ROSMAP-37253                        yes  ...       1.0       5.0   \n",
       "4       ROSMAP-14589                        yes  ...       1.0       4.0   \n",
       "...              ...                        ...  ...       ...       ...   \n",
       "221234  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "221235  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "221236  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "221237  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "221238  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "\n",
       "          pmi_df2  age_death msex  educ     age_first_ad_dx  cogdx  ceradsc  \\\n",
       "0        4.416667  88.032854  0.0  18.0                 NaN    4.0      1.0   \n",
       "1        3.616667  86.110883  0.0  17.0                 NaN    1.0      4.0   \n",
       "2        6.866667  90.000000  0.0   7.0   87.00342231348391    4.0      1.0   \n",
       "3       17.416667  87.668720  0.0  20.0  75.698836413415464    4.0      1.0   \n",
       "4        5.000000  90.000000  0.0  11.0  86.984257357973988    4.0      1.0   \n",
       "...           ...        ...  ...   ...                 ...    ...      ...   \n",
       "221234   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "221235   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "221236   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "221237   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "221238   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "\n",
       "       braaksc  \n",
       "0          5.0  \n",
       "1          1.0  \n",
       "2          5.0  \n",
       "3          5.0  \n",
       "4          4.0  \n",
       "...        ...  \n",
       "221234     1.0  \n",
       "221235     1.0  \n",
       "221236     1.0  \n",
       "221237     1.0  \n",
       "221238     1.0  \n",
       "\n",
       "[221239 rows x 39 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata = single_cell_metadata.drop(columns=['apoe_genotype'])\n",
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fe0ee86-f93b-47a4-a543-cb6c90546c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.rb</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>cell_type_high_resolution</th>\n",
       "      <th>subject</th>\n",
       "      <th>Pathologic_diagnosis_of_AD</th>\n",
       "      <th>...</th>\n",
       "      <th>ceradsc_y</th>\n",
       "      <th>braaksc_y</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>age_death</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>age_first_ad_dx</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>braaksc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>13490</td>\n",
       "      <td>4276</td>\n",
       "      <td>0.237213</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.879183</td>\n",
       "      <td>Inh L3-5 SST MAFB</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>88.032854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGATTCGCT.20.4</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>22353</td>\n",
       "      <td>5550</td>\n",
       "      <td>0.827629</td>\n",
       "      <td>0.317631</td>\n",
       "      <td>0.860888</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-57180</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>86.110883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGCCATCCG.21.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>1091</td>\n",
       "      <td>782</td>\n",
       "      <td>2.749771</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.952394</td>\n",
       "      <td>Inh CUX2 MSR1</td>\n",
       "      <td>ROSMAP-10132</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.00342231348391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGCCTATTG.18.6</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>11199</td>\n",
       "      <td>4095</td>\n",
       "      <td>1.660863</td>\n",
       "      <td>0.517903</td>\n",
       "      <td>0.892095</td>\n",
       "      <td>Inh PTPRK FAM19A1</td>\n",
       "      <td>ROSMAP-37253</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>87.668720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.698836413415464</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGCTAGATA.25.10</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>36185</td>\n",
       "      <td>6967</td>\n",
       "      <td>1.608401</td>\n",
       "      <td>0.290175</td>\n",
       "      <td>0.843045</td>\n",
       "      <td>Inh PVALB HTR4</td>\n",
       "      <td>ROSMAP-14589</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>86.984257357973988</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221234</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221235</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221236</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221237</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221238</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>ROSMAP</td>\n",
       "      <td>9475</td>\n",
       "      <td>3447</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>0.889569</td>\n",
       "      <td>Inh VIP ABI3BP</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221239 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cell_id orig.ident  nCount_RNA  nFeature_RNA  \\\n",
       "0        AAACCCAAGAAATCCA.12.9     ROSMAP       13490          4276   \n",
       "1        AAACCCAAGATTCGCT.20.4     ROSMAP       22353          5550   \n",
       "2        AAACCCAAGCCATCCG.21.6     ROSMAP        1091           782   \n",
       "3        AAACCCAAGCCTATTG.18.6     ROSMAP       11199          4095   \n",
       "4       AAACCCAAGCTAGATA.25.10     ROSMAP       36185          6967   \n",
       "...                        ...        ...         ...           ...   \n",
       "221234   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "221235   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "221236   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "221237   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "221238   TTTGTTGTCTTGGTGA.8.11     ROSMAP        9475          3447   \n",
       "\n",
       "        percent.mt  percent.rb  log10GenesPerUMI cell_type_high_resolution  \\\n",
       "0         0.237213    0.289103          0.879183         Inh L3-5 SST MAFB   \n",
       "1         0.827629    0.317631          0.860888            Inh PVALB HTR4   \n",
       "2         2.749771    0.641613          0.952394             Inh CUX2 MSR1   \n",
       "3         1.660863    0.517903          0.892095         Inh PTPRK FAM19A1   \n",
       "4         1.608401    0.290175          0.843045            Inh PVALB HTR4   \n",
       "...            ...         ...               ...                       ...   \n",
       "221234    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "221235    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "221236    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "221237    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "221238    0.147757    0.179420          0.889569            Inh VIP ABI3BP   \n",
       "\n",
       "             subject Pathologic_diagnosis_of_AD  ... ceradsc_y braaksc_y  \\\n",
       "0       ROSMAP-65967                        yes  ...       1.0       5.0   \n",
       "1       ROSMAP-57180                         no  ...       4.0       1.0   \n",
       "2       ROSMAP-10132                        yes  ...       1.0       5.0   \n",
       "3       ROSMAP-37253                        yes  ...       1.0       5.0   \n",
       "4       ROSMAP-14589                        yes  ...       1.0       4.0   \n",
       "...              ...                        ...  ...       ...       ...   \n",
       "221234  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "221235  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "221236  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "221237  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "221238  ROSMAP-44788                         no  ...       4.0       1.0   \n",
       "\n",
       "          pmi_df2  age_death msex  educ     age_first_ad_dx  cogdx  ceradsc  \\\n",
       "0        4.416667  88.032854  0.0  18.0                 NaN    4.0      1.0   \n",
       "1        3.616667  86.110883  0.0  17.0                 NaN    1.0      4.0   \n",
       "2        6.866667  90.000000  0.0   7.0   87.00342231348391    4.0      1.0   \n",
       "3       17.416667  87.668720  0.0  20.0  75.698836413415464    4.0      1.0   \n",
       "4        5.000000  90.000000  0.0  11.0  86.984257357973988    4.0      1.0   \n",
       "...           ...        ...  ...   ...                 ...    ...      ...   \n",
       "221234   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "221235   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "221236   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "221237   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "221238   6.166667  87.868583  1.0  18.0  85.489390828199859    1.0      4.0   \n",
       "\n",
       "       braaksc  \n",
       "0          5.0  \n",
       "1          1.0  \n",
       "2          5.0  \n",
       "3          5.0  \n",
       "4          4.0  \n",
       "...        ...  \n",
       "221234     1.0  \n",
       "221235     1.0  \n",
       "221236     1.0  \n",
       "221237     1.0  \n",
       "221238     1.0  \n",
       "\n",
       "[221239 rows x 39 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell_metadata = single_cell_metadata[~single_cell_metadata.pmi_df2.isna()]\n",
    "single_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6763cf50-8719-484e-8403-dba192329dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>subject</th>\n",
       "      <th>age_death</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>age_first_ad_dx</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>braaksc</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>88.032854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCCAAGATTCGCT.20.4</td>\n",
       "      <td>AAACCCAAGATTCGCT.20.4</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>ROSMAP-57180</td>\n",
       "      <td>86.110883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCCAAGCCATCCG.21.6</td>\n",
       "      <td>AAACCCAAGCCATCCG.21.6</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>ROSMAP-10132</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.00342231348391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCCAAGCCTATTG.18.6</td>\n",
       "      <td>AAACCCAAGCCTATTG.18.6</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>ROSMAP-37253</td>\n",
       "      <td>87.668720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.698836413415464</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCCAAGCTAGATA.25.10</td>\n",
       "      <td>AAACCCAAGCTAGATA.25.10</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>ROSMAP-14589</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>86.984257357973988</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221234</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221235</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221236</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221237</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221238</th>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>TTTGTTGTCTTGGTGA.8.11</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>ROSMAP-44788</td>\n",
       "      <td>87.868583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.489390828199859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221239 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         index                 cell_id    pmi_df2  \\\n",
       "0        AAACCCAAGAAATCCA.12.9   AAACCCAAGAAATCCA.12.9   4.416667   \n",
       "1        AAACCCAAGATTCGCT.20.4   AAACCCAAGATTCGCT.20.4   3.616667   \n",
       "2        AAACCCAAGCCATCCG.21.6   AAACCCAAGCCATCCG.21.6   6.866667   \n",
       "3        AAACCCAAGCCTATTG.18.6   AAACCCAAGCCTATTG.18.6  17.416667   \n",
       "4       AAACCCAAGCTAGATA.25.10  AAACCCAAGCTAGATA.25.10   5.000000   \n",
       "...                        ...                     ...        ...   \n",
       "221234   TTTGTTGTCTTGGTGA.8.11   TTTGTTGTCTTGGTGA.8.11   6.166667   \n",
       "221235   TTTGTTGTCTTGGTGA.8.11   TTTGTTGTCTTGGTGA.8.11   6.166667   \n",
       "221236   TTTGTTGTCTTGGTGA.8.11   TTTGTTGTCTTGGTGA.8.11   6.166667   \n",
       "221237   TTTGTTGTCTTGGTGA.8.11   TTTGTTGTCTTGGTGA.8.11   6.166667   \n",
       "221238   TTTGTTGTCTTGGTGA.8.11   TTTGTTGTCTTGGTGA.8.11   6.166667   \n",
       "\n",
       "             subject  age_death  msex  educ     age_first_ad_dx  cogdx  \\\n",
       "0       ROSMAP-65967  88.032854   0.0  18.0                 NaN    4.0   \n",
       "1       ROSMAP-57180  86.110883   0.0  17.0                 NaN    1.0   \n",
       "2       ROSMAP-10132  90.000000   0.0   7.0   87.00342231348391    4.0   \n",
       "3       ROSMAP-37253  87.668720   0.0  20.0  75.698836413415464    4.0   \n",
       "4       ROSMAP-14589  90.000000   0.0  11.0  86.984257357973988    4.0   \n",
       "...              ...        ...   ...   ...                 ...    ...   \n",
       "221234  ROSMAP-44788  87.868583   1.0  18.0  85.489390828199859    1.0   \n",
       "221235  ROSMAP-44788  87.868583   1.0  18.0  85.489390828199859    1.0   \n",
       "221236  ROSMAP-44788  87.868583   1.0  18.0  85.489390828199859    1.0   \n",
       "221237  ROSMAP-44788  87.868583   1.0  18.0  85.489390828199859    1.0   \n",
       "221238  ROSMAP-44788  87.868583   1.0  18.0  85.489390828199859    1.0   \n",
       "\n",
       "        ceradsc  braaksc clinical_pathological_AD  \n",
       "0           1.0      5.0          AD_with_Plaques  \n",
       "1           4.0      1.0      NCI_with_No_Plaques  \n",
       "2           1.0      5.0          AD_with_Plaques  \n",
       "3           1.0      5.0          AD_with_Plaques  \n",
       "4           1.0      4.0          AD_with_Plaques  \n",
       "...         ...      ...                      ...  \n",
       "221234      4.0      1.0      NCI_with_No_Plaques  \n",
       "221235      4.0      1.0      NCI_with_No_Plaques  \n",
       "221236      4.0      1.0      NCI_with_No_Plaques  \n",
       "221237      4.0      1.0      NCI_with_No_Plaques  \n",
       "221238      4.0      1.0      NCI_with_No_Plaques  \n",
       "\n",
       "[221239 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates_dataframe = pd.merge(merged_data_clinical_pathological.reset_index()['index'],single_cell_metadata[['cell_id','pmi_df2','subject','age_death','msex','educ','age_first_ad_dx','cogdx','ceradsc','braaksc',\n",
    "                                                                                        'clinical_pathological_AD']] , left_on='index', right_on='cell_id', how='inner')\n",
    "covariates_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aedb9734-b1a8-419c-9338-a14b41c28e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>subject</th>\n",
       "      <th>age_death</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>age_first_ad_dx</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>braaksc</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <td>AAACCCAAGAAATCCA.12.9</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>88.032854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGATTCGCT.20.4</th>\n",
       "      <td>AAACCCAAGATTCGCT.20.4</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>ROSMAP-57180</td>\n",
       "      <td>86.110883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCATCCG.21.6</th>\n",
       "      <td>AAACCCAAGCCATCCG.21.6</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>ROSMAP-10132</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.00342231348391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCTATTG.18.6</th>\n",
       "      <td>AAACCCAAGCCTATTG.18.6</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>ROSMAP-37253</td>\n",
       "      <td>87.668720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.698836413415464</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCTAGATA.25.10</th>\n",
       "      <td>AAACCCAAGCTAGATA.25.10</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>ROSMAP-14589</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>86.984257357973988</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         index    pmi_df2       subject  \\\n",
       "cell_id                                                                   \n",
       "AAACCCAAGAAATCCA.12.9    AAACCCAAGAAATCCA.12.9   4.416667  ROSMAP-65967   \n",
       "AAACCCAAGATTCGCT.20.4    AAACCCAAGATTCGCT.20.4   3.616667  ROSMAP-57180   \n",
       "AAACCCAAGCCATCCG.21.6    AAACCCAAGCCATCCG.21.6   6.866667  ROSMAP-10132   \n",
       "AAACCCAAGCCTATTG.18.6    AAACCCAAGCCTATTG.18.6  17.416667  ROSMAP-37253   \n",
       "AAACCCAAGCTAGATA.25.10  AAACCCAAGCTAGATA.25.10   5.000000  ROSMAP-14589   \n",
       "\n",
       "                        age_death  msex  educ     age_first_ad_dx  cogdx  \\\n",
       "cell_id                                                                    \n",
       "AAACCCAAGAAATCCA.12.9   88.032854   0.0  18.0                 NaN    4.0   \n",
       "AAACCCAAGATTCGCT.20.4   86.110883   0.0  17.0                 NaN    1.0   \n",
       "AAACCCAAGCCATCCG.21.6   90.000000   0.0   7.0   87.00342231348391    4.0   \n",
       "AAACCCAAGCCTATTG.18.6   87.668720   0.0  20.0  75.698836413415464    4.0   \n",
       "AAACCCAAGCTAGATA.25.10  90.000000   0.0  11.0  86.984257357973988    4.0   \n",
       "\n",
       "                        ceradsc  braaksc clinical_pathological_AD  \n",
       "cell_id                                                            \n",
       "AAACCCAAGAAATCCA.12.9       1.0      5.0          AD_with_Plaques  \n",
       "AAACCCAAGATTCGCT.20.4       4.0      1.0      NCI_with_No_Plaques  \n",
       "AAACCCAAGCCATCCG.21.6       1.0      5.0          AD_with_Plaques  \n",
       "AAACCCAAGCCTATTG.18.6       1.0      5.0          AD_with_Plaques  \n",
       "AAACCCAAGCTAGATA.25.10      1.0      4.0          AD_with_Plaques  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates_dataframe = covariates_dataframe.drop_duplicates()\n",
    "covariates_dataframe.set_index('cell_id',inplace = True)\n",
    "covariates_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91766b2a-9892-4cbf-be99-388fc83ec44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_489909/516615762.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  covariates_dataframe.drop(columns=['index'],inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>subject</th>\n",
       "      <th>age_death</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>age_first_ad_dx</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>braaksc</th>\n",
       "      <th>clinical_pathological_AD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <td>4.416667</td>\n",
       "      <td>ROSMAP-65967</td>\n",
       "      <td>88.032854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGATTCGCT.20.4</th>\n",
       "      <td>3.616667</td>\n",
       "      <td>ROSMAP-57180</td>\n",
       "      <td>86.110883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NCI_with_No_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCATCCG.21.6</th>\n",
       "      <td>6.866667</td>\n",
       "      <td>ROSMAP-10132</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.00342231348391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCTATTG.18.6</th>\n",
       "      <td>17.416667</td>\n",
       "      <td>ROSMAP-37253</td>\n",
       "      <td>87.668720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.698836413415464</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCTAGATA.25.10</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>ROSMAP-14589</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>86.984257357973988</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AD_with_Plaques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pmi_df2       subject  age_death  msex  educ  \\\n",
       "cell_id                                                                  \n",
       "AAACCCAAGAAATCCA.12.9    4.416667  ROSMAP-65967  88.032854   0.0  18.0   \n",
       "AAACCCAAGATTCGCT.20.4    3.616667  ROSMAP-57180  86.110883   0.0  17.0   \n",
       "AAACCCAAGCCATCCG.21.6    6.866667  ROSMAP-10132  90.000000   0.0   7.0   \n",
       "AAACCCAAGCCTATTG.18.6   17.416667  ROSMAP-37253  87.668720   0.0  20.0   \n",
       "AAACCCAAGCTAGATA.25.10   5.000000  ROSMAP-14589  90.000000   0.0  11.0   \n",
       "\n",
       "                           age_first_ad_dx  cogdx  ceradsc  braaksc  \\\n",
       "cell_id                                                               \n",
       "AAACCCAAGAAATCCA.12.9                  NaN    4.0      1.0      5.0   \n",
       "AAACCCAAGATTCGCT.20.4                  NaN    1.0      4.0      1.0   \n",
       "AAACCCAAGCCATCCG.21.6    87.00342231348391    4.0      1.0      5.0   \n",
       "AAACCCAAGCCTATTG.18.6   75.698836413415464    4.0      1.0      5.0   \n",
       "AAACCCAAGCTAGATA.25.10  86.984257357973988    4.0      1.0      4.0   \n",
       "\n",
       "                       clinical_pathological_AD  \n",
       "cell_id                                          \n",
       "AAACCCAAGAAATCCA.12.9           AD_with_Plaques  \n",
       "AAACCCAAGATTCGCT.20.4       NCI_with_No_Plaques  \n",
       "AAACCCAAGCCATCCG.21.6           AD_with_Plaques  \n",
       "AAACCCAAGCCTATTG.18.6           AD_with_Plaques  \n",
       "AAACCCAAGCTAGATA.25.10          AD_with_Plaques  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    covariates_dataframe.drop(columns=['index'],inplace = True)\n",
    "except:\n",
    "    print('no such columns, probably I am running this snippet second time')\n",
    "covariates_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e731656-0bca-4a27-8894-e16022bb8be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_death</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>braaksc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <td>88.032854</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGATTCGCT.20.4</th>\n",
       "      <td>86.110883</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCATCCG.21.6</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCTATTG.18.6</th>\n",
       "      <td>87.668720</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCTAGATA.25.10</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCCTGTAAG.32.11</th>\n",
       "      <td>85.790554</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCGAACCTA.5.2</th>\n",
       "      <td>87.200548</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTACACT.27.3</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>11.983333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTCCCGA.28.6</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTGGTGA.8.11</th>\n",
       "      <td>87.868583</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61667 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        age_death    pmi_df2  msex  educ  cogdx  ceradsc  \\\n",
       "cell_id                                                                    \n",
       "AAACCCAAGAAATCCA.12.9   88.032854   4.416667   0.0  18.0    4.0      1.0   \n",
       "AAACCCAAGATTCGCT.20.4   86.110883   3.616667   0.0  17.0    1.0      4.0   \n",
       "AAACCCAAGCCATCCG.21.6   90.000000   6.866667   0.0   7.0    4.0      1.0   \n",
       "AAACCCAAGCCTATTG.18.6   87.668720  17.416667   0.0  20.0    4.0      1.0   \n",
       "AAACCCAAGCTAGATA.25.10  90.000000   5.000000   0.0  11.0    4.0      1.0   \n",
       "...                           ...        ...   ...   ...    ...      ...   \n",
       "TTTGTTGTCCTGTAAG.32.11  85.790554   5.416667   0.0  16.0    1.0      4.0   \n",
       "TTTGTTGTCGAACCTA.5.2    87.200548   4.566667   0.0  18.0    1.0      4.0   \n",
       "TTTGTTGTCTTACACT.27.3   90.000000  11.983333   0.0  12.0    4.0      1.0   \n",
       "TTTGTTGTCTTCCCGA.28.6   90.000000   6.250000   0.0  12.0    1.0      4.0   \n",
       "TTTGTTGTCTTGGTGA.8.11   87.868583   6.166667   1.0  18.0    1.0      4.0   \n",
       "\n",
       "                        braaksc  \n",
       "cell_id                          \n",
       "AAACCCAAGAAATCCA.12.9       5.0  \n",
       "AAACCCAAGATTCGCT.20.4       1.0  \n",
       "AAACCCAAGCCATCCG.21.6       5.0  \n",
       "AAACCCAAGCCTATTG.18.6       5.0  \n",
       "AAACCCAAGCTAGATA.25.10      4.0  \n",
       "...                         ...  \n",
       "TTTGTTGTCCTGTAAG.32.11      4.0  \n",
       "TTTGTTGTCGAACCTA.5.2        1.0  \n",
       "TTTGTTGTCTTACACT.27.3       5.0  \n",
       "TTTGTTGTCTTCCCGA.28.6       3.0  \n",
       "TTTGTTGTCTTGGTGA.8.11       1.0  \n",
       "\n",
       "[61667 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates_dataframe = covariates_dataframe.sort_index()\n",
    "covariates_dataframe = covariates_dataframe[['age_death','pmi_df2','msex','educ','cogdx','ceradsc','braaksc']]\n",
    "covariates_dataframe = covariates_dataframe.astype(float)\n",
    "covariates_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72d5ac79-9807-4dce-8de6-0429fee3655e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ensemble_gene_name</th>\n",
       "      <th>ENSG00000163463</th>\n",
       "      <th>ENSG00000163462</th>\n",
       "      <th>ENSG00000185499</th>\n",
       "      <th>ENSG00000169231</th>\n",
       "      <th>ENSG00000261905</th>\n",
       "      <th>ENSG00000263290</th>\n",
       "      <th>ENSG00000261893</th>\n",
       "      <th>ENSG00000263324</th>\n",
       "      <th>ENSG00000262785</th>\n",
       "      <th>ENSG00000160752</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000228253</th>\n",
       "      <th>ENSG00000198899</th>\n",
       "      <th>ENSG00000198938</th>\n",
       "      <th>ENSG00000198840</th>\n",
       "      <th>ENSG00000212907</th>\n",
       "      <th>ENSG00000198886</th>\n",
       "      <th>ENSG00000198786</th>\n",
       "      <th>ENSG00000198695</th>\n",
       "      <th>ENSG00000198727</th>\n",
       "      <th>ENSG00000274847</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGAAATCCA.12.9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGATTCGCT.20.4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCATCCG.21.6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCCTATTG.18.6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGCTAGATA.25.10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>118</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCCTGTAAG.32.11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCGAACCTA.5.2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTACACT.27.3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTCCCGA.28.6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTTGGTGA.8.11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61667 rows × 22500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ensemble_gene_name      ENSG00000163463  ENSG00000163462  ENSG00000185499  \\\n",
       "AAACCCAAGAAATCCA.12.9                 0                0                0   \n",
       "AAACCCAAGATTCGCT.20.4                 0                0                0   \n",
       "AAACCCAAGCCATCCG.21.6                 0                0                0   \n",
       "AAACCCAAGCCTATTG.18.6                 0                0                0   \n",
       "AAACCCAAGCTAGATA.25.10                0                1                0   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGTCCTGTAAG.32.11                0                0                0   \n",
       "TTTGTTGTCGAACCTA.5.2                  0                0                0   \n",
       "TTTGTTGTCTTACACT.27.3                 0                0                0   \n",
       "TTTGTTGTCTTCCCGA.28.6                 0                1                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                0                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000169231  ENSG00000261905  ENSG00000263290  \\\n",
       "AAACCCAAGAAATCCA.12.9                 0                0                0   \n",
       "AAACCCAAGATTCGCT.20.4                 0                0                0   \n",
       "AAACCCAAGCCATCCG.21.6                 0                0                0   \n",
       "AAACCCAAGCCTATTG.18.6                 0                0                0   \n",
       "AAACCCAAGCTAGATA.25.10                0                0                1   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGTCCTGTAAG.32.11                0                0                0   \n",
       "TTTGTTGTCGAACCTA.5.2                  0                0                0   \n",
       "TTTGTTGTCTTACACT.27.3                 0                0                0   \n",
       "TTTGTTGTCTTCCCGA.28.6                 0                0                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                0                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000261893  ENSG00000263324  ENSG00000262785  \\\n",
       "AAACCCAAGAAATCCA.12.9                 0                2                0   \n",
       "AAACCCAAGATTCGCT.20.4                 0                1                0   \n",
       "AAACCCAAGCCATCCG.21.6                 0                0                0   \n",
       "AAACCCAAGCCTATTG.18.6                 0                0                0   \n",
       "AAACCCAAGCTAGATA.25.10                0                0                0   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGTCCTGTAAG.32.11                0                1                0   \n",
       "TTTGTTGTCGAACCTA.5.2                  0                0                0   \n",
       "TTTGTTGTCTTACACT.27.3                 0                0                0   \n",
       "TTTGTTGTCTTCCCGA.28.6                 0                0                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                0                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000160752  ...  ENSG00000228253  \\\n",
       "AAACCCAAGAAATCCA.12.9                 1  ...                0   \n",
       "AAACCCAAGATTCGCT.20.4                 1  ...                0   \n",
       "AAACCCAAGCCATCCG.21.6                 0  ...                0   \n",
       "AAACCCAAGCCTATTG.18.6                 0  ...                0   \n",
       "AAACCCAAGCTAGATA.25.10                0  ...                1   \n",
       "...                                 ...  ...              ...   \n",
       "TTTGTTGTCCTGTAAG.32.11                0  ...                0   \n",
       "TTTGTTGTCGAACCTA.5.2                  0  ...                0   \n",
       "TTTGTTGTCTTACACT.27.3                 1  ...                1   \n",
       "TTTGTTGTCTTCCCGA.28.6                 1  ...                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0  ...                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000198899  ENSG00000198938  ENSG00000198840  \\\n",
       "AAACCCAAGAAATCCA.12.9                 3                2                1   \n",
       "AAACCCAAGATTCGCT.20.4                40               34                6   \n",
       "AAACCCAAGCCATCCG.21.6                 4                5                1   \n",
       "AAACCCAAGCCTATTG.18.6                23               40               11   \n",
       "AAACCCAAGCTAGATA.25.10               90              118               43   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGTCCTGTAAG.32.11                4                9                1   \n",
       "TTTGTTGTCGAACCTA.5.2                 15               33                3   \n",
       "TTTGTTGTCTTACACT.27.3                21               36                9   \n",
       "TTTGTTGTCTTCCCGA.28.6                 4                4                0   \n",
       "TTTGTTGTCTTGGTGA.8.11                 1                1                1   \n",
       "\n",
       "ensemble_gene_name      ENSG00000212907  ENSG00000198886  ENSG00000198786  \\\n",
       "AAACCCAAGAAATCCA.12.9                 0                0                3   \n",
       "AAACCCAAGATTCGCT.20.4                 0               12                4   \n",
       "AAACCCAAGCCATCCG.21.6                 0                3                0   \n",
       "AAACCCAAGCCTATTG.18.6                 2               21                2   \n",
       "AAACCCAAGCTAGATA.25.10                0               32               10   \n",
       "...                                 ...              ...              ...   \n",
       "TTTGTTGTCCTGTAAG.32.11                0                4                0   \n",
       "TTTGTTGTCGAACCTA.5.2                  0                6                2   \n",
       "TTTGTTGTCTTACACT.27.3                 1                7                4   \n",
       "TTTGTTGTCTTCCCGA.28.6                 0                1                2   \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                3                0   \n",
       "\n",
       "ensemble_gene_name      ENSG00000198695  ENSG00000198727  ENSG00000274847  \n",
       "AAACCCAAGAAATCCA.12.9                 0                4                0  \n",
       "AAACCCAAGATTCGCT.20.4                 0               14                0  \n",
       "AAACCCAAGCCATCCG.21.6                 0                1                0  \n",
       "AAACCCAAGCCTATTG.18.6                 0               18                0  \n",
       "AAACCCAAGCTAGATA.25.10                0               60                0  \n",
       "...                                 ...              ...              ...  \n",
       "TTTGTTGTCCTGTAAG.32.11                0                3                0  \n",
       "TTTGTTGTCGAACCTA.5.2                  0                5                0  \n",
       "TTTGTTGTCTTACACT.27.3                 0               25                0  \n",
       "TTTGTTGTCTTCCCGA.28.6                 0                6                0  \n",
       "TTTGTTGTCTTGGTGA.8.11                 0                1                0  \n",
       "\n",
       "[61667 rows x 22500 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merged_data_clinical_pathological = merged_data_clinical_pathological[merged_data_clinical_pathological.index.isin(covariates_dataframe.index)]\n",
    "merged_data_clinical_pathological = merged_data_clinical_pathological.sort_index()\n",
    "merged_data_clinical_pathological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88c51ca3-8f3e-4c22-bcba-e8c3af47dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming merged_data_clinical_pathological is your data matrix (samples x features)\n",
    "# and labels is a list/array of labels corresponding to each sample\n",
    "\n",
    "# Standardize the data (important for PCA)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(merged_data_clinical_pathological)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=10)  # Choose number of components\n",
    "principal_components = pca.fit_transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b406ec3-3dc4-460d-b80c-99c2c64f769a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10289423, 0.00902173, 0.00776265, 0.00503358, 0.00329029,\n",
       "       0.00186534, 0.00182254, 0.0015859 , 0.00147769, 0.00141185])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a70155b-5268-4f60-bb1c-0f8f4188b780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22.40968103,   0.86275247,  -3.29953434, ...,   7.01994722,\n",
       "          3.98354209,  -0.84037539],\n",
       "       [ 64.83545466,  30.71745945,   3.3835039 , ...,  -8.09946582,\n",
       "         -3.23784515,  -1.82138864],\n",
       "       [-45.26718999,   0.68400237,   2.88072597, ...,  -0.2475044 ,\n",
       "         -0.28667145,   0.34586479],\n",
       "       ...,\n",
       "       [164.15258874,  47.84395532,  21.16950727, ..., -12.50461814,\n",
       "        -12.18768943,  -0.24136847],\n",
       "       [ 66.66519381,  31.93525096,   3.19950867, ...,  -6.20976698,\n",
       "         -9.17699736,   1.79006498],\n",
       "       [ -2.68893932,  -4.92479415, -12.95676358, ...,  -0.2414489 ,\n",
       "         -4.48268297,  -6.38373638]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2bbfbf0-d1d7-49fb-8e27-5f57c28fa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "correlation_matrix = np.corrcoef(principal_components.T, covariates_dataframe.T)[:principal_components.shape[1], principal_components.shape[1]:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6852f5f5-b7a2-4717-b9f2-8ef11c06bb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correlation between PCs and Covariates')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot Heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', xticklabels=covariates_dataframe.columns,\n",
    "            yticklabels=[f'PC {i+1}' for i in range(principal_components.shape[1])], ax=ax1)\n",
    "ax1.set_title('Correlation between PCs and Covariates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6828b5a-c434-4a5e-8ff2-43450455f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         PC1       PC2       PC3       PC4       PC5  \\\n",
      "ensemble_gene_name                                                     \n",
      "ENSG00000163463     0.001049 -0.002934  0.004109  0.000413 -0.000292   \n",
      "ENSG00000163462     0.007016  0.000021 -0.001893 -0.000132 -0.001204   \n",
      "ENSG00000185499     0.000160 -0.000155 -0.000401 -0.001043  0.000430   \n",
      "ENSG00000169231     0.005109  0.005020  0.001255  0.002169 -0.001035   \n",
      "ENSG00000261905     0.004033 -0.004559  0.010764  0.000891 -0.001687   \n",
      "...                      ...       ...       ...       ...       ...   \n",
      "ENSG00000198886     0.011342 -0.006207  0.027388  0.003835 -0.002184   \n",
      "ENSG00000198786     0.011215 -0.000836  0.021986  0.001562  0.000366   \n",
      "ENSG00000198695     0.003299 -0.001315  0.005838  0.000059 -0.000622   \n",
      "ENSG00000198727     0.011811 -0.004210  0.029949  0.001794 -0.001750   \n",
      "ENSG00000274847     0.001135 -0.002068 -0.000705  0.001845 -0.001088   \n",
      "\n",
      "                         PC6       PC7       PC8       PC9      PC10  \n",
      "ensemble_gene_name                                                    \n",
      "ENSG00000163463    -0.004271 -0.000801  0.000772 -0.000747 -0.000700  \n",
      "ENSG00000163462    -0.010017  0.003912  0.003911  0.003235 -0.001930  \n",
      "ENSG00000185499     0.000937 -0.002358 -0.000161  0.000003 -0.002615  \n",
      "ENSG00000169231    -0.008398  0.001489 -0.000117  0.003550 -0.000353  \n",
      "ENSG00000261905    -0.004282  0.001414  0.000649 -0.000739 -0.001230  \n",
      "...                      ...       ...       ...       ...       ...  \n",
      "ENSG00000198886     0.044047  0.005154 -0.002026  0.057321 -0.020372  \n",
      "ENSG00000198786     0.051642  0.001570 -0.008382  0.047615 -0.018558  \n",
      "ENSG00000198695    -0.001098  0.001473  0.000539  0.005493 -0.002945  \n",
      "ENSG00000198727     0.043156  0.007290 -0.000583  0.051628 -0.021452  \n",
      "ENSG00000274847    -0.000567 -0.000972 -0.001468 -0.000770  0.001498  \n",
      "\n",
      "[22500 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "loadings = pca.components_\n",
    "loadings_df = pd.DataFrame(loadings.T, columns=[f'PC{i+1}' for i in range(loadings.shape[0])], index=merged_data_clinical_pathological.columns)\n",
    "print(loadings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c843eb83-2646-4618-a683-b3a87743acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_df.to_csv('../../../../usman/Single_Cell_Microglia_Project/results/inhibitory_neuron/loadings_pca_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13dd118-b507-441f-8bf1-2c86705c45b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cba262ac-425b-4872-9026-f991709b3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_column(column):\n",
    "    np.random.shuffle(column)\n",
    "    return column\n",
    "\n",
    "def permutation_test_covariates(df):\n",
    "    shuffled_df = df.copy()\n",
    "    return shuffled_df.reindex(np.random.permutation(shuffled_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6f720267-e85f-49b4-8b27-49ccf91c3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_covariates = permutation_test_covariates(covariates_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "554f0b85-6056-481f-9e34-5f7d1d9b3a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_death</th>\n",
       "      <th>pmi_df2</th>\n",
       "      <th>msex</th>\n",
       "      <th>educ</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>braaksc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CATTGTTAGTATCCTG.6.9</th>\n",
       "      <td>84.216290</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGAGGATTCCACACCT.14.4</th>\n",
       "      <td>82.713210</td>\n",
       "      <td>5.716667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTCCGATTCGCCAGTG.22.9</th>\n",
       "      <td>86.587269</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAGGCCTGTGGGATTG.25.10</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCATCTCAGTGCCGAA.21.6</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGCACGTCGAATGCT.2.9</th>\n",
       "      <td>81.911020</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGCACGTAGAGAGTGA.5.6</th>\n",
       "      <td>80.736482</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGATCAGAGTTAGTAG.25.9</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCAGGGCTCCTAAACG.1.3</th>\n",
       "      <td>84.700890</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAGACCCCAGGAGACT.31.6</th>\n",
       "      <td>83.871321</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61667 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        age_death    pmi_df2  msex  educ  cogdx  ceradsc  \\\n",
       "cell_id                                                                    \n",
       "CATTGTTAGTATCCTG.6.9    84.216290  10.733333   1.0  14.0    1.0      4.0   \n",
       "GGAGGATTCCACACCT.14.4   82.713210   5.716667   1.0  19.0    4.0      1.0   \n",
       "CTCCGATTCGCCAGTG.22.9   86.587269   1.250000   1.0  25.0    4.0      1.0   \n",
       "GAGGCCTGTGGGATTG.25.10  90.000000   5.000000   0.0  11.0    4.0      1.0   \n",
       "GCATCTCAGTGCCGAA.21.6   90.000000   6.866667   0.0   7.0    4.0      1.0   \n",
       "...                           ...        ...   ...   ...    ...      ...   \n",
       "GTGCACGTCGAATGCT.2.9    81.911020   3.916667   0.0  16.0    1.0      4.0   \n",
       "GGCACGTAGAGAGTGA.5.6    80.736482   6.000000   0.0  16.0    4.0      1.0   \n",
       "TGATCAGAGTTAGTAG.25.9   90.000000   4.166667   1.0  15.0    4.0      1.0   \n",
       "TCAGGGCTCCTAAACG.1.3    84.700890   4.083333   1.0  16.0    4.0      1.0   \n",
       "GAGACCCCAGGAGACT.31.6   83.871321   5.083333   1.0  18.0    1.0      4.0   \n",
       "\n",
       "                        braaksc  \n",
       "cell_id                          \n",
       "CATTGTTAGTATCCTG.6.9        2.0  \n",
       "GGAGGATTCCACACCT.14.4       3.0  \n",
       "CTCCGATTCGCCAGTG.22.9       1.0  \n",
       "GAGGCCTGTGGGATTG.25.10      4.0  \n",
       "GCATCTCAGTGCCGAA.21.6       5.0  \n",
       "...                         ...  \n",
       "GTGCACGTCGAATGCT.2.9        4.0  \n",
       "GGCACGTAGAGAGTGA.5.6        5.0  \n",
       "TGATCAGAGTTAGTAG.25.9       5.0  \n",
       "TCAGGGCTCCTAAACG.1.3        3.0  \n",
       "GAGACCCCAGGAGACT.31.6       3.0  \n",
       "\n",
       "[61667 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ca264065-8df8-4228-b0df-b17fa1155259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 61667)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principal_components.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c58dff2-7561-40c2-981a-f7f22580cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "covariates_clinical_data_AD_NCI = covariates_dataframe\n",
    "X_pca_expression = principal_components\n",
    "\n",
    "li = [[[] for i in range(covariates_clinical_data_AD_NCI.T.shape[0])] for l in range(X_pca_expression.shape[1])]\n",
    "for l in range(X_pca_expression.shape[1]):\n",
    "    x = np.array(np.array(X_pca_expression.T[l]))\n",
    "    for i in range(1000):\n",
    "        shuffled_covariates = permutation_test_covariates(covariates_clinical_data_AD_NCI)\n",
    "        \n",
    "        for k,j in enumerate(range(shuffled_covariates.T.shape[0])):\n",
    "            y = np.array(np.array(shuffled_covariates.T.iloc[j,]))\n",
    "            corr = np.corrcoef(x,y)[0,1]\n",
    "            li[l][k].append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "72e96ba7-42b0-4616-a065-2bd707c0229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00662549, 0.01017039, 0.00594471, ..., 0.00301107, 0.00385116,\n",
       "        0.00759747],\n",
       "       [0.00817778, 0.00619233, 0.00454291, ..., 0.00292302, 0.00657604,\n",
       "        0.00828092],\n",
       "       [0.00608114, 0.00309599, 0.00677586, ..., 0.00497589, 0.00450232,\n",
       "        0.00538373],\n",
       "       ...,\n",
       "       [0.00630857, 0.00419316, 0.00313353, ..., 0.00429841, 0.00287835,\n",
       "        0.00212136],\n",
       "       [0.00456399, 0.00470891, 0.01004045, ..., 0.00542672, 0.00466258,\n",
       "        0.0057585 ],\n",
       "       [0.0047161 , 0.00238   , 0.00391778, ..., 0.00569032, 0.00284061,\n",
       "        0.00433141]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = np.array(li)\n",
    "li = np.sort(np.abs(li), axis=1)\n",
    "percentiles_90 = np.percentile(li, 90, axis=1)\n",
    "percentiles_90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "634a4c7f-dfae-4287-89e0-1a9b8f911a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_pc_fdr = []\n",
    "for i in li:   \n",
    "    li_ = np.array(i)\n",
    "    li_ = np.sort(np.abs(li_), axis=1)\n",
    "    percentiles_90 = np.percentile(li_, 90, axis=1)\n",
    "    li_pc_fdr.append(list(percentiles_90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "519a5f4c-98cf-4056-af2a-95e138fc1d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(li_pc_fdr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e4ba2c44-4c9b-4102-93e9-3b1843fadb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correlation between PCs and Covariates')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "sns.heatmap(np.array(li_pc_fdr), annot=True, cmap='coolwarm', fmt='.2f', xticklabels=covariates_clinical_data_AD_NCI.columns, yticklabels=[f'PC {i+1}' for i in range(X_pca_expression.shape[1])], ax=ax1)\n",
    "ax1.set_title('Correlation between PCs and Covariates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "93045ab4-ea38-424e-8582-0eeda4d4407e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correlation between PCs and Covariates')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot Heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', xticklabels=covariates_dataframe.columns,\n",
    "            yticklabels=[f'PC {i+1}' for i in range(principal_components.shape[1])], ax=ax1)\n",
    "ax1.set_title('Correlation between PCs and Covariates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e332285-8877-44db-b0bc-4bde349b3505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
